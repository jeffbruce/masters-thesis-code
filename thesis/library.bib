Automatically generated by Mendeley 1.8
Any changes to this file will be lost if it is regenerated by Mendeley.

@article{Wiklund2004,
author = {Wiklund, K. and Sonnadara, R. and Trainor, L. and Haykin, S.},
doi = {10.1109/ICASSP.2004.1326749},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/2004 - R-HINT-E A realistic hearing in noise test environment.pdf:pdf},
isbn = {0-7803-8484-9},
journal = {2004 IEEE International Conference on Acoustics, Speech, and Signal Processing},
pages = {iv--5--8},
publisher = {Ieee},
title = {{R-HINT-E: a realistic hearing in noise test environment}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1326749},
year = {2004}
}
@article{Clarkson1988,
author = {Clarkson, M G and Clifton, R K and Perris, E E},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Clarkson, Clifton, Perris - 1988 - Infant timbre perception discrimination of spectral envelopes.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Auditory Perception,Child Psychology,Conditioning, Operant,Cues,Female,Humans,Infant,Male,Psychoacoustics},
month = jan,
number = {1},
pages = {15--20},
pmid = {3340494},
title = {{Infant timbre perception: discrimination of spectral envelopes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3340494},
volume = {43},
year = {1988}
}
@article{Ricketts1999,
abstract = {This study compared the speech recognition performance of 12 hearing-impaired listeners fit with three commercially available behind-the-ear hearing aids in both directional and omnidirectional modes. One digitally programmable analog and two "true digital" hearing aids were selected as test instruments. Testing was completed in both "living room" and anechoic room environments. Speech recognition was examined using modified forms of the Hearing in Noise Test and the Nonsense Syllable Test. The single competing stimuli of these tests were replaced with five uncorrelated competing sources. Results revealed a significant speech recognition in noise advantage for all directional hearing aids in comparison to their omnidirectional counterparts. Maximum performance of the directional hearing aids did not significantly vary across circuit type, suggesting that processing differences did not affect maximum directional hearing aid performance. In addition, the results suggest that performance in one reverberant environment cannot be used to accurately predict performance in an environment with differing reverberation.},
author = {Ricketts, T and Dhar, S},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Speech-In-Noise Tests/1999 (Ricketts, Dhar) - Comparison of Performance across Three Directional Hearing Aids.pdf:pdf},
issn = {1050-0545},
journal = {Journal of the American Academy of Audiology},
keywords = {Acoustic Stimulation,Acoustic Stimulation: instrumentation,Equipment Design,Hearing Aids,Hearing Disorders,Hearing Disorders: therapy,Humans,Speech Perception,Speech Perception: physiology},
month = apr,
number = {4},
pages = {180--9},
pmid = {10941709},
title = {{Comparison of performance across three directional hearing aids.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10941709},
volume = {10},
year = {1999}
}
@article{Korczak2005,
abstract = {To systematically investigate the combined effects of sensorineural hearing loss and prescribed personal hearing aid(s) on cortical event-related potentials (ERPs) (waves N1, MMN, N2b, and P3b) and their related behavioral measures of discrimination (d-prime sensitivity and reaction time) to the speech sounds /ba/ and /da/ presented at 65 and 80 dB peak-to-peak equivalent SPL.},
annote = {        Introduction        
-cortical ERPs with behavioural measures (d-prime sensitivity, reaction time) have been used to assess cognitive processes involved in detection and discrimination of speech sounds in normal-hearing subjects [references], as well as those with SNHL [reference]
-with increasing degree of hearing loss, latencies of ERPs and reaction time measures are prolonged, and ERP amplitudes and d-prime sensitivity scores are reduced or absent [Oates et al., 2002]
-combining these behavioural and electrophysiological measures gives a window into how auditory perception may be improved by personal hearing aids
-Kraus and McGee (1994) investigated the effects of SNHL and hearing aids on MMN and P300 - one subject had good behavioural discrimination of /ta-da/ and showed a present MMN and P300, whereas the other person had poor behavioural discrim and had no MMN, but a present P300
-in the previous studies mentioned in the introduction, electroacoustic or real ear measurements were not taken
-there seem to be inconsistent results because there are so many variables (calibration of stimuli, number of trials, degree of hearing loss, verification of hearing aid gain, etc.)
-reaction time is defined as the time from the onset of a stimulus to initiation of a motor response, and therefore provides a measure of the speed of signal processing [references]
-d-prime on the other hand is a criterion free measure of percent correct, taking into account false-alarm rate [Swets, 1973]
-for a review of cortical ERPs in assisting in managing hearing losses in clinical populations, see Stapells (2002) chapter in Handbook of Clinical Audiology
-cortical ERPs allow the investigator to look at the integrity of the entire auditory system, and can be recorded from a variety of stimuli which makes it comprehensive and quite flexible
-cortical ERPs are useful for determining whether there is any higher-level auditory dysfunction
-slow cortical ERPs (P1-N1-P2) may be used to assess the auditory cortex's ability to detect a change in speech stimuli (Martin \& Boothroyd, 1999), and may also be used as a functional measure of benefit provided by personal hearing aids [references]
-Kane and colleagues have shown that the MMN can be elicited in coma patients [reference]; in contrast, conscious perception of an acoustic change to elicit an N2b or P3b does require attention [Naatanen \& Alho, 1997]
-the purpose of the present study was to:
1) assess the effect of SNHL and hearing aids on the detectability of cortical ERPs to /ba-da/ speech sounds in adults with SNHL
2) determine effect of SNHL and hearing aids on latencies and amplitudes of ERPs across varying degrees of hearing loss
3) determine whether these differences in amplitude / latencies reflect different stages of auditory processing
                  
Methods                  
Subjects        
-2 groups of subjects: 20 listeners with normal hearing, and 14 with SNHL
-10 normals testing in active condition, the other 10 in the passive condition
-the 10 normals in the active condition and all of the SNHL group participated in the 2002 study (Oates et al.)
-for analyses, the SNHL group was divided into 2 groups ("moderate" and "severe-profound" groups)
-all participants in the study had normal tympanograms (single peak, between +/- 50 daPa to a 226 Hz probe tone) and no self-reported history of recurrent middle-ear or neurological problems
-immittance testing done before each session to ensure no changes in middle-ear function
-normals were only tested in the unaided condition, and SNHL group tested both aided and unaided; 10 of the SNHL group wore binaural hearing aids and 4 wore monaural
        Stimuli        
-consonant-vowel stimuli /ba/ and /da/ were the same as used in the 2002 Oates et al. study -- natural speech tokens, 30000Hz sampling rate, 10000Hz anti-aliasing filter, edited to 150ms long, removed final portion of the steady-state vowel and windowed the vowel offset
-these stimuli were chosen because they differ in place of articulation, which is susceptible to effects of peripheral hearing impairment
-stimuli presented at 65 and 80 dB SPL, 1m away from the subject from a speaker, and these levels correspond to 70 and 85 dB HL according to ANSI standards and binaural free field sensitivity [reference]
-stimuli were presented in active and passive oddball paradigms
-in the active condition, they were asked to listen for the deviant stimulus and press a button as quickly and accurately as possible
-in the passive condition, they were asked to sit quietly, ignore the stimuli, stay awake, and read a magazine of their choice
-90\% for the standard and 10\% for the deviant, onset to onset ISI was 1100ms for active condition, and 627ms for the passive condition
-both speech sounds presented as standards and deviants in separate runs
-order of stimulus presentation was pseudorandom for the active condition, so no run began with a deviant and a deviant was never adjacent to another deviant
-for the passive condition, stimulus presentation was not randomized, and every 10th stimulus was a deviant [reference]
-for active condition, electrophysiological responses to 200 stimuli were recorded in a run, and each run was replicated, for 400 total trials for each stimulus at each intensity
-for passive condition, 1000 single-trial recordings were obtained then replicated, producing 2000 trials for each stimulus at both intensities
-a larger number of trials was needed for passive due to small amplitude and large variability of the MMN [reference]
-2000 trials had been used before in MMN studies with simulated hearing losses and actual hearing losses [references]          
EEG Recordings        
-ERPs were obtained using 7 EEG channels, and an eighth channel for eye movements, reference on the nose
-an electrode on the 7th cervical vertebra served as ground
-impedances were 5 kOhm or less, and were amplified (20000 gain), filtered (0.1 to 100Hz, 6 dB/octave), and digitized (568Hz per channel, 512 points) using analysis times of 900ms and 550ms for the active and passive conditions respectively
-prestimulus baseline activity was part of the analysis time, and before averaging, offline signal processing was done (baseline correction, digital filtering in freq domain -- 30Hz low-pass, artifact rejection)          
Behavioural Measures        
-median reaction times were calculated (only on the active task obviously) as opposed to means because the reaction time distribution is skewed
-participants only pressed the button if they heard the deviant, and misses/false alarms, hits, and correct rejections were tallied
-presentation rate was 0.9/sec, and timing was independent of response button presses
-d-prime was calculated by z(false alarms) - z(hits)          
Procedure        
-testing done in double-walled sound-attenuating booth
-one session for the NH subjects, first passive then active conditions
-two sessions for the HI subjects, first aided then unaided, and always passive first
-electroacoustic analysis done before testing with Audioscan, providing an evaluation of gain, freq response, and output limiting
-participants told to adjust VC to MCL, while 65 dB SPL /ba-da/ speech sounds were played, with the softer stimuli used because it was closer to conversational levels
-once hearing aids set to MCL, real ear was conducted
-REAR was compared to REUR to get REIG for 1000 and 2000Hz and was compared to the target given by NAL-RP, and the SII was also expressed as a percentage value
-1000 and 2000Hz were looked at specifically because the primary acoustic cues needed to differentiate ba and da are between 1300 and 1900Hz (Oates et al., 2002)
-for a majority of subjects, the difference between target and real gain was within 5dB, and SII improvements ranged from 6-81\%
-during the active condition, subjects fixated on a dot and avoided blinking and swallowing          
Data Analysis        
-to get N2b and MMN, averaged standard was subtracted from average deviant
-two judges judged whether the ERP peaks were visible in individual responses according to specified criteria (highlighted on pg 170)
-presence of MMN was determined using difference waveforms in the passive conditions, and also had to be more negative at fronto-central sites than parietal, and a polarity inversion at mastoid electrode sites
-peaks were compared across the replicated recording blocks, and if consistent, they were kept
-if there was no peak judged, 0uV was assigned          
Response Measurements        
-N1 was defined as the largest negativity occurring between 80 and 200ms at Cz to the standard; N2b was defined as largest negativity from 200 and 420ms at Cz in the difference waveform; P3b was defined as the largest positivity between 285 and 800ms at Pz in response to the deviant.  MMN was defined as largest negativity occurring between 80 and 400ms at Fz in the difference waveform
-some postprocessing techniques are listed on page 172          
Statistical Analyses        
-ANOVAs were only performed at the electrode sites with the maximum responses for each component
                  
Results        
-results of the ANOVAs indicate that ERPs and behavioural results don't differ between /ba/ and /da/, so results were averaged across these stimuli
-the only exceptions were N1 MMN and N2b latencies at 80 dB SPL          
Effect of HL and HA on ERPs and Behavioural Measures        
-one participant's responses are shown in Fig 1
-use of a personal hearing aid substantially increased amplitude and decreased latency of all ERP components, particularly for the lower level stimulus
-the subject's response time latencies were also significantly shorter in the aided condition, especially for the lower intensity stimulus
-despite improvements in RT and latencies for the aided condition, they are still worse than that found in the old study with normal subjects (Oates et al., 2002)
-Fig 2 shows the same participant in the passive condition, and potential MMNs
-no pronounced MMNs in the unaided condition, but seems to be some in the aided condition
-the MMN recorded in the 80 dB SPL aided condition does resemble amplitude, latency, and morphology of the responses recorded in subjects with normal-hearing sensitivity
-from Table 3, the use of HAs had a substantial impact on response presence at lower stimulus intensity for both moderate and severe groups, but for the higher intenisty, use of hearing aids only produced a large improvement for the severe group
-Fig 3 shows the grand-mean waveforms for each group
-in the active condition with 65 dB stim, use of hearing aids clearly improved detectability of waves N1, N2b, and P3b for individuals with moderate or severe impairments, and especially the severe group
-in the active condition with 80 dB, a similar pattern was found, with the morphology looking more normal once amplification was applied.  amplification clearly helps the severe group more than the moderate group, which makes sense given that more amplification would be given to the severe group
-despite improvements given by amplification, the mean latencies are delayed for the impaired groups relative to the NH group, and especially at lower stimulus intensities
-Fig 4 shows grand-mean waveforms in the passive condition for each group
-for stimuli presented at 65 dB SPL, use of hearing aids improved detectability of the MMN for individuals in the moderate group, but no MMN was evident in the unaided or aided conditions for the severe-profound group
-one surprising result for 80 dB SPL in the passive condition was that the amplitude of the aided MMN was smaller than unaided for the moderate group
-another surprising result for 80 dB SPL passive is despite there being no aided MMN in the severe-profound group for 80 dB SPL, it was judged to be present in 87.5\% of individual cases, which is likely due to variability in latency between subjects and poor SNR of the MMN
-ANOVAs were done with two within-subjects factors of stimulus type and test condition (aided vs unaided); responses for each stimulus intensity were tested separately because some HI subjects were not tested at 65 dB SPL
-all response strength measures (ERP amplitudes and dprime) were larger in the aided versus unaided conditions for lower stimulus intensity, and a clear trend of all mean ERP and RT latencies at 65 dB SPL to be shorter in aided versus unaided condition (MMN latency was the only exception)
-a different pattern of results emerged for the 80 dB SPL stimuli: only N1 amplitudes and d-prime sensitivity were significantly better/larger in the aided versus unaided conditions, and a trend for P3b amplitudes to be larger; also, all ERP and RT latencies were shorter, except for MMN, but none of these differences were statistically significant          
Comparison of Aided ERP and Behavioural Measures to Those From NH Subjects        
-because there is more to SNHL than just a reduced threshold, ANOVA comparisons were made to see if the brain's ability to process the speech stimuli is similar between aided HI subjects and normal subjects
-the between subject factor here was group (NH, moderate, or severe), and within subject factor was type of stimulus (ba versus da), and again, results for each stimulus intensity were evaluated independently
-at both stim intensities, mean amplitudes for the moderate group were larger than the normal subjects, but none of these differences reached statistical significance
-mean aided ERP and RT latencies for the HI groups were prolonged compared to individuals with normal hearing sensitivity for both stimulus intensities (only ones that reached significance were RTs at both intensities and N2b latencies at 80 dB)
-my own observation: it seems like behavioural studies of these kinds have more power          
Variability in Improvements for ERP and Behavioural Measures in Aided Condition        
-Fig 5 shows the change in amplitude/latency of ERP components and behavioural measures between unaided and aided for the 65 dB SPL condition
-the vast majority of subjects demonstrated improvements in the aided versus unaided for both behavioural and electrophysiological measures at 65 dB SPL; there were a few subjects who demonstrated opposite effects, however
-Fig 5 also shows that the latencies are delayed relative to mean latencies for the NH subjects
-even though most participants showed increased amplitude, decreased latency, the amount of response change was quite variable
                  
Discussion        
-clear effect of hearing aid use on timing and strength of brain processes involved in speech detection/discrimination, and is dependent on level of hearing loss, intensity of stimuli, and level of brain processing (early vs. late)
-results of this study also show cortical ERPs and behavioural measures could be consistently recorded
-the greatest improvements in detectability occurred for individuals in the severe group
-improvements in latencies and amplitudes as well as behavioural measurements was greatest for the lower intensity stimulus
-the reason for the improvements being greatest for the lower stimulus intensity could be due to the decreased audibility of the lower intensity stimulus, or due to the output limiter
-the improvements did not completely restore functionality to normal
-there was large intersubject variability, and when the worsening or opposite pattern occurred, it was often in the MMN
-recording the MMN in individuals is more challenging than other cortical ERPs, because it is generally smaller in amplitude, the difference waveform has more noise (1.41 times more), more trials are needed due to the lower SNR, MMN is not always reliably elicited in individual subjects or SNHL subjects, MMN amplitude can vary significantly based on arousal levels, and the MMN is less reliable in children than adults
-there is clinical value in looking at these responses, because if an N1 is observed in the aided condition, it's clear that the auditory cortex is better encoding the sound, which the listener may decide to leverage
-response changes later on in the ERPs can provide audiologists with info regarding whether the brain can discriminate the acoustic differences between speech stimuli better with a hearing aid, such as the MMN at a preattentive level and N2b and P3b at an attentive level
-these techniques may also be useful in such a case as seeing an intact MMN and N1, but no visible N2b and P3b, suggesting the sound is being encoded at a preattentive level but the brain hasn't learned to use it in perception
-it is also possible for smaller amplitudes and longer latencies yet still intact behavioural scores, which may indicate an auditory processing disorder          
Summary and Future Directions        
-nothing very important in this section},
author = {Korczak, Peggy a and Kurtzberg, Diane and Stapells, David R},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/EEG/2005 (Korczak, Kurtzberg, Stapells) - Effects of SNHL and HAs on ERP and Behavioural Measures of Speech-Sound Processing.pdf:pdf},
issn = {0196-0202},
journal = {Ear and hearing},
keywords = {Acoustic Stimulation,Acoustic Stimulation: instrumentation,Adult,Audiometry, Pure-Tone,Brain,Brain: physiology,Evoked Potentials,Evoked Potentials: physiology,Female,Hearing Aids,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: diagnosis,Hearing Loss, Sensorineural: rehabilitation,Humans,Male,Phonetics,Prosthesis Design,Severity of Illness Index,Speech Discrimination Tests,Speech Perception},
month = apr,
number = {2},
pages = {165--85},
pmid = {15809543},
title = {{Effects of sensorineural hearing loss and personal hearing AIDS on cortical event-related potential and behavioral measures of speech-sound processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15809543},
volume = {26},
year = {2005}
}
@article{Moore2010,
abstract = {Moore et al (1999b) described a procedure, CAMEQ, for the initial fitting of multi-channel compression hearing aids. The procedure was derived using a model of loudness perception for impaired hearing. We describe here the development of a new fitting method, CAMEQ2-HF, which differs from CAMEQ in the following ways: (1) CAMEQ2-HF gives recommended gains for centre frequencies up to 10 kHz, whereas the upper limit for CAMEQ is 6 kHz; (2) CAMEQ is based on the assumption that the hearing aid user faces the person they wish to hear and uses a free-field-to-eardrum transfer function for frontal incidence. CAMEQ2-HF is based on the assumption that the user may wish to hear sounds from many directions, and uses a diffuse-field-to-eardrum transfer function; (3) CAMEQ2-HF is based on an improved loudness model for impaired hearing; (4) CAMEQ2-HF is based on recent wideband measurements of the average spectrum of speech.},
author = {Moore, Brian C J and Glasberg, Brian R and Stone, Michael a},
doi = {10.3109/14992020903296746},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Hearing Aids and Hearing Loss/Fitting Procedures/2010 (Moore et al.) - Development of a new method for deriving initial fittings CAMEQ2-HF.pdf:pdf},
isbn = {1499202090329},
issn = {1708-8186},
journal = {International journal of audiology},
keywords = {Audiometry, Speech,Auditory Threshold,Hearing Aids,Humans,Loudness Perception,Prosthesis Fitting},
month = mar,
number = {3},
pages = {216--27},
pmid = {20151930},
title = {{Development of a new method for deriving initial fittings for hearing aids with multi-channel compression: CAMEQ2-HF.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20151930},
volume = {49},
year = {2010}
}
@article{Byrne1998,
author = {Byrne, D. and Noble, W.},
doi = {10.1177/108471389800300202},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Sound Localization/1998 (Byrne, Noble) - Optimizing Sound Localization with Hearing Aids.pdf:pdf},
issn = {1084-7138},
journal = {Trends in Amplification},
month = jun,
number = {2},
pages = {51--73},
title = {{Optimizing Sound Localization with Hearing Aids}},
url = {http://tia.sagepub.com/cgi/doi/10.1177/108471389800300202},
volume = {3},
year = {1998}
}
@article{McDermott2004,
annote = {- reviews research on music perception in cochlear implants
1) implant users perceive rhythm about as well as normal listeners
2) recognition of melodies is extremely poor (little better than chance) when rhythmic or verbal cues are absent, even with multi-channel sound processors
3) perception of timbre is unsatisfactory
4) implant users rate quality of musical sounds as less pleasant than listeners with normal hearing
5) special auditory training programs may improve subjective acceptability of music for CI users
6) pitch perception may be improved using innovative sound processors that use spatial and temporal patterns of electrical stimulation; overcome the limitations of signal coding in existing CIs
7) CI population is growing, and some of these users with low frequency hearing intact may benefit in music perception from combined acoustic and electric stimulation
                  
1. INTRODUCTION
        - goes over the earliest attempts of cochlear implantation, and how they affect music perception (recognition of familiar music, pitch discriminations)
                  
2. COCHLEAR IMPLANT TECHNOLOGY
        - implant systems have a microphone usually packaged in an enclosure worn on the user's pinna, like with conventional BTE hearing aids
- mechanical signal is transduced into electrical form, selectively processed by the signal processor and converted into patterns of nerve activity
- Loizou (1998) writes about various distinct processing schemes for CI sound processors          
2.1. IMPLANTED DEVICES        
- output of the sound processor is a digital code, specifying the parameters to be sent to the electrode array, sent through an inductive link, decoded by a receiver
- output of most stimulators is precisely controlled current sent to the electrode as a series of symmetric, biphasic pulses (although some are able to generate analog stimuli)
- an orderly relationship between frequency of a sound and location of maximal excitation on the cochlea (Greenwood, 1990)
- not only tonotopic organization of hair cells, but also cell bodies and dendrites
- multiple electrodes in implant arrays can deliver stimulating currents in different ways:
monopolar, bipolar, common ground
(it gets complicated around this section)          
2.2. SOUND PROCESSORS
(skipped this section for now, goes into far too much detail)
          
          
3. MUSIC PERCEPTION WITH COCHLEAR IMPLANTS        
- there are objective and subjective characteristics in the experience of music
- objective - rhythm, melody, timbre, loudness, harmony
- subjective - subjective quality, mood, situational context          
3.1. PERCEPTION OF RHYTHM        
- rhythm is a temporal pattern varying in intensity, although personally I don't think variations in intensity is a necessity
- standardized test for music perception (Gfeller and Lansing, 1991; 1992) is the Primary Measures of Music Audiation (PMMA), developed mainly for use with children (Gordon, 1979)
- rhythm subtest of PMMA comprises pairs of short sequences of sounds, unvarying pitch and timbre; sequences either identical or different, randomly presented to listener, who then indicates whether the pair is same or different
- Gfeller and Lansing (1991) used this test on 18 adult cochlear implant users; mean score was 88\% and ranged from 80 to 95\%; little difference in performance related to the type of prosthesis
- Gfeller et al. (1997) used a modified PMMA rhythm subtest to compare two sound-processing schemes of a particular CI device (Nucleus 22-electrode); scores were 84\% correct, which was very close to the average score of a control group of 35 normal hearing subjects
- Schulz and Kerber (1994) investigated rhythmic pattern recognition and reproduction comparing 8 implant users and 7 normal hearing subjects; required listeners to identify patterns similar to common musical rhythms (tango, waltz), and to tap several distinctive rhythmic patterns (three to five beats); no statistical analyses were done on this data, but average scores for each group was at least 80\%
- Leal et al. (2003) assessed rhythm perception by 29 recipients of Nucleus 24-electrode device, majority used ACE scheme, remainder used SPEAK scheme; test was similar to PMMA rhythm subtest, but with fewer items; in addition to the discrimination of sequence pairs, an identification task was used -- subjects asked to indicate where in the sequence the rhythmic change occurred; subjects classified as 'good' or 'poor' on the basis of a criterion on the discrimination and identification tasks (90\% and 75\%); 24 performed 'good' on the discrimination test, only 12 performed 'good' on the identification test
- a test by Kong et al. (2004), compared 3 CI users to 4 normal hearing; task was to identify one of seven distinct rhythmic patterns; normally hearing subjects got near 100\% on the test, one CI user got near perfect, but the other 2 got 10 to 25\% lower; these results were replicated at different overall speeds as well (60-150 bpm)
- Kong et al. (2004) also looked at discriminating differences in tempo with 5 CI users; results very similar to the same 4 normal hearing subjects above; change in tempo discernable by the CI users ranged from 4 to 6 bpm across 60-120 bpm
- Szelag et al. (2004) asked CI users and matched normally hearing listeners to accentuate mentally a rhythmic pattern within a sequence of regular tone bursts presented at varying burst rates (1 to 5 bps); implant users did much poorer at integrating rhythmic patterns below 3 bps was significantly poorer than participants with normal hearing, but same for higher beat rates (controversial, because it's an unusual experimental procedure and is subjective)          
3.2. PERCEPTION OF MELODY                  
3.2.1. TUNE IDENTIFICATION        
- individuals vary in their ability to recognize tunes (listening experience, musical training, social culture, person's memory for the tunes and titles)
- Happy Birthday is rated amongst most familiar melodies for the general population (Gfeller et al., 2002a; Looi et al., 2003), even when acoustical fidelity is poor, incorrect intonations or rhythms, so the ability to perceive fundamental features of sounds is not necessary for recognition of a melody
- since CI rhythm perception is fairly intact, one would expect that recognition of melodies with distinctive rhythmic patterns is greater than recognition of melodies with more generic patterns; Schulz and Kerber (1994) found this with 8 CI users; only 4 tunes were used, presented in different musical arrangements, normal users got nearly 100\% correct, average score of the CI users was 50\%; when the songs were divided by rhythmically distinctive, the difference in scores was only 15\% between implant users and normal hearing subjects 
- similar study to the above was done with 49 CI users and 18 normal hearing subjects (Gfeller et al., 2002a), using 12 different melodies; overall score for CI users was 19\% correct, 83\% correct for normal hearing listeners; for each subject group the average score for rhythmic melodies was approximately 12\% higher than for arrhythmic melodies
- Kong et al. (2004) published more evidence supporting importance of rhythmic information for melody recognition in implant users.  6 normal subjects and 6 multi-channel CI users asked to identify 12 familiar songs, rhythmic information was taken out.  normal subjects got 100\%, CI users got 63\% when rhythmic cues were available, but when duration of notes were the same and silent intervals the same, recognition was reduced to chance levels
- Fujita and Ito (1999) looked at recognition of familiar melodies in several musical contexts.  found higher scores for closed-set identification of songs when played with words as opposed to just an instrumental sound.  discrimination of melodies lacking rhythmic or verbal cues was at chance level.          
3.2.2 MELODIC PATTERN RECOGNITION        
- pitch discrimination is more difficult than melody recognition because you can't use context to guide your answers
- task: label two pitch sequences as same or different
- in this task, you don't necessarily need absolute pitch or relative pitch, detection of an overall pitch contour change may be enough
- Dorman et al. (1991) asked CI users to determine if a musical scale was ascending or descending, and most of them were unable to discriminate these pitch sequences
- like with rhythm perception, a subtest of PMMA has been used for discrimination of pitch patterns
- tonal subtest, pairs of short sequences of notes with identical rhythm, but the pattern is same or different (18 CI users achieved 78\% on this test) (Gfeller and Lansing, 1991)
- the score of the CI users on the tonal subtest was 10\% lower than their scores on the rhythm subtest, whereas with normal hearing subjects you get the opposite trend (they do better on the tonal subtest)
- Gfeller et al. (1997) did a similar study with a modified version of the PMMA and CI users got 77\% correct
- another study (McKay and McDermott, 1993) used stimuli that varied in the way fundamental frequency (F0) changed over time; voiced phonemes with rising, steady, or falling F0 contour
- another variation in pitch sequence discrimination is asking the subjects to describe whether the pitch in each sequence became higher or lower, and indicate where the pitch change occurred          
3.3. PERCEPTION OF TIMBRE                  
3.3.1. TIMBRE RECOGNITION        
- most published studies on perception of timbre in cochlear implant users have been identification or discrimination of the sounds of different musical instruments
- Schulz and Kerber (1994) asked CI users to identify the instrument playing a melody from a closed set of five alternatives; they scored 35\% and normal hearing subjects got 90\%
- Gfeller et al. (2002b) looked at instrument identification with eight different instruments playing the same brief sequence of notes, selected their responses from a set of 16 possible alternatives; implant users scored 47\% and the normal hearing subjects again got 90\%; confusions in timbre by the implant users were of a diffuse pattern, and the normal hearing subjects tended to make mistakes on instruments of the same family
- Leal et al. (2003) used three different instruments (trombone, piano, violin) on an identification task, where the same melody was played in similar pitch range and style, asked to name the instrument; there were definite ceiling effects here
- McDermott and Looi (2004) asked CI users to identify 16 different musical instruments in closed-set procedure, recognition scores varied widely; they use a cool figure called a confusion matrix, listing all the instruments that were used on the left, and subject responses on the top; average score for the CI users was 44\% correct, and normal users achieved 97\% correct; CI users identified xylophone, drums, and male singers around 75\% accurately, organ flute and harp were very poorly recognized          
3.3.2. TIMBRE APPRAISAL        
- asked to describe the quality of the music using adjectives, or to assign ratings; the ratings are usually based on subjective descriptors: "pleasantness," "naturalness"
- Gfeller and Lansing (1991) applied a questionnaire (the "Musical Instrument Quality Rating" form) to obtain simple descriptions of the perceived quality of nine instruments
- Gfeller and Lansing (2002b) using rating scales from 0 to 100 on overall pleasantness, and 3 perceptual dimensions: dull-brilliant, compact-scattered, full-empty; implant users rated on average 17 points lower than normal listeners, and this was particularly true of stringed instruments
- Gfeller et al. (2003) used ratings of liking and subjective complexity for cochlear implant users and normal listeners; stimuli were excerpts of music in three genres (classical, country, pop); the scores for overall appraisal given to classical music was significantly lower, and rated pop and country significantly more complex
                  
4. EFFECTS OF TRAINING
(skipped this section for now, may want to go back to it to see what sort of methods they used to assess training so I can apply it to hearing aid users)
          
5. PSYCHOPHYSICAL STUDIES RELEVANT TO MUSIC PERCEPTION        
- perception of rhythm in music is related to the perception of duration of sounds and the gaps between them
- gap detection threshold for simple signals of moderate loudness is usually reported as 10ms (Shannon, 1989, 1993), but for very soft sounds it can be as long as 50ms          
5.1. PERCEPTION OF PITCH                  
5.1.1. INTRODUCTION        
- multiple-channel cochlear implant users perceive pitch in two ways: (rate pitch - rapid temporal fluctuations in electric stimuli, place pitch - position in the cochlea where the electric stimulus is delivered)
- some researchers have argued against place pitch contributing to perceived pitch, in favor of its contribution to perceived timbre (McDermott and McKay, 1997; Moore and Carlyon, 2005)
- ranking - subjects shown two sounds presented in sequence, asked to judge which one has higher pitch (pitch is varied, but that could mean subjects are discriminating based on loudness or timbre)
- pitch experiments can involve scaling - subjects asked to assign numbers in orderly way to the perceived pitch or identification - recognize and label each one of a small number of sounds
- very few studies on judgments of interval size in cochlear implant users          
5.1.2. TEMPORAL PITCH MECHANISMS        
- simplest electric stimuli used by psychophysical researchers on cochlear implants have been sine waves and regular pulse trains, usually delivered to a single cochlear location
- in this section they describe experiments where the pulse rate was changed to produce specific music perceptions, so i skipped most of it          
5.1.3. PITCH ASSOCIATED WITH PLACE OF STIMULATION        
- when frequency of a pure tone presented to an acoustically hearing ear is varied, changes in temporal and spatial patterns of neural excitation occur; at low frequencies, information about frequency is encoded by the temporal patterns, but for higher frequencies it's more likely represented in spatial configuration of nerve fibers that are maximally excited          
5.1.4.         
- did not read in depth past this point because the research was not so relevant to my task},
author = {McDermott, H. J.},
doi = {10.1177/108471380400800203},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/McDermott - 2004 - Music Perception with Cochlear Implants A Review.pdf:pdf},
issn = {1084-7138},
journal = {Trends in Amplification},
month = jun,
number = {2},
pages = {49--82},
title = {{Music Perception with Cochlear Implants: A Review}},
url = {http://tia.sagepub.com/cgi/doi/10.1177/108471380400800203},
volume = {8},
year = {2004}
}
@article{Zeyl2013,
annote = {
        Introduction
        
-other hearing aids are fit qualitatively with prescription formulas
-real world sounds elicit non-linear responses in the auditory nerve of a healthy ear, such as compression, two-tone suppression, synchrony capture and masking in the presence of background noise
-these nonlinear responses become distorted with sensorineural hearing impairment (Yates, 1990; Oxenham et al., 1997)
-neural compensation assumes that the higher neural structures in the auditory pathway are able to use a healthy auditory nerve input.  even though they have likely reorganized due to hearing loss, it is reasonable to assume that they can reorganize back to normal once given a healthy input
-it's the goal of the current study to show that a model-trained NC can perform well when shown novel test sounds
-major improvements to the NC in this study include:
(1) a revised error metric which better compares the healthy and impaired neural codes
(2) a mass-learning methodology which evaluates the entire training set before making updates to ensure good generalization
(3) a preprocessor which applies a trainable phonemic single-band compression
(4) a variant of divisive normalization which acts as a contrast enhancement scheme

        
          
NeuroCompensator Development
3.1 Alopex Development

        -the alopex learning strategy was implemented in Matlab and tested on finding polynomials
-the original version of ALOPEX is listed in this section; sometimes when trying to find polynomials the error would shoot off to huge ranges and was unstable
-the error was related to the direct correlation term in Equation 9
-it is difficult to balance eta and the Error terms
-equations 9 and 14 were changed to increase stability
-following these changes, the modified ALOPEX was able to find the polynomials, and the error steadily decreased
-once the polynomial case worked, Zeyl tested a problem more similar to the NC problem
-in this problem, a matrix of target weights is specified, and the training weights are randomly initialized and trained with ALOPEX to find the target weights, with a squared error term
-Zeyl then included momentum into the ALOPEX equations, which did not significantly affect the speed of learning
-the NC was then developed in Matlab code, first channel-by-channel starting from the highest channel working downwards, row by row, holding the other channels constant
-as channels were learned, the audio was filtered to allow the current channel and any higher channels through
          
3.2 Previous Versions of the NC throughout Development
        
-nc\_02 - mass learning which optimizes one audio segment at a time: similar to the Chen et al. version, which had a small amount of learning for each audio segment
-nc\_03 - NC trains one channel at a time, starting with the highest channel and working down.  on each iteration the highest frequencies to the current channel are presented to the model for Error calculation.  therefore changing the lower frequencies alters the response in the higher frequencies, and the high frequencies don't have a chance to adjust to this.  not a lot of learning is done in this version
-nc\_05 - optimizes channel by channel starting with lowest frequency and going up, and at the end of all 16 frequencies, there are 10 iterations of optimization of all channels simultaneously.  error goes down as the new channels are included.
-nc\_06 is essentially the same as nc\_03 but more audio segments are included.
-nc\_02 was chosen to be the best of these other neural compensation forms, so it was expanded and rewritten to include real audiograms, and a large speech training set
-shown next is a sample of learning profiles at various stages throughout development
-mass learning was adopted
-major changes were made: 1) Contrast Enhancement, DPA, and Single-Band Compression
-not a lot of change was seen between no compression and trainable compression, so Zeyl started looking at fine-timing vs. coarse-timing
-one trial shows coarse timing being optimized while fine-timing error goes up, and vice versa
          
3.3 Final Four Neurocompensators Chosen
        
-eventually all the parameters were chosen except the error metric time resolution and wide band gain
-so the four final versions were <fine, DPA>, <fine, DVN>, <coarse, DPA>, <coarse, DVN>
-all 4 schemes trained well on most of the hearing loss profiles, although some worked better than others
-when fine-timing was the error metric, coarse-timing error was always reduced, but when coarse-timing error was the error metric, fine-timing error was not always reduced
-one interesting result was that when training a fine-time error metric it prescribed lower EQ gains than the trials training a coarse-time error metric
-the coarse-time error metrics prescribed higher gains, and less compression
          
3.4 WIDE-BAND Gain - DVN vs DPA
        
-a major problem involving the wide-band gain processing: Divisive Normalization vs. Inverted Divisive Normalization (Dynamic Power Attenuation)
-the functional form of the NC uses a gain term that watches power interactions across the frequency spectrum, weighting the interactions to prescribe a gain to maximize near-normal frequency response
-this term is either DVN (Schwartz \& Simoncelli, 2001), or DPA
          
3.4.1 DVN
        
Gi = Pi/(sum\_j(vij*Pj) + sigma)
-vij is a square matrix of the weights being trained during neurocompensation to optimze power interactions across frequency bands, sigma is a term to prevent gain from blowing up
-Gi can only attenuate due to constraints on vij
-this function works as a contrast enhancer: if the ith band has more power than the other bands it won't be attenuated much.  if it has a lot less power than the other bands it will be attenuated a lot.
          
-with high frequency hearing loss, obviously it would be best to receive high frequency amplification, but DVN would only prescribe this if the high freqs had more power than the low freqs, so for voiced sounds (generally more power in lower freq than high), i likely would receive less high freq timbre information
-the problem with DVN then is that it attenuates high frequencies when low frequency content is present
          
3.4.2 DPA
        
-DPA is simply DVN with an inverted denominator; it attempts to attenuate frequency areas where there is lots of power, and has the opposite problem of DVN
Gi = 1/(sum\_j(vij*Pi/Pj)+sigma)
-it is a power equalizer as opposed to a contrast enhancer
-generally speech has more energy in the lows, so attenuation of those could be good so that they mask the high frequencies less; at the same time, if i encounter speech with more information in the high frequencies, then DPA will attempt to attenuate the high frequencies, which will not help
          
3.4.3 DPA and DVN Compromises
        
-it would be nice to have the best of both worlds of DPA and DVN; when listening to a vowel with hearing loss at the 2nd formant, we want to attenuate the first formant so it doesn't capture the fibers in the hearing loss region
-a way to do this may be to constrain one triangular region of the vij matrix to 0, either for DPA or DVG
-apparently this does not help
          
3.4.4 Noise
        
-this section examines the effect of noise on the wide-band gain term, suppose we are dealing with LTASS
-DVN will amplify parts of the signal with more power than the noise, which will hopefully extract the signal
-it will do this regardless of the hearing loss profile unless NC was trained with noise
-conversely DPA will bring the signal down to the level of the noise, but if the noise is louder it may reduce the noise
-Zeyl hypothesizes that DPA will work best on a clean signal (reducing upward spread of synchrony), whereas DVN may better extract the speech in a noisy signal

        3.5 Fine-Timing vs. Coarse-Timing
        
-the basic error metric is described in the section "Summary of major changes to the Neurocompensator", which is essentially an absolute difference between healthy and impaired neurograms
-the raw output of the model contains fine-time response information which is important for tracking degree of synchrony capture in the AN, however this information can be ignored by using larger bins and convolving with a hamming window, which tracks the mean discharge rate of the AN fibre at a given time
-the question therefore arises as to what time resolution one should use to compare the healthy and impaired neural responses
-it depends which provides more important information for speech intelligibility or loudness encoding
-if the finest time resolution AN response could be restored, then so could the coarse time responses, but Zeyl found that training on the fine-time resolution error metric was difficult, in that it provided much less gain, and more compression, perhaps because the healthy and impaired responses were out of phase and the NC couldn't adjust the phase, so the only way to reduce error was to lower the overall gain
          
4 Development of Evaluation Schemes
4.1 Neurograms
        
-neurogram is a spatio-temporal discharge pattern in the AN, and displays neural response as a function of fibre CF and Time
-spike timing information can be maintained using a small time bin and convolving each CF with a 32 sample hamming window, and it can be excluded by binning into larger bins and convolving with a 128-sample hamming window
-the differences between the 4 test NCs can be quantified and the best NC can be chosen for any particular error metric, but the problem is it depends on what error metric one uses
-since the evaluation of NCs changes with error metric, Zeyl simply chose the absolute difference as his error metric and tried to find NCs that minimized fine-timing error and coarse-timing error, then he let perceptual tests decide which NC to use
          
4.2 R-HINT-E
        
-allows one to present a sentence binaurally simulated as if being spoken in a real position in a real room with other TIMIT sentences as background noise in other positions
-convolve the impulse response of the room with the sentence and background noise sentences at different positions and sum them together
          
4.3 WDRC Comparison
        
-the standard hearing aid processor to compare the NC against is WDRC
-the original and modified WDRC code is described in this section
-in each channel, the following parameters can be independently adjusted:
1) low-level expansion threshold (Squelch Threshold)
2) channel gain (Gmax)
3) compression threshold
4) compression ratio (CR)
5) compression 'back to linear' threshold (comp. upper threshold)
6) attack and release time constants
-a bunch of details about the implementation
          
4.4 Other Evaluation Tools
5 Major Improvements to the Neurocompensator
        
-big changes to the code were implemented throughout development, to train multiple NCs at a time, using real audiograms, and evaluation of the training through modelling a test set
          
5.1 Improvements to the Neurocompensator Hearing-Aid
5.1.1 Contrast Enhancement
        
-a local contrast enhancement scheme was devised to enhance the vowel formants which can be narrow, and it operates like divisive normalization but in every frequency bin in the DFT, and the contrast is based on the current bin's 6 surrounding bins
-the idea behind the local contrast enhancement comes from the results of Miller et. al (1999), where it was shown CE could improve repesentation of vowels in the HI AN
          
5.1.2 Wide-Band Dynamic Power Attenuation
        
-the idea of DPA is to turn down gain in the low frequencies to avoid upward spread of synchrony
          
5.1.3 Phonemic Single-Band Compression
        
-included as a preprocessor to the NC
-based on a multi-band compression scheme from Philippe Pango
          
5.1.4 Equivalent Rectangular Bandwidth
        
-one major improvement came from incorporating each band in DVN to be the width of one ERB (Glasberg and Moore, 1990)
          
5.1.5 Temporal Smoothing
        
-applied to the CE, and in a similar way that attack and decay are applied to single-band compression
-the smoothing does give the formant enhancement a smooth shape
          
5.2 Improvements to the Neural Compensation Method
5.2.1 TIMIT Database

        -this database was used as the main training set for Neurocompensation, which has 630 speakers speaking 10 sentences, divided into training and testing sets, with speakers of different dialects
-gave two options for the NC: TIMIT sentences could be randomly chosen based on used defined number of audio segments and length of audio segment, or a number of phones could be randomly chosen from the entire TIMIT set based on type of phone desired (vowel, fricative), and number of phones per audio segment
          
5.2.2 Training in Noise
        
-the noise is included in the signal presented to the NC and then the model of the impaired ear, and the noise is not included in the signal presented to the healthy ear; in this way the NC has a chance to adjust parameters to do noise removal
          
5.2.3 Revision of Error Metric
        
-instead of an onset detector and probabilistic measure of clustering in the neurogram, Zeyl uses an absolute difference between AN responses (both fine and coarse-time metrics)
          
5.2.4 Mass Learning
        
-implements mass learning
-instead of training the NC for a given number of iterations on one sentence, then moving on to the next as Chen et al. (2005), this version evaluates all sentences in the training set, takes an average, then prescribes a change with ALOPEX, which provides greater generalization
          
5.2.5 ALOPEX
        
-described in Section 3.1
-also implemented ALOPEX for all blocks of gain; if one or more blocks is performing poorly, ALOPEX minimizes its contribution to overall gain},
author = {Zeyl, Timothy},
doi = {10.1111/febs.12167},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Hearing Aids and Hearing Loss/Neuro-Compensator/Zeyl-NCreport.pdf:pdf},
issn = {1742-4658},
journal = {The FEBS journal},
month = feb,
number = {4},
pages = {1168},
pmid = {23414330},
title = {{NeuroComp Developments}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23414330},
volume = {280},
year = {2013}
}
@article{Schneider1999,
abstract = {Twenty normal hearing younger and twenty older adults in the early stages of presbycusis, but with relatively normal hearing at 2 kHz, were asked to discriminate between the presence versus absence of a gap between two equal-duration tonal markers. The duration of each marker was constant within a block of trials but varied between 0.83 and 500 ms across blocks. Notched-noise, centered at 2 kHz, was used to mask on- and off-transients. Gap detection thresholds of older adults were markedly higher than those of younger adults for marker durations of less than 250 ms but converged on those of younger adults at 500 ms. For both age groups, gap detection thresholds were independent of audiometric thresholds. These results indicate that older adults have more difficulty detecting a gap than younger adults when short marker durations (i.e., durations characteristic of speech sounds) are employed. It is shown that these results cannot be explained by linear models of temporal processing but are consistent with differential adaptation effects in younger and older adults.},
annote = {        Introduction        
- older adults with normal thresholds complain about comprehension in a variety of situations
- Pichora-Fuller (1997) showed that these kinds of adults in particular have trouble in noisy environments, especially with multiple talkers
- several investigators have argued this is due to hearing loss (Humes, 1996; van Rooij and Plomp, 1990, 1992), and others have suggested it's due to other auditory processes (Bergman, 1980; Duquesnoy, 1983; Plomp, 1986; Schneider, 1997)
- recent evidence (Lutman, 1991; Stuart and Phillips, 1996; Schneider, 1997) suggests one of the factors contributing is loss of temporal resolution
- gap detection thresholds are elevated in those with hearing loss relative to normals (Irwin et al., 1981; Fitzgibbons and Wightman, 1982; Tyler et al., 1982; Florentine and Buus, 1984; Buus and Florentine, 1985; Fitzgibbons and Gordon-Salant, 1987; Glasberg et al., 1987; Irwin and McAuley, 1987; Long and Cullen, 1988; Moore and Glasberg, 1988; Moore et al., 1989)
- evidence for age-related changes in temporal resolution independent of hearing loss is equivocal: Moore et al. (1992) showed that older adults with normal hearing thresholds had similar gap thresholds to younger adults
- however, Schneider et al. (1994) and Snell (1997) found significant age effects in gap detection in older and younger subjects with good hearing (mind you, these used shorter duration markers, which likely lead Schneider et al. to pursue the current study's hypothesis)
- the 3 studies differed in 4 ways: 1) tones vs. noise, 2) marker duration, 3) gating of the stimulus, 4) presence of masking noise
- the present study investigated to what extent these factors influenced the results},
author = {Schneider, B a and Hamstra, S J},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1999 (Schneider, Hamstra) - Gap detection thresholds as function of tonal duration for younger and older listeners.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Adult,Age Factors,Aged,Aging,Aging: physiology,Audiometry,Audiometry: methods,Auditory Threshold,Auditory Threshold: physiology,Humans,Neurons,Neurons: physiology,Speech Perception,Speech Perception: physiology,Time Factors},
month = jul,
number = {1},
pages = {371--80},
pmid = {10420628},
title = {{Gap detection thresholds as a function of tonal duration for younger and older listeners.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10420628},
volume = {106},
year = {1999}
}
@article{Moore2010a,
abstract = {A method for fitting multichannel compression hearing aids with an extended high-frequency response, called CAMEQ2-HF, was described by . This study describes an evaluation of the method, using a 16-channel behind the ear hearing aid incorporating slow-acting compression and providing gain for frequencies up to 7500 Hz.},
author = {Moore, Brian C J and F\"{u}llgrabe, Christian},
doi = {10.1097/AUD.0b013e3181e1cd0d},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Hearing Aids and Hearing Loss/Fitting Procedures/2010 (Moore, Fullgrabe) - Evaluation of the CAMEQ2-HF Method.pdf:pdf},
issn = {1538-4667},
journal = {Ear and hearing},
keywords = {Aged,Female,Hearing Aids,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: therapy,Humans,Loudness Perception,Male,Medical Records,Middle Aged,Patient Satisfaction,Prosthesis Design,Prosthesis Fitting,Prosthesis Fitting: methods,Severity of Illness Index,Speech Perception},
month = oct,
number = {5},
pages = {657--66},
pmid = {20526199},
title = {{Evaluation of the CAMEQ2-HF method for fitting hearing aids with multichannel amplitude compression.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20526199},
volume = {31},
year = {2010}
}
@article{Keidser2006,
abstract = {This study examined the effect that signal processing strategies used in modern hearing aids, such as multi-channel WDRC, noise reduction, and directional microphones have on interaural difference cues and horizontal localization performance relative to linear, time-invariant amplification. Twelve participants were bilaterally fitted with BTE devices. Horizontal localization testing using a 360 degrees loudspeaker array and broadband pulsed pink noise was performed two weeks, and two months, post-fitting. The effect of noise reduction was measured with a constant noise present at 80 degrees azimuth. Data were analysed independently in the left/right and front/back dimension and showed that of the three signal processing strategies, directional microphones had the most significant effect on horizontal localization performance and over time. Specifically, a cardioid microphone could decrease front/back errors over time, whereas left/right errors increased when different microphones were fitted to left and right ears. Front/back confusions were generally prominent. Objective measurements of interaural differences on KEMAR explained significant shifts in left/right errors. In conclusion, there is scope for improving the sense of localization in hearing aid users.},
author = {Keidser, Gitte and Rohrseitz, Kristin and Dillon, Harvey and Hamacher, Volkmar and Carter, Lyndal and Rass, Uwe and Convery, Elizabeth},
doi = {10.1080/14992020600920804},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Sound Localization/2006 - The effect of multi-channel WDRC, noise reduction, directional microphone on horizontal localization performance.pdf:pdf},
issn = {1499-2027},
journal = {International journal of audiology},
keywords = {Adult,Aged,Female,Hearing Aids,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: rehabilitation,Humans,Male,Middle Aged,Prosthesis Design,Regression Analysis,Sound Localization,Speech Perception,Treatment Outcome},
month = oct,
number = {10},
pages = {563--79},
pmid = {17062498},
title = {{The effect of multi-channel wide dynamic range compression, noise reduction, and the directional microphone on horizontal localization performance in hearing aid wearers.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17062498},
volume = {45},
year = {2006}
}
@article{Oxenham2008,
abstract = {Pitch is important for speech and music perception, and may also play a crucial role in our ability to segregate sounds that arrive from different sources. This article reviews some basic aspects of pitch coding in the normal auditory system and explores the implications for pitch perception in people with hearing impairments and cochlear implants. Data from normal-hearing listeners suggest that the low-frequency, low-numbered harmonics within complex tones are of prime importance in pitch perception and in the perceptual segregation of competing sounds. The poorer frequency selectivity experienced by many hearing-impaired listeners leads to less access to individual harmonics, and the coding schemes currently employed in cochlear implants provide little or no representation of individual harmonics. These deficits in the coding of harmonic sounds may underlie some of the difficulties experienced by people with hearing loss and cochlear implants, and may point to future areas where sound representation in auditory prostheses could be improved.},
author = {Oxenham, Andrew J},
doi = {10.1177/1084713808325881},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Oxenham - 2008 - Pitch perception and auditory stream segregation implications for hearing loss and cochlear implants.pdf:pdf},
issn = {1084-7138},
journal = {Trends in amplification},
keywords = {Auditory Threshold,Cochlear Implants,Hearing Impaired Persons,Hearing Loss,Hearing Loss: physiopathology,Hearing Loss: rehabilitation,Humans,Perceptual Masking,Pitch Perception,Prosthesis Design,Rehabilitation of Hearing Impaired,Sound Spectrography,Speech Perception,Time Perception},
month = dec,
number = {4},
pages = {316--31},
pmid = {18974203},
title = {{Pitch perception and auditory stream segregation: implications for hearing loss and cochlear implants.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2901529\&tool=pmcentrez\&rendertype=abstract},
volume = {12},
year = {2008}
}
@article{Rahne2010,
abstract = {The identification and discrimination of timbre are essential features of music perception. As timbre differences appear as multidimensional cues, the spectral shape, the spectral fluctuation, and the rise time are the most dominating parameters of timbre in normal-hearing listeners. We developed a psychoacoustical test to determine the timbre discrimination abilities using only the spectral difference as a cue. Therefore, a synthetically generated tone continuum was used in an adaptive alternative forced choice paradigm. The spectral difference was modified by cross-fading the tones adaptively, depending on the listeners' response which allows very precise determinations of the just noticeable difference (JND). We measured the JND for the spectral difference with 18 normal-hearing listeners. The results confirm the applicability of the test to measure timbre discrimination with the spectral difference as solely cue. Further, the portability of the test to further dimensions of timbre is discussed.},
author = {Rahne, Torsten and Rasinski, Christine and Neumann, Kerstin},
doi = {10.1016/j.jneumeth.2010.03.023},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rahne, Rasinski, Neumann - 2010 - Measuring timbre discrimination with cross-faded synthetic tones.pdf:pdf},
issn = {1872-678X},
journal = {Journal of neuroscience methods},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Auditory Perception,Discrimination (Psychology),Humans,Psychoacoustics,Psychophysics,Psychophysics: methods,Sensory Thresholds,Young Adult},
month = jun,
number = {2},
pages = {176--9},
pmid = {20350567},
publisher = {Elsevier B.V.},
title = {{Measuring timbre discrimination with cross-faded synthetic tones.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20350567},
volume = {189},
year = {2010}
}
@article{Killion2004,
author = {Killion, Mead C. and Niquette, Patricia a. and Gudmundsen, Gail I. and Revit, Lawrence J. and Banerjee, Shilpi},
doi = {10.1121/1.1784440},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Speech-In-Noise Tests/2004 (Killion, Niquette, Gudmundsen, Revit, Banerjee) - Development of QuickSIN.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {4},
pages = {2395},
title = {{Development of a quick speech-in-noise test for measuring signal-to-noise ratio loss in normal-hearing and hearing-impaired listeners}},
url = {http://link.aip.org/link/JASMAN/v116/i4/p2395/s1\&Agg=doi},
volume = {116},
year = {2004}
}
@article{VanDenBogaert2006,
author = {{Van Den Bogaert}, Tim and Klasen, Thomas J. and Moonen, Marc and {Van Deun}, Lieselot and Wouters, Jan},
doi = {10.1121/1.2139653},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Sound Localization/2006 - Horizontal localization with bilateral hearing aids- Without is better than with.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {1},
pages = {515},
title = {{Horizontal localization with bilateral hearing aids: Without is better than with}},
url = {http://link.aip.org/link/JASMAN/v119/i1/p515/s1\&Agg=doi},
volume = {119},
year = {2006}
}
@article{Giraudi-Perry1982,
author = {Giraudi-Perry, DM and Salvi, RJ and Henderson, D},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1982 (Giraudi-Perry, Salvi, Henderson) - Gap detection in hearing-impaired chinchillas.pdf:pdf},
journal = {The Journal of the Acoustical Society of America},
number = {5},
pages = {1387--1393},
title = {{Gap detection in hearing-impaired chinchillas}},
url = {http://link.aip.org/link/?JASMAN/72/1387/1},
volume = {72},
year = {1982}
}
@article{Gfeller2002,
author = {Gfeller, K and Witt, S and Woodworth, G},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gfeller, Witt, Woodworth - 2002 - Effects of frequency, instrumental family, and cochlear implant type on timbre recognition and appraisal.pdf:pdf},
journal = {The Annals of otology, rhinology \& laryngology},
pages = {349--356},
title = {{Effects of frequency, instrumental family, and cochlear implant type on timbre recognition and appraisal.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11991588},
volume = {111},
year = {2002}
}
@article{Zendel2011,
abstract = {Age-related decline in auditory perception reflects changes in the peripheral and central auditory systems. These age-related changes include a reduced ability to detect minute spectral and temporal details in an auditory signal, which contributes to a decreased ability to understand speech in noisy environments. Given that musical training in young adults has been shown to improve these auditory abilities, we investigated the possibility that musicians experience less age-related decline in auditory perception. To test this hypothesis we measured auditory processing abilities in lifelong musicians (N = 74) and nonmusicians (N = 89), aged between 18 and 91. Musicians demonstrated less age-related decline in some auditory tasks (i.e., gap detection and speech in noise), and had a lifelong advantage in others (i.e., mistuned harmonic detection). Importantly, the rate of age-related decline in hearing sensitivity, as measured by pure-tone thresholds, was similar between both groups, demonstrating that musicians experience less age-related decline in central auditory processing. (PsycINFO Database Record (c) 2011 APA, all rights reserved).},
author = {Zendel, Benjamin Rich and Alain, Claude},
doi = {10.1037/a0024816},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/2011 (Zendel, Alain) - Musicians Experience Less Age-Related Decline in Central Auditory Processing.pdf:pdf},
issn = {1939-1498},
journal = {Psychology and aging},
keywords = {10,30,aging,auditory processing,auditory-based communication problems are,by,by age 60,criteria for moderate hearing,elderly,loss,musician,of,people meet the diagnostic,prevalent in the,worldwide estimates indicate that},
month = sep,
pmid = {21910546},
title = {{Musicians experience less age-related decline in central auditory processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21910546},
year = {2011}
}
@article{Bruce2003,
author = {Bruce, Ian C. and Sachs, Murray B. and Young, Eric D.},
doi = {10.1121/1.1519544},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Hearing Aids and Hearing Loss/Neuro-Compensator/2003 - An auditory-periphery model of the effects of acoustic trauma on auditory nerve responses.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {1},
pages = {369},
title = {{An auditory-periphery model of the effects of acoustic trauma on auditory nerve responses}},
url = {http://link.aip.org/link/JASMAN/v113/i1/p369/s1\&Agg=doi},
volume = {113},
year = {2003}
}
@article{Moore2000,
abstract = {Hearing impairment may sometimes be associated with complete loss of inner hair cells (IHCs) over a certain region of the basilar membrane. We call this a 'dead region'. Amplification (using a hearing aid) over a frequency range corresponding to a dead region may not be beneficial and may even impair speech intelligibility. However, diagnosis of dead regions is not easily done from the audiogram. This paper reports the design and evaluation of a method for detecting and delimiting dead regions. A noise, called 'threshold equalizing noise' (TEN), was spectrally shaped so that, for normally hearing subjects, it would give equal masked thresholds for pure tone signals at all frequencies within the range 250-10,000 Hz. Its level is specified as the level in a one-ERB (132 Hz) wide band centred at 1000 Hz. Measurements obtained from 22 normal-hearing subjects and TEN levels of 30, 50 and 70 dB/ERB confirmed that the signal level at masked threshold was approximately equal to the noise level/ERB and was almost independent of signal frequency. Masked thresholds were measured for 20 ears of 14 subjects with sensorineural hearing loss, using TEN levels of 30, 50 and 70 dB/ERB. Psychophysical tuning curves (PTCs) were measured for the same subjects. When there are surviving IHCs corresponding to a frequency region with elevated absolute thresholds, a signal in that frequency region is detected via IHCs with characteristic frequencies (CFs) close to that region. In such a case, threshold in the TEN is close to that for normal-hearing listeners, provided that the noise intensity is sufficient to produce significant masking. Also, the tip of the PTC lies close to the signal frequency. When a dead region is present, the signal is detected via IHCs with CFs different from that of the signal frequency. In such a case, threshold in the TEN is markedly higher than normal, and the tip of the PTC is shifted away from the signal frequency. Generally, there was a very good correspondence between the results obtained using the TEN and the PTCs. We conclude that the measurement of masked thresholds in TEN provides a quick and simple method for the diagnosis of dead regions.},
annote = {        General Notes        
- tried to understand this, the methods section was very difficult and I couldn't picture exactly what they were talking about, so I decided to invest my time elsewhere          
          
dead region - complete loss of inner hair cells along the basilar membrane
- diagnosis of dead regions is not easily done from the audiogram
- amplification of a dead region may not be beneficial and could impair speech inteliigiblity
                  
threshold equalizing noise (TEN) - spectrally shaped noise so that for normal hearing subjects it gives equal masked thresholds for all pure tone signals at frequencies between 250-10000 Hz
- TEN's level is specified as the level in one-ERB (132 Hz) wide band centred at 1000 Hz
                  
Introduction        
- damage to OHC impairs the active mechanism, reducing the amount of vibration in the basilar membrane for a low sound level
- damage to IHC can reduce the efficiency of transduction
- total sensorineural hearing loss is the sum of IHC and OHC loss
- Moore\&Glasberg (1997), Moore et al. (1999) have ways of estimating IHC and OHC damage
- apparently hearing loss due to OHC loss is at most 50dB for low frequencies and 65dB for high frequencies (Yates, 1990, 1995, Ruggero et al. (1997)
- we may underestimate the length of dead regions, because IHCs outside of the dead region respond to frequencies inside the dead region as a result of the shape of their psychophysical tuning curve          
off-frequency listening - tones with frequencies in a dead region are detected by neurons with CFs remote from the signal frequency
- OHC loss corresponds to a loss of frequency selectivity -- typically 2-3 times greater than normally hearing listeners, and never more than about 3.8 times greater than normal (Moore \& Glasberg, 1997)
- when a signal frequency falls in a dead region, the tip of a PTC is shifted away from the signal frequency -- the tip is expected to fall at the boundary of a dead region
- hypothesis was that higher than normal thresholds for TEN would always coincide with shifted PTC tips, and would confirm that TEN can be used to diagnose dead regions
                  
Method
        - power of signal at threshold; Ps = N0 * K * ERB
N0 is noise power spectral density
K is signal-to-noise ratio at the output of the auditory filter required for threshold
ERB is the equivalent rectangular bandwidth of the auditory filter
TEN was spectrally shaped so Ps was constant over the frequency range of 125Hz to 15000Hz
- I found this section extremely confusing          
          
Results
          
          
TEN        
- present sinusoids with broadband noise, designed to produce equal masked thresholds over a wide frequency range for normally hearing listeners and those with hearing impairments but without dead regions - an abnormally high masked threshold at a given frequency indicates a dead region
- results from the TEN test are compared to psychophysical tuning curves (Chistovich, 1957; Small, 1959)
      },
author = {Moore, B C and Huss, M and Vickers, D a and Glasberg, B R and Alc\'{a}ntara, J I},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/TEN Test/1999 - A test for the diagnosis of dead regions in the cochlea.pdf:pdf},
issn = {0300-5364},
journal = {British journal of audiology},
keywords = {Aged,Aged, 80 and over,Audiometry, Pure-Tone,Auditory Threshold,Auditory Threshold: physiology,Cochlea,Cochlea: physiopathology,Hair Cells, Auditory, Inner,Hair Cells, Auditory, Inner: pathology,Hearing Aids,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: diagnosis,Hearing Loss, Sensorineural: physiopathology,Hearing Loss, Sensorineural: rehabilitation,Humans,Middle Aged,Noise,Noise: adverse effects,Perceptual Masking,Psychophysics,Psychophysics: methods,Severity of Illness Index},
month = aug,
number = {4},
pages = {205--24},
pmid = {10997450},
title = {{A test for the diagnosis of dead regions in the cochlea.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18344872},
volume = {34},
year = {2000}
}
@misc{TheMendeleySupportTeam2010,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2010}
}
@article{Snell2000,
abstract = {The relationships among age-related differences in gap detection and word recognition in subjects with normal hearing or mild sensorineural hearing loss were explored in two studies. In the first study, gap thresholds were obtained for 40 younger and 40 older subjects. The gaps were carried by 150-ms, modulated, low-pass noise bursts with cutoff frequencies of 1 or 6 kHz. The noise bursts were presented at an overall level of 80 dB SPL in three background conditions. Mean gap thresholds ranged between 2.6 and 7.8 ms for the younger age group and between 3.4 and 10.0 ms for the older group. Mean gap thresholds were significantly larger for the older group in all six conditions. Gap thresholds were not significantly correlated with audiometric thresholds in either age group but the 1-kHz gap thresholds increased with age in the younger group. In the second study, the relationships among gap thresholds, spondee-in-babble thresholds, and audiometric thresholds of 66 subjects were examined. Compared with the older subjects, the younger group recognized the spondees at significantly lower (more difficult) spondee-to-babble ratios. In the younger group, spondee-in-babble thresholds were significantly correlated with gap thresholds in conditions of high-frequency masking. In the older group, spondee-in-babble thresholds, gap thresholds, and audiometric thresholds were not significantly correlated, but the spondee-in-babble thresholds and two audiometric thresholds increased significantly with age. These results demonstrate that significant age-related changes in auditory processing occur throughout adulthood. Specifically, age-related changes in temporal acuity may begin decades earlier than age-related changes in word recognition.},
author = {Snell, K B and Frisina, D R},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1999 (Snell, Frisina) - Relationships among age-related differences in gap detection and word recognition.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Adolescent,Age Factors,Aged,Aged, 80 and over,Aging,Aging: physiology,Auditory Threshold,Auditory Threshold: physiology,Female,Humans,Male,Middle Aged,Speech Perception,Speech Perception: physiology,Vocabulary},
month = mar,
number = {3},
pages = {1615--26},
pmid = {10738815},
title = {{Relationships among age-related differences in gap detection and word recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10738815},
volume = {107},
year = {2000}
}
@article{Smith1994,
abstract = {Previous studies have shown that a random-dot kinematogram (RDK) comprising dots, each of which takes a random walk in direction or speed over time, can appear to flow in a single direction. This has been interpreted as evidence for the existence of a co-operative network linking neurons sensitive to different directions/speeds and different spatial locations. We have investigated the possibility that global motion perception in such patterns might simply reflect motion energy detection at a coarse spatial scale (such that many dots fall in the receptive field of one energy detector) without the need to encode local dot motions on a fine spatial scale and then integrate their motions over space. We created random-walk RDKs and then spatially high-pass filtered them to remove low spatial frequencies. Perception of global motion was unimpaired for both direction and speed random walks, showing that the phenomenon is not reliant on low spatial frequencies and must, therefore, involve integration of local motion signals across space, as originally postulated.},
author = {Smith, a T and Snowden, R J and Milne, a B},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/PSYCH 720/Unit 3/Paper 1/1993 - Is global motion really based on spatial integration of local motion signals.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Discrimination (Psychology),Discrimination (Psychology): physiology,Humans,Motion Perception,Motion Perception: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Psychometrics,Time Factors},
month = sep,
number = {18},
pages = {2425--30},
pmid = {7975281},
title = {{Is global motion really based on spatial integration of local motion signals?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7975281},
volume = {34},
year = {1994}
}
@article{Chrostowski2011,
abstract = {Travelling waves of activity in neural circuits have been proposed as a mechanism underlying a variety of neurological disorders, including epileptic seizures, migraine auras and brain injury. The highly influential Wilson-Cowan cortical model describes the dynamics of a network of excitatory and inhibitory neurons. The Wilson-Cowan equations predict travelling waves of activity in rate-based models that have sufficiently reduced levels of lateral inhibition. Travelling waves of excitation may play a role in functional changes in the auditory cortex after hearing loss. We propose that down-regulation of lateral inhibition may be induced in deafferented cortex via homeostatic plasticity mechanisms. We use the Wilson-Cowan equations to construct a spiking model of the primary auditory cortex that includes a novel, mathematically formalized description of homeostatic plasticity. In our model, the homeostatic mechanisms respond to hearing loss by reducing inhibition and increasing excitation, producing conditions under which travelling waves of excitation can emerge. However, our model predicts that the presence of spontaneous activity prevents the development of long-range travelling waves of excitation. Rather, our simulations show short-duration excitatory waves that cancel each other out. We also describe changes in spontaneous firing, synchrony and tuning after simulated hearing loss. With the exception of shifts in characteristic frequency, changes after hearing loss were qualitatively the same as empirical findings. Finally, we discuss possible applications to tinnitus, the perception of sound without an external stimulus.},
author = {Chrostowski, Michael and Yang, Le and Wilson, Hugh R and Bruce, Ian C and Becker, Suzanna},
doi = {10.1007/s10827-010-0256-1},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Tinnitus/Chrostowski paper.pdf:pdf},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {Acoustic Stimulation,Action Potentials,Action Potentials: physiology,Animals,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Computer Simulation,Hearing Loss,Hearing Loss: pathology,Hearing Loss: physiopathology,Homeostasis,Homeostasis: physiology,Models, Neurological,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology},
month = apr,
number = {2},
pages = {279--99},
pmid = {20623168},
title = {{Can homeostatic plasticity in deafferented primary auditory cortex lead to travelling waves of excitation?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20623168},
volume = {30},
year = {2011}
}
@article{Krishnan2009,
abstract = {A behavioral measure of the basilar membrane response can be obtained by comparing the growth in forward masking for maskers at, and well below, the signal frequency. Since the off-frequency masker is assumed to be processed linearly at the signal place, the difference in masking growth with level is thought to reflect the compressive response to the on-frequency masker. The present experiment used an electrophysiological analog of this technique, based on measurements of the latency of wave V of the auditory brainstem response elicited by a 4-kHz, 4-ms pure tone, presented at 65 dB SPL. Responses were obtained in quiet and in the presence of either an on-frequency (4 kHz) or an off-frequency (1.8 kHz) pure-tone forward masker. Wave V latency increased with masker level, although the increase was greater for the off-frequency masker than for the on-frequency masker, consistent with a more compressive response to the latter. Response functions generated from the data showed the characteristic shape, with a nearly linear response at lower levels and 4:1 compression at higher levels. However, the breakpoint between the linear region and the compressive region was at about 60 dB SPL, higher than expected on the basis of previous physiological and psychophysical measures.},
annote = {        <Introduction>        
-tones presented well below the CF give more linear BM response than those at CF [references]
-the same is true of auditory nerve fiber rate level functions (at and below CF) [references]
-psychophysical studies on humans have shown similar responses with behavioural measures of BM nonlinearity (growth of forward masking, pulsation threshold, temporal masking curves, masking additivity)
-in contrast to compression CF response, at high CFs the response to tones well below CF is almost linear over the entire dynamic range (little gain)
-damage to the cochlea, the OHCs, results in reduction in sensitivity and compression at CF [Ruggero, Rich]
-for those with SNHL, therefore, it would be useful to have behavioural measures of BM nonlinearity, and this study proposes an electrophysiological measure
-another way to measure the BM response is with DPOAEs [Dorn et al., 2001; Gorga et al, 2007]
-the DPOAE method presents f1 and f2 at L1 and L2, varying L2, looking at 2f1-f2 and estimating the BM IO function, but this method is susceptible to middle ear pathology and a HL greater than 25 dB
-the authors' method derives from forward-masking where growth of forward masking for on- and off-frequency maskers are compared to estimate the BM nonlinearity; it measures wave V of the ABR, which represents neural activity in lateral lemniscus/IC synchronized to a brief sound [reference]
-in the present study, the magnitude of the latency shift of wave V as a function of masker level is compared for on- and off-freq maskers
-authors decided to use wave V because there is little variability and it is reliable [references], and because it is a sensitive index of the forward-masking effects on ABR components [references]
-wave V increases in latency with more intense maskers, and less time between masker and probe [references]
-in contrast, wave V has large inter-sub and intra-sub variability in amplitude, especially with masking
-it is thought that the wave V latency in forward-masking reflects receptor adaptation and poststimulus recovery from this adaptation, presumably at the hair cell-nerve junction [references]
-adaptation is thought to elevate threshold of the cochlear excitatory process
                  
<Methods>        
-100ms masker tone (either 1.8 or 4 kHz) followed by 5ms silence then 4ms probe tone (4 kHz)
-level of masker fluctuated in 5 dB increments from 50-85 dB, and probe tone was 65 dB
-also a quiet condition in which only probe was presented
-all stim were cosine-squared gated to reduce spectral splatter
-10 subjects were young with normal hearing
-responses evaluated by manually marking the positive peak of wave V relative to onset of probe tone
-latency shift relative to quiet was calculated for all conditions, and growth of masking functions were generated for the on- and off-freq maskers (mean latency shift as a function of masker level)
-using the growth of masking functions, the BM IO function was derived
-the 3 different test conditions were randomized both within and across subjects
                  
<Results>                  
Characteristics of Latency Change        
-latency increase of wave V is greater for on-frequency condition, but this difference is less apparent for masker levels > 70 dB SPL
-no sig dif for masker levels between 60-80 for on-frequency masker, suggesting compression, however, latency continued to shift for off-frequency maskers adjusted at these levels, converging upon the on-frequency masker curve          
Derivation of BM IO Function        
-used latency data to generate BM IO function for tone at CF, using a few assumptions:
1) the delay of wave V from the probe tone depends on the BM response to the masker at CF
2) for a masker well below the CF, the BM response at the probe place is linear; so the off-frequency masker level estimates the BM response needed to produce the resulting wave V delay E = M\_off + c, where E=BM response, M\_off=off-freq masker level, c=constant
3) BM response at the signal place is some function, f, of the on-freq masker level (M\_on); E = f(M\_on)
so M\_off = f(M\_on) - c
-if one then plots off-freq masker level versus on-freq masker level to produce equal wave V delay, this describes the IO function, and this same reasoning has been used to derive BM IO from behavioural data [references]
-3rd order polynomials were fit to the data which described the data immensely well (R\^{}2 = 0.99)
-8 of 10 subjects show the compressive nonlinearity
-Plack et al (2004) report substantial variability in compressive slopes of the BM for hearing impaired listeners
                  
<Discussion>        
-the shape and compression ratio observed in this study (4:1) agrees with physiological and psychoacoustical measures of BM nonlinearity [references]
-the kneepoint was higher in this study, and one possible explanation is because of the low gain for the broken stick fits, and possibly upward spread of excitation (fibers >4000Hz responding to the probe--Oxenham and Plack [1997] reduced this effect using high-pass noise)
-it is unlikely that the shift in the IO function to a higher level is due solely to upward spread of excitation, since probe tones are place specific to within half an octave of the nominal freq of the stimulus [references]
-a more plausible explanation in the kneepoint shift is the role of medial efferents in attenuating the response and increase sensitivity of the BM
-the upward shift may be due to activation of the medial efferents due to high duty cycle of stimulus presentation
-the ABR wave V latency shows very little intersubject variability, but the medial efferent reflex has much variability (it serves as a protective, dynamic range adjustment, and enhancer for signals in noise [references])
-Patuzzi (1998) has looked at threshold shifts due to sound exposure, and is thought to be caused by adaptation of the OHC active process, reducing gain
-along with scalp recorded ABR, can also obtain CAP simultaneously
-many studies have shown increasing latency in wave V over the course of the experiment [references]
-in forward masking, wave I and wave V recover linearly proportional to log(deltaT), where deltaT is the time between probe and masker
-Golga et al [1983] showed that peripheral frequency selectivity can be estimated from wave V amplitude
-some other groups [references] have used CAP and ABR wave V to measure frequency selectivity, and the results of the different methods are very similar
                  
<Implications>        
-finding suggests that an electrophysiological response of the BM is possible, and may be more efficient in terms of the time/reliability trade-off than behavioural measures},
author = {Krishnan, Ananthanarayan and Plack, Christopher J},
doi = {10.1159/000158537},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/ABRs/2008 (Krishnan, Plack) - ABR correlates of BM nonlinearity.pdf:pdf},
issn = {1421-9700},
journal = {Audiology \& neuro-otology},
keywords = {Basilar Membrane,Basilar Membrane: physiology,Cochlear Nucleus,Cochlear Nucleus: physiology,Evoked Potentials, Auditory, Brain Stem,Evoked Potentials, Auditory, Brain Stem: physiolog,Hearing,Hearing: physiology,Humans,Models, Neurological,Nonlinear Dynamics,Reaction Time,Reaction Time: physiology,Young Adult},
month = jan,
number = {2},
pages = {88--97},
pmid = {18827479},
title = {{Auditory brainstem correlates of basilar membrane nonlinearity in humans.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18827479},
volume = {14},
year = {2009}
}
@article{Looi2008,
abstract = {To investigate the music perception skills of adult cochlear implant (CI) users in comparison with hearing aid (HA) users who have similar levels of hearing impairment. It was hypothesized that the HA users would perform better than the CI recipients on tests involving pitch, instrument, and melody perception, but similarly for rhythm perception.},
author = {Looi, Valerie and McDermott, Hugh and McKay, Colette and Hickson, Louise},
doi = {10.1097/AUD.0b013e31816a0d0b},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Looi et al. - 2008 - Music perception of cochlear implant users compared with that of hearing aid users.pdf:pdf},
issn = {0196-0202},
journal = {Ear and hearing},
keywords = {Adult,Aged,Auditory Perception,Cochlear Implants,Deafness,Deafness: rehabilitation,Female,Hearing Aids,Hearing Tests,Hearing Tests: methods,Humans,Male,Middle Aged,Music,Pitch Discrimination,Psychoacoustics,Sound Spectrography,Time Perception},
month = jun,
number = {3},
pages = {421--34},
pmid = {18344870},
title = {{Music perception of cochlear implant users compared with that of hearing aid users.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18344870},
volume = {29},
year = {2008}
}
@article{Valente1995,
author = {Valente, M. and Fabry, DA and Potts, LG},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Speech-In-Noise Tests/1995 (Valente, Fabry, Potts) - Recognition of Speech in Noise with Hearing Aids Using Dual-Microphones.pdf:pdf},
journal = {Journal of the American Academy of Audiology},
number = {6},
pages = {440},
title = {{Recognition of speech in noise with hearing aids using dual microphones.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8580504},
volume = {6},
year = {1995}
}
@article{Glasberg1987,
abstract = {Subjects with cochlear impairments often show reduced temporal resolution as measured in gap-detection tasks. The primary goals of these experiments were: to assess the extent to which the enlarged gap thresholds can be explained by elevations in absolute threshold; and to determine whether the large gap thresholds can be explained by the same processes that lead to a slower-than-normal recovery from forward masking. In experiment I gap thresholds were measured for nine unilaterally and eight bilaterally impaired subjects, using bandlimited noise stimuli centered at 0.5, 1.0, and 2.0 kHz. Gap thresholds were usually larger for the impaired ears, even when the comparisons were made at equal sensation levels (SLs). Gap thresholds tended to increase with increasing absolute threshold, but the scatter of gap thresholds was large for a given degree of hearing loss. In experiment II threshold was measured as a function of the delay between the onset of a 210-ms masker and the onset of a 10-ms signal in both simultaneous- and forward-masking conditions. The signal frequency was equal to the center frequency of the bandlimited noise masker, which was 0.5, 1.0, or 2.0 kHz. Five subjects with unilateral cochlear impairments, two subjects with bilateral impairments, and two normal subjects were tested. The rate of recovery from forward masking, particularly the initial rate, was usually slower for the impaired ears, even when the maskers were presented at equal SLs. Large gap thresholds tended to be associated with slow rates of recovery from forward masking.},
author = {Glasberg, B R and Moore, B C and Bacon, S P},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1987 (Glasberg, Moore, Bacon) - Gap detection and masking in hearing-impaired and normal-hearing subjects.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Acoustic Stimulation,Adolescent,Adult,Aged,Auditory Threshold,Cochlea,Cochlea: physiology,Cochlea: physiopathology,Female,Hearing Loss,Hearing Loss: physiopathology,Humans,Male,Middle Aged,Reference Values},
month = may,
number = {5},
pages = {1546--56},
pmid = {3584692},
title = {{Gap detection and masking in hearing-impaired and normal-hearing subjects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3584692},
volume = {81},
year = {1987}
}
@article{Mcdermott2004,
author = {Mcdermott, H and Looi, V},
doi = {10.1016/j.ics.2004.08.034},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mcdermott, Looi - 2004 - Perception of complex signals, including musical sounds, with cochlear implants.pdf:pdf},
issn = {05315131},
journal = {International Congress Series},
keywords = {cochlear implant,music perception,sound identification},
month = nov,
pages = {201--204},
title = {{Perception of complex signals, including musical sounds, with cochlear implants}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0531513104013895},
volume = {1273},
year = {2004}
}
@article{Alain2001,
author = {Alain, Claude and McDonald, Kelly L. and Ostroff, Jodi M. and Schneider, Bruce},
doi = {10.1121/1.1367243},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alain et al. - 2001 - Age-related changes in detecting a mistuned harmonic.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {5},
pages = {2211},
title = {{Age-related changes in detecting a mistuned harmonic}},
url = {http://link.aip.org/link/JASMAN/v109/i5/p2211/s1\&Agg=doi},
volume = {109},
year = {2001}
}
@article{Chen2005,
abstract = {We propose a novel model-based hearing compensation strategy and gradient-free optimization procedure for a learning-based hearing aid design. Motivated by physiological data and normal and impaired auditory nerve models, a hearing compensation strategy is cast as a neural coding problem, and a Neurocompensator is designed to compensate for the hearing loss and enhance the speech. With the goal of learning the Neurocompensator parameters, we use a gradient-free optimization procedure, an improved version of the ALOPEX that we have developed, to learn the unknown parameters of the Neurocompensator. We present our methodology, learning procedure, and experimental results in detail; discussion is also given regarding the unsupervised learning and optimization methods.},
annote = {
        Introduction
        
-most hearing aids work by amplifying sound at frequencies specified by the audiogram, but this is not an optimal solution, and seems not to be a good strategy when background noises are present (speech, whatever)
-directional microphones and other generic signal processing provides modest benefit
-instead, frame the problem as a neural coding problem, such that if one restores a normal encoding of the sound at the level of the cochlea, it will restore hearing to the extent to which the cochlea is accurately modeled, and the connections beyond the cochlea remain intact},
author = {Chen, Zhe and Becker, Suzanna and Bondy, Jeff and Bruce, Ian C and Haykin, Simon},
doi = {10.1162/089976605774320575},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Hearing Aids and Hearing Loss/Neuro-Compensator/2005 - A Novel Model-Based Hearing Compensation Design Using a Gradient-Free Optimzation Method.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Cochlear Nerve,Cochlear Nerve: physiology,Equipment Design,Female,Hearing Aids,Humans,Male,Models, Neurological,Models, Theoretical,Neural Networks (Computer)},
month = dec,
number = {12},
pages = {2648--71},
pmid = {16212766},
title = {{A novel model-based hearing compensation design using a gradient-free optimization method.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16212766},
volume = {17},
year = {2005}
}
@article{Levitt1971,
author = {Levitt, H},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Adaptive Procedures/1971 (Levitt) - Transformed Up-Down Methods in Psychoacoustics.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Acoustics},
month = feb,
number = {2},
pages = {Suppl 2:467+},
pmid = {5541744},
title = {{Transformed up-down methods in psychoacoustics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/5541744},
volume = {49},
year = {1971}
}
@article{Mauk2004,
abstract = {A complete understanding of sensory and motor processing requires characterization of how the nervous system processes time in the range of tens to hundreds of milliseconds (ms). Temporal processing on this scale is required for simple sensory problems, such as interval, duration, and motion discrimination, as well as complex forms of sensory processing, such as speech recognition. Timing is also required for a wide range of motor tasks from eyelid conditioning to playing the piano. Here we review the behavioral, electrophysiological, and theoretical literature on the neural basis of temporal processing. These data suggest that temporal processing is likely to be distributed among different structures, rather than relying on a centralized timing area, as has been suggested in internal clock models. We also discuss whether temporal processing relies on specialized neural mechanisms, which perform temporal computations independent of spatial ones. We suggest that, given the intricate link between temporal and spatial information in most sensory and motor tasks, timing and spatial processing are intrinsic properties of neural function, and specialized timing mechanisms such as delay lines, oscillators, or a spectrum of different time constants are not required. Rather temporal processing may rely on state-dependent changes in network dynamics.},
author = {Mauk, Michael D and Buonomano, Dean V},
doi = {10.1146/annurev.neuro.27.070203.144247},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/2004 (Mauk, Buonomano) - The Neural Basis of Temporal Processing.pdf:pdf},
issn = {0147-006X},
journal = {Annual review of neuroscience},
keywords = {Animals,Biological Clocks,Biological Clocks: physiology,Brain,Brain: anatomy \& histology,Brain: physiology,Humans,Models, Neurological,Motor Skills,Motor Skills: physiology,Nerve Net,Nerve Net: anatomy \& histology,Nerve Net: physiology,Neural Pathways,Neural Pathways: anatomy \& histology,Neural Pathways: physiology,Perception,Perception: physiology,Space Perception,Space Perception: physiology,Time Perception,Time Perception: physiology},
month = jan,
pages = {307--40},
pmid = {15217335},
title = {{The neural basis of temporal processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15217335},
volume = {27},
year = {2004}
}
@article{Zeyl2013a,
author = {Zeyl, Timothy},
doi = {10.1111/febs.12167},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Hearing Aids and Hearing Loss/Neuro-Compensator/Zeyl-manual.pdf:pdf},
issn = {1742-4658},
journal = {The FEBS journal},
month = feb,
number = {4},
pages = {1168},
pmid = {23414330},
title = {{Matlab Code Manual}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23414330},
volume = {280},
year = {2013}
}
@article{Ellemberg2004,
author = {Ellemberg, D and Lewis, T and Dirks, M and Maurer, D and Ledgeway, T and Guillemot, J and Lepore, F},
doi = {10.1016/j.visres.2004.05.006},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/PSYCH 720/Unit 3/Paper 1/2003 - Putting order into the development of sensitivity to global motion.pdf:pdf},
issn = {00426989},
journal = {Vision Research},
keywords = {adults,children,first-order motion,gabor,global motion,random,second-order motion,speed processing,visual development},
month = sep,
number = {20},
pages = {2403--2411},
title = {{Putting order into the development of sensitivity to global motion}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0042698904002408},
volume = {44},
year = {2004}
}
@article{Alain2012,
abstract = {Older adults presented with short (i.e., 40ms) harmonic complex tones show a reduced likelihood of hearing the mistuned harmonic as a separate sound. Here, we examined whether this age difference for the mistuned harmonic would generalize to a longer signal duration (i.e., 200ms). We measured auditory evoked fields (AEFs) using magnetoencephalography while young and older adults were presented with harmonic complex tones that either had all partials of the tones in tune (single sound object) or contained a 4 or 16\% mistuned harmonic (dual sound objects). The auditory stimuli were presented in isolation or embedded in low or moderate levels of continuous white noise. For each participant, we modeled the AEFs with a pair of dipoles in the superior temporal plane and examined the effects of age and noise on the amplitude and latency of the resulting source waveforms. The present study reveals similar noise-induced increases in N1m and object-related negativity in young and older adults which may be mediated via efferent feedback connections and/or changes in the temporal window of integration. We observed less age-related differences in concurrent sound segregation for stimuli that matched the duration of the temporal integration window of auditory perception (i.e., 200ms) than for short duration sounds (i.e., 40ms). Possible explanations for this duration-dependent age-related decline in concurrent sound perception are a general slowing in auditory processing and/or lengthening of the temporal integration window.},
annote = {        Purpose        
-older adults perform worse on the mistuned harmonic task with shorter duration sounds, so the present study investigated whether this is true of harmonic sounds with duration of 200ms relative to 40ms and whether noise also affects auditory evoked fields
                  
Introduction        
-older adults have difficulty following a conversation in multi-talker babble (references) or reverberation (references)
-older adults are worse at identifying two synthetic sounds presented concurrently (Snyder and Alain, 2005) and increased thresholds for detection of inharmonicity in complex tones (Alain et al. 2001b, Grube et al. 2003), thus are more likely to erroneously combine frequency components from different sources
-prior research has shown mistuned harmonic thresholds are generally around 1-3\% depending on the listeners, duration, and frequency of the mistuned harmonic (Moore et al., 1986)
-in Alain and McDonald's study with MEG, mistuned harmonics elicited an early enhanced positivity (60-100ms), and ORN overlapping N1m and P2m (130-190ms), and a positive displacement peaking at 230ms after sound onset (P230)
-the 60-100ms early positivity was similar across age groups, but the ORN and P230 amplitude was smaller in the older group coinciding with less accurate detection of the mistuned harmonic
-age differences for detecting a mistuned harmonic are smaller for longer (400ms) than shorter duration (100ms) signals (Alain et al., 2001b)
-aging has been shown to modulate the amplitude and latency of auditory evoked responses as well; amplitude of P1 wave is larger in older adults (Pekkonen et al., 1995; Ross et al., 2010; Soros et al., 2009), larger N1 wave in older adults (Alain and Woods, 1999; Chao and Knight, 1997; Soros et al., 2009), and another study reporting longer latencies (Tremblay et al., 2003), and longer latencies for the P2 wave for older adults during passive listening (Lister et al., 2011; Tremblay et al., 2003)
-thought to reflect general slowing (Salthouse, 1996) and impaired inhibitory functions (Alain and Woods, 1999; Chao and Knight ,1997), taking place at various levels in the afferent and efferent pathways
-older adults may also have more difficulty filtering out task-irrelevant information, allocating more attentional resources than younger adults (Alain et al., 2004; Grady, 2008), which could account for the larger amplitudes in older subjs
-the present study used a passive listening task to allow examination of low-level auditory processing without any influence of attention
-in a recent study of young adults, Alain et al., 2009 found a noise-induced increase in N1m and ORN amplitudes with pure tones or complex harmonic tones in low-level background noise
-the authors reason that during passive listening background noise would mainly modulate low-level auditory processing at the cochlea and ascending auditory pathways, and expected the age-related difference in N1m to be affected by background noise
                  
Materials and Methods                  
Participants        
-normal hearing, 20 young 20 old          
Hearing Assessment        
-used a basic audiogram, and QuickSIN (Etymotic Research, 2001, Killion et al., 2004)          
Stimuli and Task        
-200Hz complex tone with 10 harmonics, 0\%, 4\% or 16\% mistuning
-stimuli digitally generated at sampling rate of 24,414Hz using a System 3 RTP (TDT) and presented binaurally via audiometer using ER-3A transducers and reflectionless 2.5m plastic tubes
-sounds were 200ms long with rise/fall times of 5ms
-all sounds were equiprobable and presented in random order at 75 dB SPL with ISI varying randomly between 800 and 1200ms in 100ms steps
-there were 3 conditions, low (45 dBA), moderate (65 dBA) or no background noise (Gaussian white noise)
-three blocks of 900 trials were presented, and order of listening conditions was counterbalanced
-participants completed a behavioural task after the MEG recording, and testing was done in a double-walled sound attenuated chamber; on each trial they were asked to indicate if they heard one sound (a buzz) or two sounds (a buzz and a sound with a pure-tone quality)
-next stimulus was presented 1500ms following the previous response, and they did not receive feedback
-practice on the behavioural trials was done with a 500ms stimulus
-after familiarization, subjects completed 6 blocks of trials with 150 trials each, 100 trials of each type per background noise condition
-d', beta, and proportion of trials where heard two sounds          
Neuromagnetic Recording and Analysis        
-use of muted subtitle movies has been shown to effectively capture attention without interfering with auditory processing (Pettigrew et al., 2004)
        
        Results                  
3.1. Behavioral Data        
-young adults had lower audiometric thresholds from 250-2000Hz (difference \~{}5 dB), and the interaction between group and frequency was significant due to older individuals having worse hearing at 2000Hz
-young and older adults performed equally on the QuickSIN
-older adults were less likely to report hearing two concurrent sounds than young adults, but this failed to reach significance
-for proportion, interaction between age and mistuning was not significant
-for proportion, main effect of noise was not significant nor did it interact with other factors
-for d', main effect of age was not significant, nor was interaction between age and mistuning, but effect of noise was very significant: d' was larger in low-noise condition than in no- and moderate-noise conditions, revealing a quadratic trend relation between d' and noise level.  there was also an interaction between age and noise, due to a larger age difference when background noise was moderate than no- or low-
-for beta, response bias varied as a function of mistuning, but there was no significant difference between young and old adults in beta, nor was the interaction between group and mistuning significant          
3.2. Auditory evoked fields and dipole source location        
                  
Discussion        
-the age-related decline of ORNm for short duration signals (40ms) did not occur for longer (200ms) signals
-the temporal integration window of an AEF in this context is the minimum stim duration that produces a maximal amplitude
-auditory processing may be less efficient with age due to age-related changes in internal neuronal noise (Garrett et al., 2011), independent of general slowing
-as in their 2007 study, latency and amplitude of the early P90m response was not affecteed by age, indicating the mistuning was equally well registered in auditory cortex of young and older adults, suggests early cortical encoding of the temporal structure is little affected by normal aging
-the above result seems at odds with many studies showing age-related decline in temporal and spectral processing, but these differences can be reconciled by postulating that age differences in performance reflect impairment in subsequent stages of processing such as forming a sound object or making a decision          
A couple other subheadings        
      },
author = {Alain, Claude and McDonald, Kelly and {Van Roon}, Patricia},
doi = {10.1016/j.heares.2011.10.007},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alain, McDonald, Van Roon - 2012 - Effects of age and background noise on processing a mistuned harmonic in an otherwise periodic complex sound.pdf:pdf},
issn = {1878-5891},
journal = {Hearing research},
month = jan,
number = {1-2},
pages = {126--35},
pmid = {22101023},
publisher = {Elsevier B.V.},
title = {{Effects of age and background noise on processing a mistuned harmonic in an otherwise periodic complex sound.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22101023},
volume = {283},
year = {2012}
}
@article{Tremblay2006,
abstract = {Hearing aids help compensate for disorders of the ear by amplifying sound; however, their effectiveness also depends on the central auditory system's ability to represent and integrate spectral and temporal information delivered by the hearing aid. The authors report that the neural detection of time-varying acoustic cues contained in speech can be recorded in adult hearing aid users using the acoustic change complex (ACC). Seven adults (50-76 years) with mild to severe sensorineural hearing participated in the study. When presented with 2 identifiable consonant-vowel (CV) syllables ("shee" and "see"), the neural detection of CV transitions (as indicated by the presence of a P1-N1-P2 response) was different for each speech sound. More specifically, the latency of the evoked neural response coincided in time with the onset of the vowel, similar to the latency patterns the authors previously reported in normal-hearing listeners.},
annote = {        Introduction        
-hearing aid success is influenced by expectations, too little/much gain, and peripheral and central auditory systems capable of processing the spectrotemporal variations in sound
-the P1-N1-P2 complex is an auditory evoked potential characterized by a positive peak, a negative peak (100ms later), then a positive peak, reflecting neural activity from the thalamic-cortical segment of the central auditory system
-a number of studies have used this complex to assess neural representation of acoustic changes in speech
-can find multiple overlapping P1-N1-P2 responses to speech sounds, like Ostroff et al demonstrated.  using the word /sei/, the first response was to the sibilant /s/, and the next response corresponded to the transition /s/ to /ei/
-because these waveforms showed acoustic changes (silence to sound, and CV transition), Martin and Boothroyd termed this evoked response the acoustic change complex (ACC)
-Tremblay et al. examined ACC patterns in normal hearing young adults for /see/ and /shee/ (commonly confused by those with hearing loss); these sounds differ in place of articulation, spectral energy and duration of the fricative portion
-Tremblay et al. found that /shee/ and /see/ elicit distinct ACC responses
-the 30ms difference in transition from C to V between shee and see was maintained in the ACC
-the aim of the present study was to determine if ACC could be measured in hearing impaired listeners to try to understand what makes a hearing aid fitting successful/unsuccessful
-hearing aid users experience deprivation so spectral and temporal coding in central auditory system is likely altered [Willott et al., 2001], which could affect synchronous neural activity representing acoustic cues of speech sounds
-since subjects could accurately identify /see/ and /shee/, it was assumed these acoustic cues are being encoded in the auditory cortex, and it was predicted that /shee/ would be coded earlier than /see/
                  
Methods        
-7 subjects from 50-76 w mild-severe bilateral SNHL, normal immittance results, no history of Meniere's or neurologic disorders, 6 months of hearing aid experience
-two natural /see/ and /shee/ stimuli were used from the UCLA version of the Nonsense Syllable Test
-only participants who could correctly identify see and shee participated in the experiment
-tests done monaurally to avoid interactions introduced by second hearing aid, and an earmold was used for the hearing aids (always right ear)
-hearing aid was omnidirectional and compression limiting, gains were set according to NAL-R, volume wheel was inactivated
-probe microphone tests were done for each participant using 70 dB at 45 degree azimuth, to verify the insertion gain, and fits were found to be close to target          
electroacoustic properties of Phonak2 P2 AZ        
-list frequency range, peak full-on gain and average full-on gain
-acoustic recordings were measured at the output of the hearing aid in each listener's ear, and this procedure is described in more detail in the companion article
                  
Electrophysiology        
-stimuli were presented via speaker, 250 consecutive times each for /see/ and /shee/, counterbalanced across subjects
-timing was controlled by the computer, and the ISI was 1910ms
-participants were told to ignore the sound and watch a closed-captioned video of their choice
-EEG was recorded with a 32 channel Neuroscan, with ground on the forehead and reference on the nose, with eye blink activity monitored using an additional channel with electrodes on outer canthi of both eyes
-ocular artifacts were rejected, recording window was 100ms prestimulus to 1400ms poststimulus, and evoked responses were analog band-pass filtered online from 0.15 to 100Hz (12 dB/octave roll-off)
-all EEG channels amplified with gain of 500 and converted using A/D rate of 1000Hz
-after eye-blink, remaining sweeps were averaged and filtered from 1 to 20 Hz
                  
Results        
-/see/ and /shee/ elicit distinct waveforms; P1-N1-P2 responses are larger over frontal electrodes, and become smaller over parietal sites
-evoked neural activity is also larger on the contralateral side
-the difference in latency was 30 ms, just like the stimulus, which was significant with a Bonferroni-corrected paired t test
-there was no significant difference in latency or amplitude for the first N1, indicating the onset of the s, sh sound was encoded the same
                  
Discussion        
-the ACC had been studied previously for normal hearing listeners with hearing aids, and this study proved it could be done in people with hearing loss
-surprising that the latency was so well preserved given the effect years of sensory deprivation may have on the auditory system, and with the speech signals being altered by the hearing aid
-suggest the possibility of comparing ACCs between those who do receive much benefit from hearing aids and those who do not, and it would be useful if one could alter the signal processing to make the ACC more pronounced
-interesting that despite both /see/ and /shee/ having the sibilant /s/, and shee having more lower spectral energy than see, there were no amplitude/latency differences in N1
-they have another study which shows inconsistency in the effect of amplification on evoked neural activity},
author = {Tremblay, Kelly L and Kalstein, Laura and Billings, Cuttis J and Souza, Pamela E},
doi = {10.1177/1084713806292655},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/EEG/2006 (Tremblay, Kalstein, Billings, Souza) - Neural Representation of CV Transitions.pdf:pdf},
issn = {1084-7138},
journal = {Trends in amplification},
keywords = {Aged,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Auditory Threshold,Electroencephalography,Electrophysiology,Evoked Potentials, Auditory,Female,Hearing Aids,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: physiopathology,Hearing Loss, Sensorineural: therapy,Humans,Male,Middle Aged,Speech Acoustics,Speech Perception,Treatment Outcome},
month = sep,
number = {3},
pages = {155--62},
pmid = {16959736},
title = {{The neural representation of consonant-vowel transitions in adults who wear hearing AIDS.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16959736},
volume = {10},
year = {2006}
}
@article{Trainor2004,
author = {Trainor, L},
doi = {10.1016/j.sigpro.2003.10.013},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Speech-In-Noise Tests/2003 (Trainor, Sonnadara, Wiklund, Bondy, Gupta, Becker, Bruce, Haykin) - Development of a flexible, realistic hearing in noise test environment (R-HINT-E).pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {hearing in noise,impulse response,sound,speech perception},
month = feb,
number = {2},
pages = {299--309},
title = {{Development of a flexible, realistic hearing in noise test environment (R-HINT-E)}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168403002780},
volume = {84},
year = {2004}
}
@article{Hartmann1996,
abstract = {The perception of pitch forms the basis of musical melody and harmony. It is also among the most precise of all our human senses, and with imagination, this precision can be used experimentally to investigate the functioning of the auditory system. This tutorial presents auditory demonstrations from the zoo of pitch effects: pitch shifts, noise pitch, virtual pitch, dichotic pitch, and the pitches of things that are not there at all. It introduces models of auditory processing, derived from contemporary psychoacoustics and auditory physiology, and tests these models against the experimental effects. It concludes by describing the critical role played by pitch in the important human ability to disentangle overlapping sources of sound.},
author = {Hartmann, W M},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hartmann - 1996 - Pitch, periodicity, and auditory organization.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Cochlea,Cochlea: physiology,Dichotic Listening Tests,Humans,Periodicity,Pitch Perception,Pitch Perception: physiology,Time Factors},
month = dec,
number = {6},
pages = {3491--3502},
pmid = {8969472},
title = {{Pitch, periodicity, and auditory organization.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8969472},
volume = {100},
year = {1996}
}
@article{Phatak2007,
author = {Phatak, Sandeep a. and Allen, Jont B.},
doi = {10.1121/1.2642397},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Vowel Consonant Discrimination/2007 (Phatak) - Consonant and vowel confusions in speech-weighted noise.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {4},
pages = {2312},
title = {{Consonant and vowel confusions in speech-weighted noise}},
url = {http://link.aip.org/link/JASMAN/v121/i4/p2312/s1\&Agg=doi},
volume = {121},
year = {2007}
}
@article{Poth2001,
abstract = {Wave V of the auditory brainstem response was measured to two 50-ms broadband noise bursts separated by silent gaps of varied duration (4, 8, 32, or 64 ms) for younger and older adults with normal hearing. All subjects had measurable wave V responses to the first noise burst. However, for the second noise burst, three of eight older adults did not have responses with gap durations of 4 and 8 ms, and one of eight younger adults did not have a measurable response with a gap duration of 4 ms. When responses were present for older adults, latencies were similar to those of younger subjects but amplitudes were smaller. These results suggest age-related deficits in gap detection at the level of the brainstem in a group of aged subjects with no threshold elevation. Results are similar to those of Boettcher et al. (1996) using an identical paradigm in young and aged Mongolian gerbils.},
annote = {        Introduction        
- the authors think that the jury is out on whether gap detection thresholds are affected by age, but i would argue that temporal processing does degrade
- a few studies near 2000 showed deficits in intensity and frequency discrimination, duration discrimination, and gap duration discrimination
- in the early 90s, a couple studies showed that gap detection did not change with age, but rather could be explained by hearing loss; it is well established that gap detection is worse for subjects with hearing loss than those with normal hearing
- other studies have shown age effects in the absence of hearing loss, such as aged subjects doing worse with shorter markers, or when the gap was near the onset or offset of a noise burst
- electrophysiological measures analogous to psychophysical measures of gap detection have been looked at in animal models of presbyacusis, by looking at ABR wave iv, and the CAP for two noise bursts separated by a gap in Mongolian gerbils
- wave iv latencies were no different for the first sound but were longer for the second noise in aged gerbils
- in contrast, no difference in CAP latencies was observed between age groups, suggesting that the age related changes are due to central auditory nervous system (confirmed with a couple other studies)
- the purpose of the present study was to investigate gap detection of noise bursts with ABR, and hypothesized that gap detection would be worse in older subjects and one could observe this using wave V
        
        Methods        
- 8 young and 8 aged subjects
- stimuli were 50ms broadband bursts separated by 4, 8, 32, or 64 ms
- stimuli presented monaurally, 2/s, at 90 dB SPL
- subjects sat in a reclining chair with eyes closed
- wave V was measured for the first 10 ms after the onset of the first noise burst and 10 ms after the onset of the second noise burst
- the researchers were looking for a change in wave V in the second burst
        
        Results                  
Presence of Wave V                  
        - all subjects had a measurable wave V response to the first noise burst and second noise burst with 32 or 64 ms
- 3 of 8 aged subjects had unmeasurable wave V response to 4 or 8 ms, whereas 0 young subjects had unmeasurable wave V response to 8 ms, but 1 did have an unmeasurable wave V response to 4 ms          
Wave V Amplitude        
- in general, for measurable responses amplitude was the roughly the same between age groups, decreasing as gap duration decreased
- the subjects who did not have responses at 4 and 8 ms did have responses at 32 and 64 ms, and were among the lower amplitudes          
Wave V Latency        
- in general, latency increased as gap duration decreased
- one older subject had much longer latency at 32 and 64 ms
                  
Discussion        
- the animal studies mentioned in the article suggest that the difference between ABR but not CAP between groups indicates that the difference is due to central rather than peripheral changes
- the Walton et al. (1995) study suggested the central response is derived from the inferior colliculus
- the aged subjects who did not have ABRs to the second noise burst were not necessarily the ones with the worse thresholds},
author = {Poth, E a and Boettcher, F a and Mills, J H and Dubno, J R},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/2001 (Poth, Boettcher, Mills, Dubno) - ABR in younger and older adults for broadband noises separated by silent gap.pdf:pdf},
issn = {0378-5955},
journal = {Hearing research},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Aged,Aging,Aging: physiology,Evoked Potentials, Auditory, Brain Stem,Humans,Middle Aged,Noise,Reaction Time,Reference Values},
month = dec,
number = {1-2},
pages = {81--6},
pmid = {11744284},
title = {{Auditory brainstem responses in younger and older adults for broadband noises separated by a silent gap.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11744284},
volume = {161},
year = {2001}
}
@article{Moore1988,
abstract = {Thresholds for the detection of temporal gaps were measured using two types of signals to mark the gaps: bandpass-filtered noises and sinusoids. The first experiment used seven subjects with relatively flat unilateral moderate cochlear hearing loss. The normal ear of each subject was tested both at the same sound-pressure level (SPL) as the impaired ear, and at the same sensation level (SL). Background noise was used to mask spectral "splatter" associated with the gap. For the noise markers, gap thresholds tended to be larger for the impaired ears than for the normal ears when the comparison was made at equal SPL; the difference was reduced, but not eliminated, when the comparison was made at equal SL. Gap thresholds for both the normal and impaired ears decreased as the center frequency increased from 0.5 to 2.0 kHz. For the sinusoidal markers, gap thresholds were often similar for the normal and impaired ears when tested at equal SPL, and were larger for the normal ears when tested at equal SL. Gap thresholds did not change systematically with frequency. Gap thresholds using sinusoidal markers were smaller than those using noise markers. In the second experiment, three subjects with single-channel cochlear implants were tested. Gap thresholds for noise bands tended to increase with increasing center frequency when the noise bandwidth was fixed, and to decrease with increasing bandwidth when the center frequency was fixed. Gap thresholds for sinusoids did not change with center frequency, but decreased markedly with increasing level. Gap thresholds for sinusoids were considerably smaller than those for noise bands.(ABSTRACT TRUNCATED AT 250 WORDS)},
author = {Moore, B C and Glasberg, B R},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1988 (Moore, Glasberg) - Gap detection with sinusoids and noise in normal, impaired, and electrically stimulated ears.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Acoustic Stimulation,Aged,Auditory Threshold,Bone Conduction,Cochlear Implants,Female,Hearing Disorders,Hearing Disorders: diagnosis,Hearing Tests,Humans,Male,Meniere Disease,Meniere Disease: diagnosis,Middle Aged,Noise},
month = mar,
number = {3},
pages = {1093--101},
pmid = {3356814},
title = {{Gap detection with sinusoids and noise in normal, impaired, and electrically stimulated ears.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3356814},
volume = {83},
year = {1988}
}
@article{Folland2012,
abstract = {The ability to separate simultaneous auditory objects is crucial to infant auditory development. Music in particular relies on the ability to separate musical notes, chords, and melodic lines. Little research addresses how infants process simultaneous sounds. The present study used a conditioned head-turn procedure to examine whether 6-month-old infants are able to discriminate a complex tone (240 Hz, 500 ms, six harmonics in random phase with a 6 dB roll-off per octave) from a version with the third harmonic mistuned. Adults perceive such stimuli as containing two auditory objects, one with the pitch of the mistuned harmonic and the other with pitch corresponding to the fundamental of the complex tone. Adult thresholds were between 1\% and 2\% mistuning. Infants performed above chance levels for 8\%, 6\%, and 4\% mistunings, with no significant difference between conditions. However, performance was not significantly different from chance for 2\% mistuning and significantly worse for 2\% compared to all larger mistunings. These results indicate that 6-month-old infants are sensitive to violations of harmonic structure and suggest that they are able to separate two simultaneously sounding objects.},
author = {Folland, Nicole a and Butler, Blake E and Smith, Nicholas a and Trainor, Laurel J},
doi = {10.1121/1.3651254},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Folland et al. - 2012 - Processing simultaneous auditory objects infants' ability to detect mistuning in harmonic complexes.pdf:pdf},
issn = {1520-8524},
journal = {The Journal of the Acoustical Society of America},
month = jan,
number = {1},
pages = {993--7},
pmid = {22280722},
title = {{Processing simultaneous auditory objects: infants' ability to detect mistuning in harmonic complexes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22280722},
volume = {131},
year = {2012}
}
@article{Bondy2004,
annote = {Background Info
-hearing aid fitting procedures based on qualitative theory (loudness equalization, loudness normalization, maximal intelligibility) produce vastly different results for two individuals with the same audiogram
-up until the mid 80s the mechanisms for sensorineural hearing loss were not well understood
-able to predict hearing aid evaluations using auditory models which are consistent with human experimental data
-the sound propogation from media to media up a traveling wave in the fluid filled cochlea is well described by linear transfer functions, but beyond this the system is highly nonlinear
-traveling wave causes maximal displacement at some point along the basilar membrane, as a function of frequency and OHC undamping; IHC tranduce this maximal displacement, and OHC undamping enhances the IHC's sensitivity and selectivity
-hair cell loss may also impair temporal discrimination
-there is some evidence for plasticity in the mammalian auditory cortex resulting from hair cell damage, but there is no present (2004) evidence that the basic cortical circuitry (streaming, decoding) does not work
-there have been matrix solving approaches to the optimal hearing aid, by assuming that the hearing impaired system may be represented by an invertible matrix (Anderson); but this is overly simple, because the auditory system is nonlinear, has time variances and many-to-one mappings
-even if H is non-invertible (because of its nonlinearities), one may still be able to capture its capabilities in order to reproduce normal hearing
-fact that one sound can be masked by another suggests that the auditory system discards information
        
Neuro-Compensator
-alter the input signal going into the impaired ear so that there's a normal neural representation
-key idea is to use auditory models of the normal and impaired ear to evaluate hearing compensation techniques offline: compare the output of the normal model to the impaired model
-the Neuro-Compensator therefore depends on an accurate intact and damaged auditory model
-
        
Details of Auditory Model
-employs Bruce, Sachs, Young's auditory model, and uses Weiner and Ross's head related transfer function for outer ear functioning
-first section models the middle ear filtering
-second section is the control path, which models OHC modulatory functions (wideband, nonlinear, time varying, band-pass filter followed by OHC nonlinearity and low-pass filter)
-control path has wider bandwidth than signal path because of wideband nonlinear phenomena such as two-tone rate suppression
-third section is the signal path, describes filter properties and traveling wave delay of the basilar membrane (time varying, narrowband filter, nonlinear transduction and low-pass filtering of inner hair cell), synapse model and spike generator
      },
author = {Bondy, J},
doi = {10.1016/j.sigpro.2004.04.006},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Hearing Aids and Hearing Loss/Neuro-Compensator/2004 - A novel signal-processing strategy for hearing-aid design - neurocompensation.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {hearing-aids,sensorineural impairment,speech perception},
month = jul,
number = {7},
pages = {1239--1253},
title = {{A novel signal-processing strategy for hearing-aid design: neurocompensation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168404000696},
volume = {84},
year = {2004}
}
@article{Lunner2003,
abstract = {Two experiments were conducted to investigate possible relationships between cognitive function and hearing aid use. In Experiment 1, 72 first-time hearing aid users were tested for speech recognition in noise (Hagerman sentence test) with and without hearing aids. Cognitive function was assessed by tests of working memory (reading span test) and verbal information-processing speed. The results indicate that, after controlling for age and hearing loss, significant correlations exist between the measures of cognitive performance and speech recognition in noise, both with and without hearing aids. High cognitive performance was associated with high performance in the speech recognition task. In Experiment 2, 17 first-time hearing aid users with either high or low working-memory capacity tested an experimental hearing aid which processed the sound differently depending on whether or not speech was detected. The results revealed that those with high working-memory capacity were better than those with low capacity at identifying and reporting the specific processing effects of the aid. This may have implications for how reported results should be interpreted in a research context, how a person's rehabilitation needs are formulated, and how hearing aid controls should be supervised. In conclusion, careful attention should be paid to the cognitive status of listeners, as it can have a significant influence on their ability to utilize their hearing aids.},
author = {Lunner, Thomas},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Speech-In-Noise Tests/2003 (Lunner) - Cognitive function in relation to hearing aid use.pdf:pdf},
issn = {1499-2027},
journal = {International journal of audiology},
keywords = {Adult,Aged,Aged, 80 and over,Audiometry, Pure-Tone,Audiometry, Speech,Cognition,Female,Hearing Aids,Hearing Aids: adverse effects,Hearing Loss,Hearing Loss: rehabilitation,Humans,Male,Memory, Short-Term,Middle Aged,Noise,Questionnaires,Speech Perception},
month = jul,
pages = {S49--58},
pmid = {12918610},
title = {{Cognitive function in relation to hearing aid use.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12918610},
volume = {42 Suppl 1},
year = {2003}
}
@article{McAdams1995,
abstract = {To study the perceptual structure of musical timbre and the effects of musical training, timbral dissimilarities of synthesized instrument sounds were rated by professional musicians, amateur musicians, and nonmusicians. The data were analyzed with an extended version of the multidimensional scaling algorithm CLASCAL (Winsberg \& De Soete, 1993), which estimates the number of latent classes of subjects, the coordinates of each timbre on common Euclidean dimensions, a specificity value of unique attributes for each timbre, and a separate weight for each latent class on each of the common dimensions and the set of specificities. Five latent classes were found for a three-dimensional spatial model with specificities. Common dimensions were quantified psychophysically in terms of log-rise time, spectral centroid, and degree of spectral variation. The results further suggest that musical timbres possess specific attributes not accounted for by these shared perceptual dimensions. Weight patterns indicate that perceptual salience of dimensions and specificities varied across classes. A comparison of class structure with biographical factors associated with degree of musical training and activity was not clearly related to the class structure, though musicians gave more precise and coherent judgments than did non-musicians or amateurs. The model with latent classes and specificities gave a better fit to the data and made the acoustic correlates of the common dimensions more interpretable.},
author = {McAdams, S and Winsberg, S and Donnadieu, S and {De Soete}, G and Krimphoff, J},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/McAdams et al. - 1995 - Perceptual scaling of synthesized musical timbres common dimensions, specificities, and latent subject classes.pdf:pdf},
issn = {0340-0727},
journal = {Psychological research},
keywords = {Adolescent,Adult,Auditory Perception,Female,Humans,Loudness Perception,Male,Mathematics,Middle Aged,Models, Psychological,Music,Pitch Perception,Practice (Psychology),Psychoacoustics,Sound Spectrography},
month = jan,
number = {3},
pages = {177--92},
pmid = {8570786},
title = {{Perceptual scaling of synthesized musical timbres: common dimensions, specificities, and latent subject classes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8570786},
volume = {58},
year = {1995}
}
@article{Vickers2001,
author = {Vickers, Deborah a. and Moore, Brian C. J. and Baer, Thomas},
doi = {10.1121/1.1381534},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Vowel Consonant Discrimination/2001 (Vickers, Moore, Baer) - How low-pass filtering of speech in quiet for people with dead regions affects intelligibility.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {2},
pages = {1164},
title = {{Effects of low-pass filtering on the intelligibility of speech in quiet for people with and without dead regions at high frequencies}},
url = {http://link.aip.org/link/JASMAN/v110/i2/p1164/s1\&Agg=doi},
volume = {110},
year = {2001}
}
@article{Heinrich2006,
author = {Heinrich, Antje and Schneider, Bruce},
doi = {10.1121/1.2173524},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/2006 (Heinrich, Schneider) - Age-related changes in within- and between-chan gap detection using sinusoidal stimuli.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {4},
pages = {2316},
title = {{Age-related changes in within- and between-channel gap detection using sinusoidal stimuli}},
url = {http://link.aip.org/link/JASMAN/v119/i4/p2316/s1\&Agg=doi},
volume = {119},
year = {2006}
}
@article{Lewis2005,
abstract = {Psychophysical studies of children deprived of early visual experience by dense cataracts indicate that there are multiple sensitive periods during which experience can influence visual development. We note three sensitive periods within acuity, each with different developmental time courses: the period of visually-driven normal development, the sensitive period for damage, and the sensitive period for recovery. Moreover, there are different sensitive periods for different aspects of vision. Relative to the period of visually driven normal development, the sensitive period for damage is surprisingly long for acuity, peripheral vision, and asymmetry of optokinetic nystagmus, but surprisingly short for global motion. A comparison of results from unilaterally versus bilaterally deprived children provides insights into the complex nature of interactions between the eyes during normal visual development.},
author = {Lewis, Terri L and Maurer, Daphne},
doi = {10.1002/dev.20055},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/PSYCH 720/Unit 3/Paper 1/2005 - Multiple sensitive periods in human visual development.pdf:pdf},
issn = {0012-1630},
journal = {Developmental psychobiology},
keywords = {Adolescent,Cataract,Cataract: physiopathology,Child,Child, Preschool,Critical Period (Psychology),Humans,Infant,Neuronal Plasticity,Neuronal Plasticity: physiology,Sensory Deprivation,Sensory Deprivation: physiology,Vision Disorders,Vision Disorders: physiopathology,Vision, Ocular,Vision, Ocular: physiology},
month = apr,
number = {3},
pages = {163--83},
pmid = {15772974},
title = {{Multiple sensitive periods in human visual development: evidence from visually deprived children.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15772974},
volume = {46},
year = {2005}
}
@article{Byrne1998a,
author = {Byrne, D. and Noble, W.},
doi = {10.1177/108471389800300202},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Sound Localization/1998 - More front rear confusions with BTEs only when all stimuli presented at same dB.pdf:pdf},
issn = {1084-7138},
journal = {Trends in Amplification},
month = jun,
number = {2},
pages = {51--73},
title = {{Optimizing Sound Localization with Hearing Aids}},
url = {http://tia.sagepub.com/cgi/doi/10.1177/108471389800300202},
volume = {3},
year = {1998}
}
@article{Barker2012,
abstract = {Human neuroimaging studies have identified a region of auditory cortex, lateral Heschl's gyrus (HG), that shows a greater response to iterated ripple noise (IRN) than to a Gaussian noise control. Based in part on results using IRN as a pitch-evoking stimulus, it has been argued that lateral HG is a general "pitch center." However, IRN contains slowly varying spectrotemporal modulations, unrelated to pitch, that are not found in the control stimulus. Hence, it is possible that the cortical response to IRN is driven in part by these modulations. The current study reports the first attempt to control for these modulations. This was achieved using a novel type of stimulus that was generated by processing IRN to remove the fine temporal structure (and thus the pitch) but leave the slowly varying modulations. This "no-pitch IRN" stimulus is referred to as IRNo. Results showed a widespread response to the spectrotemporal modulations across auditory cortex. When IRN was contrasted with IRNo rather than with Gaussian noise, the apparent effect of pitch was no longer statistically significant. Our findings raise the possibility that a cortical response unrelated to pitch could previously have been errantly attributed to pitch coding.},
annote = {        Introduction        
-pitch obviously important in music, but also in language (lexical features in tonal languages, prosodic features in nontonal languages, separating concurrent sound sources)
-there is debate over whether there is a place in the brain representing the pitch percept, or whether this arises from representation of the physical attributes
-since the same pitch can be elicited by sounds of different spectrotemporal nature, it is suggested there is a group of neurons responsible for the pitch perception
-4 criteria for a pitch center are:
1) should respond selectively to pitch compared with matched noise
2) activity should remain after eliminating peripheral effects, such as cochlear distortions
3) should respond to all pitch-evoking stimuli, regardless of physical attributes
4) activity should increase with increasing pitch salience
 -these criteria do not imply that the pitch center should respond exclusively to pitch
-a landmark single-unit extracellular recording study in primates showed the anterolateral region in primary auditory cortex satisfies the 4 criteria for a pitch center (Bendor and Wang 2005)
-IRN can be compared with Gaussian noise to study pitch, because they have very similar spectral characteristics but one has a pitch percept
-can increase the salience of the IRN pitch by increasing the number of iterations (Yost 1996), and a physical correlate of pitch salience is the height of the first peak in the autocorrelation function
-one of the first studies was Griffiths et al. (1998), which used PET and found greater activation in lateral HG with increasing number of IRN iterations, but whether this was a linear relationship was unclear
-other human studies have shown significant differences in lateral HG between IRN and spectrally-matched noise [references], and Bendor and Wang take this to say that lateral HG is a good candidate for a human pitch center
-at present, evidence of lateral HG as a pitch center is mixed [references]
-Hall and Plack (2009) found planum temporale was typically responsive to different pitch-evoking stimuli (tone-in-noise, wideband harmonic complex, Huggins pitch), and in contrast lateral HG responded to these stim no different than their spectrally matched counterparts
-although the IRN-related response was consistent across listeners (>50\%), activation in PT produced by other pitch-evoking stimuli was less so (<25\%), this led Hall and Plack to say that no one region could reliably be assigned the label of "pitch center"
-Hall and Plack showed IRN contains features not contained in the other pitch-evoking stimuli, slow spectrotemporal variations
-increasing the number of delay-and-add iterations in IRN increases pitch salience and depth of modulations across time and frequency
-a couple other studies have also suggested the spectral ripple in IRN could be activating HG rather than the pitch
-to test the assertion that the fMRI activations are due to the spectrotemporal fluctuations as opposed to the pitch percept, the authors of the present study created a no-pitch IRN stimulus, removing the temporal fine-structure
                  
Materials and Methods        
-16 listeners with normal hearing, some with music experience, and extras for the psychophysical tests
-diotic IRN stimuli were generated from delay-and-add performed on Gaussian noise
-noise was bandpass filtered (1-2 kHz) to remove low-\# harmonics that are resolved by the peripheral auditory system
-a delay of 10ms was used, generating a stimulus of 100Hz, and the delay-and-add process was repeated 2,4,16, or 64 times to create all conditions},
author = {Barker, Daphne and Plack, Christopher J and Hall, Deborah a},
doi = {10.1093/cercor/bhr065},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/IRN/2008 (Barker Plack Hall) - IRN fMRI Pitch Sensitive Region.pdf:pdf},
issn = {1460-2199},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Acoustic Stimulation,Adult,Analysis of Variance,Auditory Cortex,Auditory Cortex: blood supply,Auditory Cortex: physiology,Auditory Pathways,Auditory Pathways: blood supply,Auditory Pathways: physiology,Brain Mapping,Discrimination (Psychology),Female,Functional Laterality,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Male,Middle Aged,Noise,Normal Distribution,Oxygen,Pitch Perception,Pitch Perception: physiology,Psychoacoustics,Young Adult},
month = apr,
number = {4},
pages = {745--53},
pmid = {21709174},
title = {{Reexamining the evidence for a pitch-sensitive region: a human fMRI study using iterated ripple noise.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21709174},
volume = {22},
year = {2012}
}
@article{Metselaar2008,
abstract = {We compared two different types of hearing-aid fitting procedures in a double-blind randomized clinical study. Hearing aid fittings based on a purely prescriptive procedure (the NAL-RP formula) were compared to a comparative fitting procedure based on optimizing speech intelligibility scores. Main outcome measures were improvement of speech intelligibility scores in quiet and in noise. Data were related to the real-ear insertion responses that were measured after fitting. For analysis purposes subgroups were composed according to degree of hearing loss, characterized by unaided speech intelligibility in quiet, previous experience with hearing aids, unilateral or bilateral fittings and type of hearing aid. We found equal improvement of speech intelligibility in quiet, while fitting according to the prescriptive formula resulted in a somewhat better performance as expressed by the speech-to-noise ratio in comparison to the comparative procedure. Both procedures resulted in comparable real-ear insertion responses.},
author = {Metselaar, Mick and Maat, Bert and Krijnen, Pieta and Verschuure, Hans and Dreschler, Wouter and Feenstra, Louw},
doi = {10.1007/s00405-008-0596-x},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Hearing Aids and Hearing Loss/Fitting Procedures/(2008) - Comparison of prescriptive (NAL-RP) and comparative fitting procedures for speech in noise scores.pdf:pdf},
issn = {0937-4477},
journal = {European archives of oto-rhino-laryngology : official journal of the European Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the German Society for Oto-Rhino-Laryngology - Head and Neck Surgery},
keywords = {Adult,Aged,Aged, 80 and over,Analysis of Variance,Double-Blind Method,Female,Hearing Aids,Humans,Male,Middle Aged,Noise,Prosthesis Fitting,Prosthesis Fitting: methods,Speech Intelligibility,Statistics, Nonparametric},
month = sep,
number = {9},
pages = {1113--20},
pmid = {18246361},
title = {{Comparison of speech intelligibility in quiet and in noise after hearing aid fitting according to a purely prescriptive and a comparative fitting procedure.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2491429\&tool=pmcentrez\&rendertype=abstract},
volume = {265},
year = {2008}
}
@article{Samson2002,
abstract = {Thirty patients with unilateral temporal lobe excisions and 15 normal control subjects were tested in a task involving judgements of timbre dissimilarity in single tone and melodic conditions. Perceptual correlates of spectral and temporal parameters resulting from changing the number of harmonics and rise-time duration, respectively, were investigated by using a multidimensional scaling technique. The results of subjects with left temporal lobe lesion suggest that they were able to use the spectral and temporal envelopes of tones independently in making perceptual judgements of single tones. In the melodic condition, their results were significantly different from those of normal control subjects, suggesting that left temporal lesions do affect subtle aspects of timbre perception, despite these patients' preserved ability to make discrimination judgements using traditional paradigms. The major finding of this study concerns perceptual ratings obtained by subjects with right temporal lobe lesion, which revealed a disturbed perceptual space in both conditions. The most distorted results were obtained with single tones, in which the temporal parameter was less prominent. Tones were grouped according to their spectral content, but the results did not reflect a coherent underlying perceptual dimension. In general, the data from both patient groups (left lesions and right lesions) showed that the extraction of temporal cues was easier in the melodic than in the single tone condition, suggesting that the different durations and frequencies heard in a musical phrase enhance the importance of certain physical parameters. The findings of the present study replicate and extend previous results showing that timbre perception depends mainly upon the integrity of right neocortical structures, although a contribution of left temporal regions is also apparent. These data also demonstrate that multidimensional techniques are sensitive to more subtle perceptual disturbances that may not be revealed by discrimination paradigms.},
author = {Samson, S\'{e}verine and Zatorre, Robert J and Ramsay, James O},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Samson, Zatorre, Ramsay - 2002 - Deficits of musical timbre perception after unilateral temporal-lobe lesion revealed with multidimensional scaling.pdf:pdf},
issn = {0006-8950},
journal = {Brain : a journal of neurology},
keywords = {Acoustic Stimulation,Adolescent,Adult,Agnosia,Agnosia: etiology,Agnosia: pathology,Agnosia: physiopathology,Auditory Diseases, Central,Auditory Diseases, Central: etiology,Auditory Diseases, Central: pathology,Auditory Diseases, Central: physiopathology,Female,Functional Laterality,Functional Laterality: physiology,Humans,Male,Middle Aged,Music,Music: psychology,Pitch Discrimination,Pitch Discrimination: physiology,Postoperative Complications,Postoperative Complications: etiology,Postoperative Complications: pathology,Postoperative Complications: physiopathology,Temporal Lobe,Temporal Lobe: injuries,Temporal Lobe: pathology,Temporal Lobe: physiopathology,Time Perception,Time Perception: physiology},
month = mar,
number = {Pt 3},
pages = {511--23},
pmid = {11872609},
title = {{Deficits of musical timbre perception after unilateral temporal-lobe lesion revealed with multidimensional scaling.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11872609},
volume = {125},
year = {2002}
}
@article{Samson1994,
abstract = {Patients with unilateral temporal lobe excisions and normal control subjects were tested in timbre discrimination tasks in which the stimuli differed by either the number of harmonics (a spectral cue) or by the duration of the rise and fall times (a time cue). Patients with right temporal lobe lesions exhibited a significant deficit in discriminating both spectral and time information, in comparison to patients with left temporal lobe lesions and normal control subjects. This finding suggests that musical timbre perception, examined in a psychoacoustic sense, depends on neural systems found within the right temporal lobe.},
author = {Samson, S and Zatorre, R J},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Samson, Zatorre - 1994 - Contribution of the right temporal lobe to musical timbre discrimination.pdf:pdf},
issn = {0028-3932},
journal = {Neuropsychologia},
keywords = {Acoustic Stimulation,Adolescent,Adult,Auditory Perception,Functional Laterality,Functional Laterality: physiology,Humans,Middle Aged,Music,Psychoacoustics,Psychosurgery,Temporal Lobe,Temporal Lobe: physiology,Temporal Lobe: surgery},
month = feb,
number = {2},
pages = {231--40},
pmid = {8190246},
title = {{Contribution of the right temporal lobe to musical timbre discrimination.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8190246},
volume = {32},
year = {1994}
}
@article{Abel1972,
author = {Abel, SM},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1972 (Abel) - Duration Discrimination of Noise and Tone Bursts.pdf:pdf},
journal = {Journal of the Acoustical Society of America},
number = {15},
pages = {1219--1223},
title = {{Duration discrimination of noise and tone bursts}},
url = {http://link.aip.org/link/JASMAN/vol\_51/iss\_4B/},
volume = {4},
year = {1972}
}
@article{Emiroglu2008,
abstract = {In an attempt to quantify differences in object separation and timbre discrimination between normal-hearing and hearing-impaired listeners with a moderate sensorineural hearing loss of two different configurations, psychoacoustic measurements were performed with a total of 50 listeners. The experiments determined just noticeable differences (JND) of timbre in normal-hearing and hearing-impaired subjects along continua of "morphed" musical instruments and investigated the variance of JND in silence and different background noise conditions and on different sound levels. The results show that timbre JNDs of subjects with a steep hearing loss are significantly higher than of normal-hearing subjects, both in silence and noise, whereas timbre JNDs of flat/diagonal hearing-impaired subjects are similar to JNDs of normal-hearing subjects for signal levels above 55 dB (plus appropriate amplification for hearing-impaired). In noise (SNR=+10 dB) timbre JNDs of all subject groups are significantly higher than in silence. In the condition testing, transferability from silence to noise (i.e., the ability to imagine how the stimulus heard in silence would sound in noise), no significant JND differences across listener groups were found. The results can be explained by primary factors involved in sensorineural hearing loss and contradict the hypothesis that hearing-impaired people generally have more problems in object discrimination than normal-hearing people.},
author = {Emiroglu, Suzan and Kollmeier, Birger},
doi = {10.1016/j.brainres.2007.08.067},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Emiroglu, Kollmeier - 2008 - Timbre discrimination in normal-hearing and hearing-impaired listeners under different noise conditions.pdf:pdf},
issn = {0006-8993},
journal = {Brain research},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Aged,Audiometry,Auditory Threshold,Auditory Threshold: physiology,Female,Hearing Loss,Hearing Loss: physiopathology,Humans,Loudness Perception,Loudness Perception: physiology,Male,Middle Aged,Noise,Psychoacoustics,Speech Reception Threshold Test},
month = jul,
pages = {199--207},
pmid = {17991457},
title = {{Timbre discrimination in normal-hearing and hearing-impaired listeners under different noise conditions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17991457},
volume = {1220},
year = {2008}
}
@article{Peters1998,
abstract = {People with cochlear hearing loss often have considerable difficulty in understanding speech in the presence of background sounds. In this paper the relative importance of spectral and temporal dips in the background sounds is quantified by varying the degree to which they contain such dips. Speech reception thresholds in a 65-dB SPL noise were measured for four groups of subjects: (a) young with normal hearing; (b) elderly with near-normal hearing; (c) young with moderate to severe cochlear hearing loss; and (d) elderly with moderate to severe cochlear hearing loss. The results indicate that both spectral and temporal dips are important. In a background that contained both spectral and temporal dips, groups (c) and (d) performed much more poorly than group (a). The signal-to-background ratio required for 50\% intelligibility was about 19 dB higher for group (d) than for group (a). Young hearing-impaired subjects showed a slightly smaller deficit, but still a substantial one. Linear amplification combined with appropriate frequency-response shaping (NAL amplification), as would be provided by a well-fitted "conventional" hearing aid, only partially compensated for these deficits. For example, group (d) still required a speech-to-background ratio that was 15 dB higher than for group (a). Calculations of the articulation index indicated that NAL amplification did not restore audibility of the whole of the speech spectrum when the speech-to-background ratio was low. For unamplified stimuli, the SRTs in background sounds were highly correlated with absolute thresholds, but not with age. For stimuli with NAL amplification, the correlations of SRTs with absolute thresholds were lower, but SRTs in backgrounds with spectral and/or temporal dips were significantly correlated with age. It is proposed that noise with spectral and temporal dips may be especially useful in evaluating possible benefits of multi-channel compression.},
author = {Peters, R W and Moore, B C and Baer, T},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1997 (Peters, Moore, Baer) - SRT in noise with and without spectral and temporal dips for hearing impaired and normal hearing.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Adult,Cochlea,Cochlea: physiopathology,Hearing,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: physiopathology,Hearing: physiology,Humans,Noise,Noise: adverse effects,Speech Perception,Speech Reception Threshold Test,Time Factors},
month = jan,
number = {1},
pages = {577--87},
pmid = {9440343},
title = {{Speech reception thresholds in noise with and without spectral and temporal dips for hearing-impaired and normally hearing people.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9440343},
volume = {103},
year = {1998}
}
@article{Walden2001,
abstract = {This study sought to describe the consonant information provided by amplification and by speechreading, and the extent to which such information might be complementary when a hearing aid user can see the talker's face.},
author = {Walden, B E and Grant, K W and Cord, M T},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Vowel Consonant Discrimination/2001 (Walden, Grant, Cord) - Effects of Amplification and Speechreading on Consonant Recognition by Persons with Impaired Hearing.pdf:pdf},
issn = {0196-0202},
journal = {Ear and hearing},
keywords = {Aged,Cues,Hearing Aids,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: diagnosis,Hearing Loss, Sensorineural: rehabilitation,Humans,Lipreading,Male,Middle Aged,Phonetics,Speech Perception,Speech Perception: physiology},
month = aug,
number = {4},
pages = {333--41},
pmid = {11527039},
title = {{Effects of amplification and speechreading on consonant recognition by persons with impaired hearing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11527039},
volume = {22},
year = {2001}
}
@article{Harris2010,
abstract = {Differences in gap detection for younger and older adults have been shown to vary with the complexity of the task or stimuli, but the factors that contribute to these differences remain unknown. To address this question, we examined the extent to which age-related differences in processing speed and workload predicted age-related differences in gap detection. Gap detection thresholds were measured for 10 younger and 11 older adults in two conditions that varied in task complexity but used identical stimuli: (1) gap location fixed at the beginning, middle, or end of a noise burst and (2) gap location varied randomly from trial to trial from the beginning, middle, or end of the noise. We hypothesized that gap location uncertainty would place increased demands on cognitive and attentional resources and result in significantly higher gap detection thresholds for older but not younger adults. Overall, gap detection thresholds were lower for the middle location as compared to beginning and end locations and were lower for the fixed than the random condition. In general, larger age-related differences in gap detection were observed for more challenging conditions. That is, gap detection thresholds for older adults were significantly larger for the random condition than for the fixed condition when the gap was at the beginning and end locations but not the middle. In contrast, gap detection thresholds for younger adults were not significantly different for the random and fixed condition at any location. Subjective ratings of workload indicated that older adults found the gap detection task more mentally demanding than younger adults. Consistent with these findings, results of the Purdue Pegboard and Connections tests revealed age-related slowing of processing speed. Moreover, age group differences in workload and processing speed predicted gap detection in younger and older adults when gap location varied from trial to trial; these associations were not observed when gap location remained constant across trials. Taken together, these results suggest that age-related differences in complex measures of auditory temporal processing may be explained, in part, by age-related deficits in processing speed and attention.},
author = {Harris, Kelly C and Eckert, Mark a and Ahlstrom, Jayne B and Dubno, Judy R},
doi = {10.1016/j.heares.2009.09.017},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/2010 (Harris et al.) - Age-related differences in gap detection - Effects of task difficulty and cognitive ability.pdf:pdf},
issn = {1878-5891},
journal = {Hearing research},
keywords = {Acoustic Stimulation,Adult,Age Factors,Aged,Aging,Attention,Audiometry, Pure-Tone,Auditory Threshold,Cognition,Comprehension,Female,Humans,Male,Middle Aged,Neuropsychological Tests,Noise,Noise: adverse effects,Perceptual Masking,Signal Detection, Psychological,Speech Perception,Task Performance and Analysis,Time Factors,Workload,Young Adult},
month = jun,
number = {1-2},
pages = {21--9},
pmid = {19800958},
publisher = {Elsevier B.V.},
title = {{Age-related differences in gap detection: effects of task difficulty and cognitive ability.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2868108\&tool=pmcentrez\&rendertype=abstract},
volume = {264},
year = {2010}
}
@article{Abel2000,
abstract = {An experiment was conducted to determine the effect of aging on sound localization. Seven groups of 16 subjects, aged 10-81 years, were tested. Sound localization was assessed using six different arrays of four or eight loudspeakers that surrounded the subject in the horizontal plane, at a distance of 1 m. For two 4-speaker arrays, one loudspeaker was positioned in each spatial quadrant, on either side of the midline or the interaural axis, respectively. For four 8-speaker arrays, two loudspeakers were positioned in each quadrant, one close to the midline and the second separated from the first by 15 degrees, 30 degrees, 45 degrees, or 60 degrees. Three different 300-ms stimuli were localized: two one-third-octave noise bands, centered at 0.5 and 4 kHz, and broadband noise. The stimulus level (75 dB SPL) was well above hearing threshold for all subjects tested. Over the age range studied, percent-correct sound-source identification judgments decreased by 12\%-15\%. Performance decrements were apparent as early as the third decade of life. Broadband noise was easiest to localize (both binaural and spectral cues were available), and the 0.5-kHz noise band, the most difficult to localize (primarily interaural temporal difference cue available). Accuracy was relatively higher in front of than behind the head, and errors were largely front/back mirror image reversals. A left-sided superiority was evident until the fifth decade of life. The results support the conclusions that the processing of spectral information becomes progressively less efficient with aging, and is generally worse for sources on the right side of space.},
author = {Abel, S M and Gigu\`{e}re, C and Consoli, a and Papsin, B C},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Sound Localization/2000 - Effect of aging on horizontal plane sound localization.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Adolescent,Adult,Aged,Aged, 80 and over,Aging,Aging: physiology,Auditory Threshold,Auditory Threshold: physiology,Child,Female,Hearing,Hearing: physiology,Humans,Male,Middle Aged,Sound Localization,Sound Localization: physiology},
month = aug,
number = {2},
pages = {743--52},
pmid = {10955641},
title = {{The effect of aging on horizontal plane sound localization.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10955641},
volume = {108},
year = {2000}
}
@article{Tremblay2003,
author = {Tremblay, Kelly L and Piskosz, Michael and Souza, Pamela},
doi = {10.1016/S1388-2457(03)00114-7},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/EEG/2003 (Tremblay, Piskosz, Souza) - Effect of Age Related HL on Neural Rep of Sp Cues.pdf:pdf},
issn = {13882457},
journal = {Clinical Neurophysiology},
keywords = {aging and cortical potentials,aging and temporal processing,auditory-evoked potentials,speech perception and aging,speech-evoked cortical},
month = jul,
number = {7},
pages = {1332--1343},
title = {{Effects of age and age-related hearing loss on the neural representation of speech cues}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1388245703001147},
volume = {114},
year = {2003}
}
@article{Snell1997,
abstract = {The purpose of this study was to clarify and extend the results of earlier studies of age-related effects on temporal resolution by precisely matching young and old subjects with normal hearing and measuring gap thresholds in a variety of listening conditions. Younger subjects were between 17 and 40 years of age, older subjects between 64 and 77 years. Signals were noisebursts which varied in upper-cutoff frequency, overall level, and sinusoidal-amplitude-modulation depth. Signals were presented in quiet, in a noise floor, and with a gated-high-frequency masker in a noise floor. Significant main effects were found for signal frequency, intensity, modulation, age, and background condition. Mean gap thresholds ranged between 2.1 and 10.1 ms and were larger for the older subjects in all 24 conditions. In some conditions, introduction of a noise floor increased the gap thresholds of the older subjects relative to those of the younger. Analyses of individual data support the conclusion that the mean differences between groups reflect shifts in the distributions of gap thresholds of the older subjects towards poorer temporal resolution.},
annote = {Introduction
- This paper talks about how temporal resolution changes as a function of age
- Moore and Glasberg (1988) - gap detection thresholds generally greater in those with cochlear hearing loss
- Previous studies had shown differences in temporal resolution as a function of age but were confounded with audibility (different absolute thresholds) and complexity of the stimuli
- Current study used matched pairs of young and old subjects on absolute thresholds and looked at the effect of changes in stimulus and background complexity
- Changes in all conditions would support a general age-related change in speed of auditory processing
        
Method},
author = {Snell, K B},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1996 (Snell) - Age-related changes in temporal gap detection.PDF:PDF},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Adolescent,Adult,Age Factors,Aged,Aging,Auditory Threshold,Hearing,Hearing: physiology,Humans,Middle Aged},
month = apr,
number = {4},
pages = {2214--20},
pmid = {9104023},
title = {{Age-related changes in temporal gap detection.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9104023},
volume = {101},
year = {1997}
}
@article{Thai-Van2010,
abstract = {This paper reviews psychoacoustical and electrophysiological evidence for reorganization of the human central auditory system in case of auditory deprivation and rehabilitation.},
author = {Thai-Van, Hung and Veuillet, Evelyne and Norena, Arnaud and Guiraud, Jeanne and Collet, Lionel},
doi = {10.3109/00016480903258024},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/EEG/2010 (Norena, other people) - Plasticity of tonotopic maps in humans.pdf:pdf},
issn = {1651-2251},
journal = {Acta oto-laryngologica},
keywords = {Acoustic Stimulation,Adult,Aged,Auditory Cortex,Auditory Cortex: physiopathology,Auditory Pathways,Auditory Pathways: physiopathology,Auditory Threshold,Auditory Threshold: physiology,Cochlear Implantation,Deafness,Deafness: physiopathology,Deafness: rehabilitation,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Hearing Aids,Hearing Loss, High-Frequency,Hearing Loss, High-Frequency: physiopathology,Hearing Loss, High-Frequency: rehabilitation,Humans,Male,Middle Aged,Neuronal Plasticity,Neuronal Plasticity: physiology,Pitch Discrimination,Pitch Discrimination: physiology,Psychoacoustics,Reaction Time,Reaction Time: physiology,Sound Spectrography},
month = mar,
number = {3},
pages = {333--7},
pmid = {19845491},
title = {{Plasticity of tonotopic maps in humans: influence of hearing loss, hearing aids and cochlear implants.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19845491},
volume = {130},
year = {2010}
}
@article{Shailer1983,
abstract = {The threshold for detection of a temporal gap in a noiseband was measured. A notched noise masker was used to restrict listening to a limited spectral region. Threshold was measured as a function of center frequency, bandwidth, and level. For a signal bandwidth of one-half the center frequency, the gap threshold decreased from 22.5 ms for a center frequency of 0.2 kHz to 3.2 ms at 8.0 kHz: a wideband condition provided an estimate of 2.3 ms, a value in agreement with previously published estimates. Bandwidth manipulation showed that the variation with frequency was not due to changes in absolute bandwidth alone. The effect of changes in level was determined at three frequencies, 0.4, 1.0, and 6.5 kHz, using a signal bandwidth of half the center frequency. At all frequencies gap threshold decreased as the signal spectrum level was raised from 10 to 25 dB, but a further increase to 40 dB showed no additional improvement. At frequencies up to about 1.0 kHz, the variation of gap threshold with frequency matches well the reciprocal of the bandwidth of the auditory filter, as determined from masking experiments using a notched-noise masker. This suggests that the temporal response of the auditory filter may limit gap detection at low frequencies.},
author = {Shailer, M J and Moore, B C},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1983 (Shailer, Moore) - Gap detection as a function of frequency, bandwidth, and level.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Auditory Perception,Auditory Threshold,Humans,Noise,Pitch Perception,Psychoacoustics,Time Perception},
month = aug,
number = {2},
pages = {467--73},
pmid = {6619424},
title = {{Gap detection as a function of frequency, bandwidth, and level.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6619424},
volume = {74},
year = {1983}
}
@article{Baer2002,
author = {Baer, Thomas and Moore, Brian C. J. and Kluk, Karolina},
doi = {10.1121/1.1498853},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Vowel Consonant Discrimination/2002 (Baer, Moore, Kluk) - How low-pass filtering of speech in noise for people with dead regions affects intelligibility.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {3},
pages = {1133},
title = {{Effects of low pass filtering on the intelligibility of speech in noise for people with and without dead regions at high frequencies}},
url = {http://link.aip.org/link/JASMAN/v112/i3/p1133/s1\&Agg=doi},
volume = {112},
year = {2002}
}
@article{Lewandowsky2010,
abstract = {We present a battery of four working memory tasks that are implemented using MATLAB and the free Psychophysics Toolbox. The package includes preprocessing scripts in R and SPSS to facilitate data analysis. The four tasks consist of a sentence-span task, an operation-span task, a spatial short-term memory test, and a memory updating task. These tasks were chosen in order to provide a heterogeneous set of measures of working memory capacity, thus reducing method variance and tapping into two content domains of working memory (verbal, including numerical, vs. spatial) and two of its functional aspects (storage in the context of processing and relational integration). The task battery was validated in three experiments conducted in two languages (English and Chinese), involving more than 350 participants. In all cases, the tasks were found to load on a single latent variable. In a further experiment, the latent working memory variable was found to correlate highly but not perfectly with performance on Raven's matrices test of fluid intelligence. We suggest that the battery constitutes a versatile tool to assess working memory capacity with either English- or Chinese-speaking participants. The battery can be downloaded from www.cogsciwa.com ("Software" button).},
author = {Lewandowsky, Stephan and Oberauer, Klaus and Yang, Lee-Xieng and Ecker, Ullrich K H},
doi = {10.3758/BRM.42.2.571},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Cognitive Tests/Stephan Lewandowski/Lewandowsky et al. - 2010.pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Adult,Asian Continental Ancestry Group,Female,Humans,Language,Male,Memory, Short-Term,Models, Psychological,Psychological Tests,Psychological Tests: statistics \& numerical data,Psychometrics,Psychometrics: instrumentation,Software,Verbal Behavior},
month = may,
number = {2},
pages = {571--85},
pmid = {20479189},
title = {{A working memory test battery for MATLAB.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20479189},
volume = {42},
year = {2010}
}
@article{Walton2010,
abstract = {This summary article reviews the literature on neural correlates of age-related changes in temporal processing in the auditory brainstem. Two types of temporal processing dimensions are considered, (i) static, which can be measured using a gap detection or forward masking paradigms, and (ii) dynamic, which can be measured using amplitude and frequency modulation. Corresponding data from physiological studies comparing neural responses from young and old animals using acoustic stimuli as silent gaps-in-noise, amplitude modulation, and frequency modulation are considered in relation to speech perception. Evidence from numerous investigations indicates an age-related decline in encoding of temporal sound features which may be a contributing factor to the deficits observed in speech recognition in many elderly listeners.},
author = {Walton, Joseph P},
doi = {10.1016/j.heares.2010.03.002},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/2010 (Walton) - Timing is everything - Temporal processing deficits in the aged auditory brainstem.pdf:pdf},
issn = {1878-5891},
journal = {Hearing research},
keywords = {Acoustic Stimulation,Age Factors,Aging,Animals,Auditory Pathways,Auditory Pathways: physiopathology,Brain Stem,Brain Stem: physiopathology,Comprehension,Cues,Evoked Potentials, Auditory, Brain Stem,Hearing Loss,Hearing Loss: physiopathology,Hearing Loss: psychology,Humans,Models, Animal,Noise,Noise: adverse effects,Perceptual Masking,Psychoacoustics,Signal Detection, Psychological,Speech Perception,Time Perception},
month = jun,
number = {1-2},
pages = {63--9},
pmid = {20303402},
publisher = {Elsevier B.V.},
title = {{Timing is everything: temporal processing deficits in the aged auditory brainstem.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20303402},
volume = {264},
year = {2010}
}
@article{Kobler2002,
abstract = {Speech intelligibility and horizontal localization of 19 subjects with mild-to-moderate hearing loss were studied in order to evaluate the advantages and disadvantages of bilateral and unilateral hearing aid (HA) fittings. Eight loudspeakers were arranged in a circular array covering the horizontal plane around the subjects. Speech signals of a sentence test were delivered by one, randomly chosen, loudspeaker. At the same time, the other seven loudspeakers emitted noise with the same long-term average spectrum as the speech signals. The subjects were asked to repeat the speech signal and to point out the corresponding loudspeaker. Speech intelligibility was significantly improved by HAs, bilateral amplification being superior to unilateral. Horizontal localization could not be improved by HA amplification. However, bilateral HAs preserved the subjects' horizontal localization, whereas unilateral amplification decreased their horizontal localization abilities. Front-back confusions were common in the horizontal localization test. The results indicate that bilateral HA amplification has advantages compared with unilateral amplification.},
author = {K\"{o}bler, S and Rosenhall, U},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Sound Localization/2002 - Horizontal localization and speech intelligibility with bilateral and unilateral HA amplification.pdf:pdf},
issn = {1499-2027},
journal = {International journal of audiology},
keywords = {Aged,Audiometry, Pure-Tone,Female,Hearing Aids,Hearing Loss, Bilateral,Hearing Loss, Bilateral: rehabilitation,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: rehabilitation,Humans,Male,Middle Aged,Noise,Sound Localization,Speech Intelligibility},
month = oct,
number = {7},
pages = {395--400},
pmid = {12403607},
title = {{Horizontal localization and speech intelligibility with bilateral and unilateral hearing aid amplification.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12403607},
volume = {41},
year = {2002}
}
@article{MooreBrianC.J.GlasbergB.R.AlcantaraJ.I.LaunerS.Kuehnel2001,
annote = {        Introduction        
- for small noise bandwidths especially, there's a tendency to confuse fluctuations in noise as a gap (Shailer and Moore, Buus and Florentine, Eddins and Green, Moore)
- subjects with hearing loss tend to have greater gap thresholds for noise (Buus and Florentine, Glasberg et al., Glasberg and Moore), but the same thresholds for sinusoids, which don't have inherent noise fluctuations (Moore and Glasberg, Moore et al.)
- Glasbert et al and Moore and Glasberg suggested the worse thresholds for noise may be due to loudness recruitment (Fowler, 1936; Fletcher and Munson, 1937), amplifying the inherent noise fluctuations
- to test this hypothesis, they did a study which extracted the Hilbert envelope to simulate recruitment and compression without introduction of significant distortion
- for moderate-severe hearing losses, a change in 50 dB in the input gives the same range of loudness as a 100 dB change in a normal ear
- gap thresholds increased with increasing recruitment in this study, and the effect was larger in narrow bandwidths, and thresholds were actually decreased with instantaneous compression
- slow-envelope fluctuations are compressed more than fast-envelope fluctuations (Braida et al., 1982; Stone and Moore, 1992)
- a higher centre frequency was used for this study than in 1992 so that many bandwidths could be used without exceeding the bandwidth of the auditory filter (Glasberg and Moore, 1990); it was done this way otherwise the auditory filter may have prominent envelope fluctuations even if the input was heavily compressed          
          
Methods        
- subjects with moderate hearing loss and normal hearing
- subjects were trained on the task until they showed no further improvement (a few hours)
- using a Phonak Clara (20 channel), slow compression(300sec attack, 3sec release), fast compression (15sec attack, 30sec release), and unaided conditions
- the compression conditions had a compression ratio of 2
- for these parameters, the IG for the normal subjects was 0 for a 70 dB SPL 4 kHz sound, but for those with impairments the IG was 20 dB for the same sound          
Stimuli        
- bands of noise, 10,20,50,100,200,500 Hz wide
- on each trial, 2 bursts of noise were presented 500 ms long separated by 500 ms
- gap was in the middle of the stimulus, ramped off and on with a cosine function, object was to detect which stimulus had the gap
- gap was presented in background noise to mask spectral splatter, headphone was placed over the hearing aid for the aided conditions
- earphone was calibrated using a KEMAR mannequin
- for normally hearing subjects, sounds were presented at 70 dB SPL at the estimated level of the eardrum, and the spectrum level of the noise at 4 kHz was 18 dB
- effective level of the background at the output of the auditory filter was 45 dB, giving a 25 dB signal to background ratio
- the signal to background ratio was the same for the hearing impaired subjects; the stimuli were made equal in loudness and level by increasing the level of the stimulus until they reported similar loudness levels to those in the aided condition          
Procedure        
- 2AFC 3-down 1-up, increased by a factor of 1.4 then 1.2 after 4 turn points, 3 threshold estimates
                  
Results        
- increasing gap thresholds from 500 to 50 Hz, which is to be expected, because the envelope is changing slower which makes the gaps in the noise more confusable
- increasing gap thresholds from 10 to 50 Hz, and the suggested explanation is that subjects use a cue of rate of change in envelope amplitude, meaning the gap is less confusable when the envelope fluctuates very slowly
- for the normally hearing subjects, there was no difference in threshold between conditions
- for the impaired subjects, the slow and unaided conditions were similar, which is as expected because the slow compression doesn't markedly affect the envelope fluctuations
- thresholds for the fast condition tended to be lower, especially for narrow bands of noise, and complements the work of Glasberg and Moore (1992) which used instantaneous compression
- post-hoc tests revealed that gap thresholds were smaller for fast compression up to 50 Hz, but there were no differences for the greater bandwidths
                  
Discussion        
- single-channel fast acting compression probably would have done the same as this multi-channel compression here
- one difference between this study and the 1992 Glasberg and Moore paper is that they found reduced thresholds with instantaneous compression in narrow bands of noise for normally hearing subjects; this difference may be a result of the higher sensation level in the current experiment, or side-effects of fast-compression such as overshoot and undershoot
- a ton of stuff about modulation rate that I don't understand.
- for hearing impaired subjects, gap detection thresholds are correlated with ability to understand speech in noise, which may explain why fast compression slightly improves speech intelligibility, although these benefits have not always been found
        
      },
author = {{Moore, Brian C. J., Glasberg, B. R., Alcantara, J. I., Launer, S., Kuehnel}, V.},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/2001 (Moore, Glasberg, Alcantara, Launer, Kuehnel) - Effects of slow- and fast-acting compression on the detection of gaps in narrow bands of noise.pdf:pdf},
journal = {British Journal of Audiology},
number = {6; ProQuest Nursing \& Allied Health Source},
pages = {365--374},
title = {{Effects of slow- and fast-acting compression on the detection of gaps in narrow bands of noise}},
volume = {35},
year = {2001}
}
@article{Moore1998,
abstract = {A model for predicting loudness for people with cochlear hearing loss is applied to the problem of prescribing the frequency-gain characteristic of a linear hearing aid. It is argued that a reasonable goal is to make all frequency bands of speech equally loud while achieving a comfortable overall loudness; this can maximize the proportion of the speech spectrum that is above the absolute threshold for a given loudness. In terms of the model this means that the specific loudness pattern evoked by speech of a moderate level (65 dB SPL) should be reasonably flat (equal loudness per critical band), and the overall loudness should be similar to that evoked in a normal listener by 65 dB speech (about 23 sones). The model is used to develop a new formula - the 'Cambridge formula' - for prescribing insertion gain from audiometric thresholds. It is shown that, for a fixed overall loudness of 23 sones, the Cambridge formula leads to a higher calculated articulation index than three other commonly used prescriptive methods: NAL(R), FIG6 and DSL.},
author = {Moore, B C and Glasberg, B R},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Hearing Aids and Hearing Loss/Fitting Procedures/1998 (Moore, Glasberg) - Use of a loudness model for hearing-aid fitting..pdf:pdf},
issn = {0300-5364},
journal = {British journal of audiology},
keywords = {Auditory Threshold,Hearing Aids,Humans,Loudness Perception,Loudness Perception: physiology,Prosthesis Fitting,Speech Perception,Speech Perception: physiology},
month = oct,
number = {5},
pages = {317--35},
pmid = {9845030},
title = {{Use of a loudness model for hearing-aid fitting. I. Linear hearing aids.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9845030},
volume = {32},
year = {1998}
}
@article{Billings2011,
abstract = {There is interest in using cortical auditory evoked potentials (CAEPs) to evaluate hearing aid fittings and experience-related plasticity associated with amplification; however, little is known about hearing aid signal processing effects on these responses. The purpose of this study was to determine the effect of clinically relevant hearing aid gain settings, and the resulting in-the-canal signal-to-noise ratios (SNRs), on the latency and amplitude of P1, N1, and P2 waves. DESIGN \& SAMPLE: Evoked potentials and in-the-canal acoustic measures were recorded in nine normal-hearing adults in unaided and aided conditions. In the aided condition, a 40-dB signal was delivered to a hearing aid programmed to provide four levels of gain (0, 10, 20, and 30 dB). As a control, unaided stimulus levels were matched to aided condition outputs (i.e. 40, 50, 60, and 70 dB) for comparison purposes.},
annote = {        Introduction        
-cortical auditory evoked potentials (CAEPs) may be useful for evaluating hearing aid fittings as well as investigating experience-related plasticity associated with amplification
-reports of recording aided CAEPs dates back to 1967, and the idea has been revisited over and over [references]
-the utility of CAEPs has yet to be established, and one reason is conflicting evidence showing that CAEPs are affected by amplification in some individuals but not others
-it's important to understand, given these inconsistencies, how the signal processing of the aids is affecting the evoked responses, which remains unclear
-in order for CAEPs to be of use clinicially, we need to know how the signal processing affects the CAEPs
-signal level is obviously important, because decades of research shows latency increases and amplitude decreases with decreasing signal level [references]
-in background noise, SNR is a key contributor to the morphology of CAEPs [references]
-noise is always present in an amplified signal and contributors range from ambient to circuit noise
-results from a previous study by Billings showed CAEPs were primarily sensitive to SNR, not absolute signal level
-the contributions of SNR to aided CAEP may explain a significant portion of variability in the literature
-in the present experiment, the authors aimed to determine:
(1) effect of output level on aided CAEPs, by manipulating hearing aid gain
(2) the contribution of in-the-canal SNR levels to resulting CAEP measures
-signal level was held constant while hearing aid gain settings were manipulated
-the authors hypothesized that amplification and gain would affect latencies and amplitudes through SNR
                  
Methods        
-repeated measures, participants tested under 9 conditions (5 unaided [30,40,50,60,70], 4 aided [40+0,+10,+20,+30])
-amplitudes and latencies were measured for evoked responses P1, N1, P2 and in-the-canal SNRs were also measured for all participants/conditions          
Participants        
-9 participants with normal-hearing, mean age 24
-participants had normal hearing from 250-8000Hz, normal immittance measures (single peak, present ipsilateral acoustic reflexes)
-tympanometry and air conduction testing was done prior to each session to ensure middle-ear function and hearing sensitivity
-used normal hearing subjects, as in their prior studies to control for effects of hearing impairment on the evoked response
        Stimuli        
-1000Hz tone with rise/fall times of 7.5ms and duration of 756ms
-CAEP stimuli need not be longer than 50ms, a longer stimulus was used as a more ecologically valid stimulus, and to compare to prior research
-the 30dB condition was included because it resulted in an ITC SNR that was less than the 40+0dB aided condition, ensuring all aided SNRs fell in the range of unaided SNRs
-stimuli were presented in the sound field, in a double-walled sound-treated booth through a speaker at 0deg azimuth 1m away
-sounds were calibrated with a sound level meter with linear weighting using a fast time constant, and the left ear was always plugged with a foam ear plug          
ITC Measurement Procedures        
-similar to their prior studies, acoustic recordings were made using Etymotic ER7c probe microphone to measure stimulus level in the ear canal
-output of the ER7c probe microphone was digitized by TDT RP2 and then recorded and analyzed in Matlab
-tone and noise levels calculated as 1/3 octave band measures centred at 1000Hz
-noise measurements were taken from 400ms analysis windows immediately preceding or following the 1000Hz tone
-ITC acoustic measurements were used to match aided/unaided conditions, and were done during electrophysiological testing for an online measure of levels at the eardrum (chance of head movement during testing)
-online measurements were completed at the beginning and end of each of the two blocks for each condition, and the four values did not vary by more than 2 dB SPL          
Hearing Aid        
-BTE coupled to a foam stock earmold was used, and was the same hearing aid programmed to the same freq. response used in the previous study (Billings et al., 2007)
-freq. range is stated, set to omni, disabled volume control, noise reduction and feedback suppression were disabled
-compression kneepoint, ratio, and attack/release times are also stated
-with an input level of 40 dB SPL, hearing aid processing was probably linear for all conditions tested
-processing delay (tested with Fonix 7000) revealed a sig processing delay of 0.5ms across the four gain settings
-majority of background noise in the canal was due to internal circuit noise rather than amplified ambient noise
-Figure 1 shows increasing noise as gain is increased (nonlinear relationship)          
Electrophysiology        
-each stimulus presented in homogenous train for total of 500 stim presentations for each stimulus condition; done across two blocks of 250 presentations
-5 min break between blocks, 1910ms ISI was used
-there was an unaided day and an aided day, and order was randomized between and within; subjects told to ignore the stimuli and watch a close-captioned movie
-recordings done with Electro-Cap International Inc. cap with 64 tin electrodes
-ground electrode was the forehead and Cz was reference, and rereferenced offline to the nose electrode
-eye movements monitored with electrodes placed at the canthi of both eyes
-recording window was 100ms prestim and 700ms poststim
-evoked responses band-pass filtered online from 0.15 to 100Hz (12 dB/octave roll off)
-using Neuroscan, all channels amplified 500x and converted with a sampling rate of 1000Hz
-ocular artifacts were rejected, and remaining sweeps were averaged and filtered offline from 1Hz (24 dB/octave) to 30Hz (12 dB/octave)          
Data analysis and interpretation        
 -responses analyzed from Cz to compare to previous literature
-fronto-central sites such as Cz are often used to estimate hearing thresholds, and experience-related changes in clinic and in research
-global field power measures were also used to quantify simultaneous activity from all electrode sites (Skrandies, 1989), which is the stdev across channels as a function of time
-wave P1, N1, and P2 were analyzed at Cz, and for GFP, N1 and P2 were analyzed from the GFP waveform
-P1 is not included because it's not robust enough to be present in GFP measures
                  
Results        
-in general, amplitude increased and latency decreased as output level increased; the only exception was the aided 70 dB output condition, which had longer latencies than expected
-only interaction between aided/unaided and output was for P2 amplitude
-there were significant differences between evoked activity between unaided and aided with equal output levels -- longer latencies and smaller amplitudes for aided CAEPs for all measures except N1 amplitude
-did a linear regression with log(latency) = a + b1(SNR) + b2(condition) + b3(interaction), but b3 was removed because the interaction was insignificant
-SNR was significant for all waves
-SNR range was 4.5 to 49.9 for unaided, 8.8 to 22.2 for aided
                  
Discussion        
-in general, latency decreased and amplitude increased with increasing output levels; however, the 70 dB aided condition did not behave this way, as latencies were longer than expected
-since CAEPs depend on signal level, unaided and aided CAEPs with the same level should be similar, but it is shown this is not the case
-the morphology of the aided CAEPs was generally weaker (longer latencies and smaller amplitudes) than unaided CAEPs 
-when SNR was taken into account in the regression, there was no significant effect of amplification (aided vs. unaided) on morphology
-the authors speculate that the reduction in SNR in the aided condition is due to circuit noise and some ambient noise
-at least for amplitude, the effect of amplification was greatest for P2 as opposed to N1
-it will be important to conduct this kind of study in hearing impaired individuals because noise levels might not be audible
-it would also be important to consider how SNR varies across frequency and time
-in particular, signal processing that affects the first 30-50ms of the stimulus might be especially important for determining morphology of the evoked response, therefore compression characteristics are important, and even linear hearing aids have shown changes to the stimulus in these small time windows},
author = {Billings, Curtis J and Tremblay, Kelly L and Miller, Christi W},
doi = {10.3109/14992027.2011.568011},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/EEG/2011 (Billings, Tremblay, Miller) - Aided cortical auditory evoked potentials in response to changes in hearing aid gain.pdf:pdf},
issn = {1708-8186},
journal = {International journal of audiology},
keywords = {Acoustic Stimulation,Adult,Audiometry,Auditory Pathways,Auditory Pathways: physiology,Auditory Threshold,Electroencephalography,Equipment Design,Evoked Potentials, Auditory,Female,Hearing Aids,Humans,Male,Noise,Noise: adverse effects,Reaction Time,Signal Processing, Computer-Assisted,Time Factors,Young Adult},
month = jul,
number = {7},
pages = {459--67},
pmid = {21486122},
title = {{Aided cortical auditory evoked potentials in response to changes in hearing aid gain.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3121886\&tool=pmcentrez\&rendertype=abstract},
volume = {50},
year = {2011}
}
@article{Wiener1946,
author = {Wiener, F.M. and Ross, D.A.},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Hearing Aids and Hearing Loss/Neuro-Compensator/1946 (Wiener, Ross) - The Pressure Distribution in the Auditory Canal in a Progressive Sound Field.pdf:pdf},
journal = {The Journal of the Acoustical Society of America},
number = {May},
pages = {401},
title = {{The pressure distribution in the auditory canal in a progressive sound field}},
url = {http://link.aip.org/link/?JASMAN/18/401/1},
volume = {18},
year = {1946}
}
@article{Leek2001,
abstract = {As research on sensation and perception has grown more sophisticated during the last century, new adaptive methodologies have been developed to increase efficiency and reliability of measurement. An experimental procedure is said to be adaptive if the physical characteristics of the stimuli on each trial are determined by the stimuli and responses that occurred in the previous trial or sequence of trials. In this paper, the general development of adaptive procedures is described, and three commonly used methods are reviewed. Typically, a threshold value is measured using these methods, and, in some cases, other characteristics of the psychometric function underlying perceptual performance, such as slope, may be developed. Results of simulations and experiments with human subjects are reviewed to evaluate the utility of these adaptive procedures and the special circumstances under which one might be superior to another.},
annote = {Introduction
        
        
Origins of Adaptive Procedures
        
        
Modern Procedures (PEST, maximum likelihood)
        
        
Staircase Procedures
        
        
Estimations of Slope from Adaptive Procedures
        
        
Violation of Assumptions in Adaptive Methods
        
        
Comparisons of Adaptive Procedures
- 1988 study by Kollmeier, Gilkey, Sieben showed the most efficient procedure out of adaptive (PEST, 2 staircases) / non-adaptive procedures was a 79\% 3AFC task when obtaining thresholds for simultaneous masking
- the psychometric function itself may be varying over time, due to rapid trial-to-trial variability and a slower varying function, Hall (1993) had previously suggested this as well
- a number of other authors have found that the 79\% 3AFC works best, as well as finding that adaptive procedures tend to result in lower thresholds than fixed procedures
- the paper generally suggests that 2AFC 71\% staircases should not be used, but 3AFC are good},
author = {Leek, M R},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Adaptive Procedures/2001 (Leek) - adaptive procedures in psychophysical research.pdf:pdf},
issn = {0031-5117},
journal = {Perception \& psychophysics},
keywords = {Attention,Humans,Likelihood Functions,Perception,Psychophysics,Psychophysics: statistics \& numerical data,Sensation,Sensory Thresholds},
month = nov,
number = {8},
pages = {1279--92},
pmid = {11800457},
title = {{Adaptive procedures in psychophysical research.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11800457},
volume = {63},
year = {2001}
}
@article{Grey1977,
author = {Grey, J M},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grey - 1977 - Multidimensional perceptual scaling of musical timbres.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Animals,Auditory Perception,Dogs,Humans,Music,Psychophysics},
month = may,
number = {5},
pages = {1270--7},
pmid = {560400},
title = {{Multidimensional perceptual scaling of musical timbres.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/560400},
volume = {61},
year = {1977}
}
@article{Shabana2011,
author = {Shabana, Mohamed Ibrahim and Shalaby, Amani Ahmed and Dabbous, Abeir Osman and Emara, Abir Abd-El-Meneim},
doi = {10.3109/1651386X.2011.625673},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/2011 (Shabana et al.) - Does hearing aid experience alter unaided auditory perception.pdf:pdf},
issn = {1651-386X},
journal = {Audiological Medicine},
keywords = {auditory fusion,hearing aids,pattern test,time compressed sentence test},
month = dec,
number = {4},
pages = {147--155},
title = {{Does hearing aid experience alter un-aided auditory perception?}},
url = {http://informahealthcare.com/doi/abs/10.3109/1651386X.2011.625673},
volume = {9},
year = {2011}
}
@article{Sabin2005,
abstract = {Physiological studies of spatial hearing show that the spatial receptive fields of cortical neurons typically are narrow at near-threshold levels, broadening at moderate levels. The apparent loss of neuronal spatial selectivity at increasing sound levels conflicts with the accurate performance of human subjects localizing at moderate sound levels. In the present study, human sound localization was evaluated across a wide range of sensation levels, extending down to the detection threshold. Listeners reported whether they heard each target sound and, if the target was audible, turned their heads to face the apparent source direction. Head orientation was tracked electromagnetically. At near-threshold levels, the lateral (left/right) components of responses were highly variable and slightly biased towards the midline, and front vertical components consistently exhibited a strong bias towards the horizontal plane. Stimulus levels were specified relative to the detection threshold for a front-positioned source, so low-level rear targets often were inaudible. As the sound level increased, first lateral and then vertical localization neared asymptotic levels. The improvement of localization over a range of increasing levels, in which neural spatial receptive fields presumably are broadening, indicates that sound localization does not depend on narrow spatial receptive fields of cortical neurons.},
author = {Sabin, Andrew T and Macpherson, Ewan a and Middlebrooks, John C},
doi = {10.1016/j.heares.2004.08.001},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Sound Localization/2004 - Human sound loc at near-threshold levels.pdf:pdf},
issn = {0378-5955},
journal = {Hearing research},
keywords = {Adult,Audiometry, Pure-Tone,Auditory Cortex,Auditory Cortex: physiology,Auditory Threshold,Auditory Threshold: physiology,Female,Humans,Male,Sound Localization,Sound Localization: physiology,Time Factors},
month = jan,
number = {1-2},
pages = {124--34},
pmid = {15574307},
title = {{Human sound localization at near-threshold levels.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15574307},
volume = {199},
year = {2005}
}
@article{Billings2007,
abstract = {Hearing aid amplification can be used as a model for studying the effects of auditory stimulation on the central auditory system (CAS). We examined the effects of stimulus presentation level on the physiological detection of sound in unaided and aided conditions. P1, N1, P2, and N2 cortical evoked potentials were recorded in sound field from 13 normal-hearing young adults in response to a 1000-Hz tone presented at seven stimulus intensity levels. As expected, peak amplitudes increased and peak latencies decreased with increasing intensity for unaided and aided conditions. However, there was no significant effect of amplification on latencies or amplitudes. Taken together, these results demonstrate that 20 dB of hearing aid gain affects neural responses differently than 20 dB of stimulus intensity change. Hearing aid signal processing is discussed as a possible contributor to these results. This study demonstrates (1) the importance of controlling for stimulus intensity when evoking responses in aided conditions, and (2) the need to better understand the interaction between the hearing aid and the CAS.},
author = {Billings, Curtis J and Tremblay, Kelly L and Souza, Pamela E and Binns, Malcolm a},
doi = {10.1159/000101331},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/EEG/2006 (Billings, Tremblay, Souza, Binns) - Effects of HA Amplification and Stimulus Intensity on Cortical AEPs.pdf:pdf},
issn = {1421-9700},
journal = {Audiology \& neuro-otology},
keywords = {Acoustic Stimulation,Adult,Auditory Cortex,Auditory Cortex: physiology,Ear Canal,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Hearing,Hearing Aids,Hearing: physiology,Humans,Loudness Perception,Loudness Perception: physiology,Male,Reaction Time,Reaction Time: physiology},
month = jan,
number = {4},
pages = {234--46},
pmid = {17389790},
title = {{Effects of hearing aid amplification and stimulus intensity on cortical auditory evoked potentials.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17389790},
volume = {12},
year = {2007}
}
@article{Robinson2007,
abstract = {Transposition of high-frequency information to lower frequencies may help people with high-frequency hearing loss associated with a 'dead region' (DR) to detect and identify certain consonants, such as 's'. Conventional high-frequency amplification is often not beneficial in such cases. We designed and evaluated a new transposition algorithm which was adapted to each subject's high-frequency DR. Frequency components from well within the DR were transposed to just within the DR without applying frequency compression. Low-frequency components were amplified, but unaffected by transposition. Transposition only occurred if there was significant high-frequency energy, preventing high-frequency background noise of moderate level from being transposed. Consonant discrimination was tested using vowel-consonant-vowel (VCV) stimuli, and the detection of word-final 's' and 'z' was assessed using word pairs. Seven subjects with high-frequency DRs were tested in quiet using a transposed and a control condition. Following transposition, two subjects improved significantly and none performed significantly worse on the VCV-test overall. The perception of affricates was consistently improved. Averaged across subjects, the detection of word-final 's' and 'z' was significantly improved, with five subjects improving significantly individually.},
annote = {Background
- severe hearing loss = avg of 75 dB HL across 4, 6, 8 kHz in the worse hearing ear; occurs in 24\% above 60 years old
        
diagnosing dead regions - TEN(HL) test (Moore et al, 2004), or classical PTCs or 'fast' PTCs
        
Other Attempts at Frequency Transposition
        
        Experiment 1 - VCV discrimination task                                                                              
stimuli                        
- VCV nonsense stimuli were used (Vickers et al, 2001; Baer et al, 2002)
- each of 3 vowels /i/ /a/ /u/, were combined with each of 21 consonants
- initial and final vowels were always the same
- each combination of vowel and consonant was presented once in each list, 63 VCV per list
- four different recordings of each VCV combination were distributed across 12 randomized lists                                                                              
presentation of stimuli                        
- subject-specific gains prescribed by 'Cambridge' formula (Moore and Glasberg, 1998)
IG(f) = HL(f) * 0.48 + INT(f)
IG(f) is insertion gain at each frequency
HL(f) is subject's hearing loss
INT(f) is a frequency-dependent intercept                                                                              
procedure                        
- trained on the transposed stimuli
- after being presented with the VCV stimulus, participants asked to choose one of the 21 possible consonants by clicking on the appropriate button using a mouse (examples of their pronunciation were presented on the screen)
- feedback is given both on correct and incorrect responses
- there was no learning effect demonstrated
                  
Experiment 2 - S and Z-test                                                                              
stimuli                        
- 24 pairs of words, 12 of which differ in their final /s/ while 12 differ in their final /z/
- within each block each word was presented once and order was randomized                                                                              
procedure                        
- played one word of a word pair, both words displayed on the screen, subjects asked to identify which one they heard by selecting it with the mouse
- scores were converted to d', measure of discriminability from signal detection theory                                                                              
                                  
Problem:  how do we obtain these stimuli?  where is there a bank of these collections of standardized stimuli?},
author = {Robinson, Joanna D and Baer, Thomas and Moore, Brian C J},
doi = {10.1080/14992020601188591},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Vowel Consonant Discrimination/2007 (Robinson, Baer, Moore) - Using transposition to improve consonant discrimination and detection for listeners with high-frequency loss.pdf:pdf},
issn = {1499-2027},
journal = {International journal of audiology},
keywords = {Adult,Aged,Aged, 80 and over,Audiometry, Pure-Tone,Female,Hearing Loss, High-Frequency,Hearing Loss, High-Frequency: diagnosis,Hearing Loss, High-Frequency: therapy,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: diagnosis,Hearing Loss, Sensorineural: therapy,Humans,Male,Middle Aged,Perceptual Masking,Phonetics,Severity of Illness Index,Sound Spectrography,Speech Discrimination Tests,Speech Perception},
month = jun,
number = {6},
pages = {293--308},
pmid = {17530514},
title = {{Using transposition to improve consonant discrimination and detection for listeners with severe high-frequency hearing loss.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17530514},
volume = {46},
year = {2007}
}
@article{Bench1979,
author = {Bench, J. and Kowal, \AA. and Bamford, J.},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Speech-In-Noise Tests/1979 (Bench, Kowal, Bamford) - The BKB (Bamford-Kowal-Bench) Sentence Lists For Partially-Hearing Children.pdf:pdf},
journal = {British Journal of Audiology},
number = {3},
pages = {108--112},
publisher = {Informa UK Ltd UK},
title = {{The BKB (Bamford-Kowal-Bench) sentence lists for partially-hearing children}},
url = {http://informahealthcare.com/doi/abs/10.3109/03005367909078884},
volume = {13},
year = {1979}
}
@article{Gfeller1991,
author = {Gfeller, K and Lansing, C},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gfeller, Lansing - 1991 - Melodic, rhythmic, and timbral perception of adult cochlear implant users.pdf:pdf},
journal = {Journal of Speech and Hearing Research},
pages = {916--920},
title = {{Melodic, rhythmic, and timbral perception of adult cochlear implant users}},
url = {http://jslhr.highwire.org/cgi/content/abstract/34/4/916},
volume = {34},
year = {1991}
}
@article{Church1976,
abstract = {A psychophysical procedure was used to determine the difference limen for the duration of a signal that ranged from .5 to 8.0 sec. The accuracy of three rats in keeping track of the duration was assumed to be limited by three factors: (a) inattention to the signal on some trials, (b) variability in starting to time the duration when the signal begins (and/or in stopping to time the duration when the signal ends), and (c) factors related to signal duration itself. A generalized Weber model provided a better approximation to the growth in the difference limen as a function of signal than a generalized Counter model.},
author = {Church, R M and Getty, D J and Lerner, N D},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1976 (Church et al.) - Duration Discrimination by Rats.pdf:pdf},
issn = {0097-7403},
journal = {Journal of experimental psychology. Animal behavior processes},
keywords = {Animals,Attention,Auditory Perception,Behavior, Animal,Conditioning, Operant,Discrimination Learning,Electroshock,Humans,Male,Psychophysiology,Rats,Reward,Stereotyped Behavior,Time Factors},
month = oct,
number = {4},
pages = {303--12},
pmid = {988110},
title = {{Duration discrimination by rats.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/988110},
volume = {2},
year = {1976}
}
@article{Billings2012,
abstract = {The clinical usefulness of aided cortical auditory evoked potentials (CAEPs) remains unclear despite several decades of research. One major contributor to this ambiguity is the wide range of variability across published studies and across individuals within a given study; some results demonstrate expected amplification effects, while others demonstrate limited or no amplification effects. Recent evidence indicates that some of the variability in amplification effects may be explained by distinguishing between experiments that focused on physiological detection of a stimulus versus those that differentiate responses to two audible signals, or physiological discrimination. Herein, we ask if either of these approaches is clinically feasible given the inherent challenges with aided CAEPs. N1 and P2 waves were elicited from 12 noise-masked normal-hearing individuals using hearing-aid-processed 1000-Hz pure tones. Stimulus levels were varied to study the effect of hearing-aid-signal/hearing-aid-noise audibility relative to the noise-masked thresholds. Results demonstrate that clinical use of aided CAEPs may be justified when determining whether audible stimuli are physiologically detectable relative to inaudible signals. However, differentiating aided CAEPs elicited from two suprathreshold stimuli (i.e., physiological discrimination) is problematic and should not be used for clinical decision making until a better understanding of the interaction between hearing-aid-processed stimuli and CAEPs can be established.},
author = {Billings, Curtis J and Papesh, Melissa a and Penman, Tina M and Baltzell, Lucas S and Gallun, Frederick J},
doi = {10.1155/2012/365752},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/EEG/2012 (BillingsPapeshPenmanBaltzellGallun) - Clinical Use of Aided Cortical Auditory Evoked Potentials as Measure of Detection or Discrimination.pdf:pdf},
issn = {1687-921X},
journal = {International journal of otolaryngology},
month = jan,
number = {1},
pages = {365752},
pmid = {23093964},
title = {{Clinical use of aided cortical auditory evoked potentials as a measure of physiological detection or physiological discrimination.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3472537\&tool=pmcentrez\&rendertype=abstract},
volume = {2012},
year = {2012}
}
@article{Blamey2005,
author = {Blamey, P. J.},
doi = {10.1177/108471380500900203},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Hearing Aids and Hearing Loss/ADRO/2005 (Blamey) - Trends in Amplification ADRO for HAs and CIs.pdf:pdf},
issn = {1084-7138},
journal = {Trends in Amplification},
month = jun,
number = {2},
pages = {77--98},
title = {{Adaptive Dynamic Range Optimization (ADRO): A Digital Amplification Strategy for Hearing Aids and Cochlear Implants}},
url = {http://tia.sagepub.com/cgi/doi/10.1177/108471380500900203},
volume = {9},
year = {2005}
}
@misc{TheMendeleySupportTeam2010a,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Program Files/Mendeley Desktop/FAQ.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2010}
}
@article{Ferguson2002,
author = {Ferguson, Sarah Hargus and Kewley-Port, Diane},
doi = {10.1121/1.1482078},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Vowel Consonant Discrimination/2002 (Ferguson, Kewley-Port) - Vowel intelligibility in clear and conversational speech for NH and HI listeners.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {1},
pages = {259},
title = {{Vowel intelligibility in clear and conversational speech for normal-hearing and hearing-impaired listeners}},
url = {http://link.aip.org/link/JASMAN/v112/i1/p259/s1\&Agg=doi},
volume = {112},
year = {2002}
}
@article{Glasberg1992,
abstract = {The inherent fluctuations present in narrowbands of noise may limit the ability to detect gaps in the noise; 'dips' in the noise may be confused with the gap to be detected. For subjects with cochlear hearing loss, loudness recruitment may effectively magnify the fluctuations and this could partly account for the reduced ability to detect gaps in noise bands that is usually found in subjects with cochlear hearing loss. In the present experiments we tested these ideas by processing noise bands to alter the amount of envelope fluctuation. The envelopes of the noise bands were raised to a power, N. Powers greater than 1 result in expansion of the envelope (magnified fluctuations, simulating loudness recruitment), while powers less than 1 result in compression of the envelope (decreased fluctuations). Thresholds for detecting gaps in processed noise bands centered at 1 kHz were measured as a function of noise bandwidth and of N. To prevent the detection of spectral changes introduced by the gap or by the processing, stimuli were either presented in background noise, or at a low sensation level (20 dB). Three normally hearing subjects, two subjects with unilateral cochlear hearing loss and two subjects with bilateral cochlear hearing loss were tested. Gap thresholds generally increased with increasing N. This effect was large for small noise bandwidths (50 Hz or less) and smaller for larger noise bandwidths (200 Hz or more). For both the normal and impaired ears, gap thresholds at narrow bandwidths were improved relative to those for unprocessed noise bands (N = 1) by compressing the envelope fluctuations (N < 1). The results support the idea that fluctuations in narrowband noises affect gap detection, and that loudness recruitment may adversely affect the ability to detect gaps in noise bands. They also show that compression of the fluctuations in the noise can improve gap detection.},
author = {Glasberg, B R and Moore, B C},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1992 (Glasberg, Moore) - Effects of envelope fluctuations on gap detection.pdf:pdf},
issn = {0378-5955},
journal = {Hearing research},
keywords = {Acoustic Stimulation,Aged,Analysis of Variance,Auditory Threshold,Hearing,Hearing Loss,Hearing Loss, Bilateral,Hearing Loss, Bilateral: physiopathology,Hearing Loss: physiopathology,Humans,Noise},
month = dec,
number = {1},
pages = {81--92},
pmid = {1490904},
title = {{Effects of envelope fluctuations on gap detection.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1490904},
volume = {64},
year = {1992}
}
@article{Cox1995,
abstract = {To develop and evaluate a shortened version of the Profile of Hearing Aid Benefit, to be called the Abbreviated Profile of Hearing Aid Benefit, or APHAB.},
author = {Cox, R M and Alexander, G C},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Subjective Ratings/1995 (Cox, Alexander) - The Abbreviated Profile of Hearing Aid Benefit.pdf:pdf},
issn = {0196-0202},
journal = {Ear and hearing},
keywords = {Adult,Aged,Female,Hearing,Hearing Aids,Humans,Male,Middle Aged,Psychometrics,Rehabilitation of Hearing Impaired,Reproducibility of Results,Treatment Outcome},
month = apr,
number = {2},
pages = {176--86},
pmid = {7789669},
title = {{The abbreviated profile of hearing aid benefit.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21271802},
volume = {16},
year = {1995}
}
@article{Seeber2004,
author = {Seeber, Bernhard U. and Baumann, Uwe and Fastl, Hugo},
doi = {10.1121/1.1776192},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Sound Localization/2004 - Localization ability with bimodal hearing aids and bilateral cochlear implants.pdf:pdf},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {3},
pages = {1698},
title = {{Localization ability with bimodal hearing aids and bilateral cochlear implants}},
url = {http://link.aip.org/link/JASMAN/v116/i3/p1698/s1\&Agg=doi},
volume = {116},
year = {2004}
}
@article{Tremblay2006a,
abstract = {To determine if (1) evoked potentials elicited by amplified speech sounds (/si/ and /[symbol: see text]/) can be recorded reliably in individuals, (2) amplification alters neural response patterns, and (3) different amplified speech sounds evoke different neural patterns.},
author = {Tremblay, Kelly L and Billings, Curtis J and Friesen, Lendra M and Souza, Pamela E},
doi = {10.1097/01.aud.0000202288.21315.bd},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/EEG/2006 (Tremblay, Billings, Friesen, Souza) - Neural Representation of Amplified Speech Sounds.pdf:pdf},
issn = {0196-0202},
journal = {Ear and hearing},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Analysis of Variance,Audiometry, Pure-Tone,Auditory Threshold,Auditory Threshold: physiology,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Hearing Aids,Hearing Loss,Hearing Loss: physiopathology,Hearing Loss: rehabilitation,Humans,Male,Neurons,Neurons: physiology,Reproducibility of Results,Sound Spectrography,Speech Perception,Speech Perception: physiology},
month = apr,
number = {2},
pages = {93--103},
pmid = {16518138},
title = {{Neural representation of amplified speech sounds.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16518138},
volume = {27},
year = {2006}
}
@article{Nelson1997,
abstract = {Temporal resolution, or the ability to process rapidly changing stimuli, has been purported to be reduced in some listeners with hearing loss while being described as normal in others. Ensuring stimulus audibility by increasing stimulus levels results in near-normal temporal resolution abilities for many listeners with hearing loss, but may also result in uncomfortably loud stimulus levels. The current study was conducted to describe temporal resolution abilities of listeners with and without hearing loss as a function of stimulus loudness. The gap detection abilities of 8 listeners with normal hearing were compared with those of 8 listeners with mild to moderate hearing losses over a wide range of intensities using a 650-Hz wide high-frequency noise marker. At low intensities, listeners with hearing loss show poor gap detection ability. As intensity increases, most listeners' performance improves and stabilizes near normal at high loudness and sensation levels. At comfortable loudness, gap detection abilities of listeners with hearing loss are less than at loud levels and are considerably poorer than normal.},
author = {Nelson, P B and Thomas, S D},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/1997 (Nelson, Thomas) - Gap detection as a function of stimulus loudness for listeners with and without HL.pdf:pdf},
issn = {1092-4388},
journal = {Journal of speech, language, and hearing research : JSLHR},
keywords = {Adolescent,Adult,Auditory Threshold,Cochlea,Cochlea: physiopathology,Female,Hearing,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: diagnosis,Hearing Loss, Sensorineural: physiopathology,Hearing: physiology,Humans,Loudness Perception,Male,Middle Aged,Severity of Illness Index,Time Factors},
month = dec,
number = {6},
pages = {1387--94},
pmid = {9430758},
title = {{Gap detection as a function of stimulus loudness for listeners with and without hearing loss.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9430758},
volume = {40},
year = {1997}
}
@article{Smith2006,
abstract = {Infants have a good ability to detect brief silent gaps between 2 short identical sound markers (within-channel gap detection), with thresholds between 2 and 11 ms. The present experiment traces the development of temporal resolution for between-channel gaps (i.e., gaps delineated by spectrally disparate markers). This ability appears crucial for the perception of complex stimuli such as speech and is thought to reflect more central auditory processing.},
author = {Smith, Nicholas a and Trainor, Laurel J and Shore, David I},
doi = {10.1044/1092-4388(2006/079)},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Gap Detection/2006 (Smith, Trainor, Shore) - The Development of Temporal Resolution- Between-Channel Gap Detection in Infants and Adults.pdf:pdf},
issn = {1092-4388},
journal = {Journal of speech, language, and hearing research : JSLHR},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Age Factors,Analysis of Variance,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Female,Humans,Infant,Male,Psychoacoustics,Reaction Time,Reaction Time: physiology},
month = oct,
number = {5},
pages = {1104--13},
pmid = {17077218},
title = {{The development of temporal resolution: between-channel gap detection in infants and adults.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17077218},
volume = {49},
year = {2006}
}
@article{Revoile1991,
abstract = {Moderately to profoundly hearing-impaired (n = 30) and normal-hearing (n = 6) listeners identified [p, k, t, f, theta, s]  in [symbol; see text], and [symbol; see text]s tokens extracted from spoken sentences. The [symbol; see text]s were also identified in the sentences. The hearing-impaired group distinguished stop/fricative manner more poorly for [symbol; see text] in sentences than when extracted. Further, the group's performance for extracted [symbol; see text] was poorer than for extracted [symbol; see text] and [symbol; see text]. For the normal-hearing group, consonant identification was similar among the syllable and sentence contexts.},
author = {Revoile, S G and Kozma-Spytek, L and Holden-Pitt, L and Pickett, J M and Droge, J},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Vowel Consonant Discrimination/1990 (Revoile et al.) - VCVs vs CVCs for stop fricative distinctions by HI and NH listeners.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Audiometry, Pure-Tone,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: diagnosis,Humans,Phonetics,Psychoacoustics,Speech Discrimination Tests},
month = jan,
number = {1},
pages = {457--60},
pmid = {2002178},
title = {{VCVs vs CVCs for stop/fricative distinctions by hearing-impaired and normal-hearing listeners.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2002178},
volume = {89},
year = {1991}
}
@misc{TheMendeleySupportTeam2010b,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2010}
}
@article{Strait2012,
annote = {        Introduction        
-a mass of evidence showing musician superiority in auditory brainstem, an evolutionarily ancient subcortical structure, highlighting it as being involved in learning-related plasticity [references]
-musicians show more precise encoding of music, speech, and emotional communication sounds [references]
-evidence thus far has been correlational, so can't definitively say that musicians are better due to exposure, could be innate
-some studies have a bit stronger evidence in that functional differences between non-musicians and musicians are linked to extent of musical practice [references]
-the present study aimed to provide unambiguous evidence for musical training's impact on shaping brain function in musicians
-until this study, subcortical investigations have approached musicians as a homogenous population [references]
-current study looked at subgroups of musicians, with the hypothesis that training of the brainstem would be selectively tuned to the instruments that were practiced relative to other instruments
                  
Methods        
-21 adult musicians between 18 and 35, 10 pianists and 11 nonpianists, with normal hearing and normal ABRs
-nonpianists had no formal piano experience, and the groups didn't differ by age, total years of practice, or age of practice onset
-recorded ABR from musicians to 3 musical sounds (piano, bassoon, tuba; 100Hz 200ms)
-the sounds differed only in timbre, and presented in 3 blocks of 30min each
-presentation was monaural via an insert earphone, 80 dB SPL at a rate of 3.33Hz using Neuroscan Stim2
-stimuli were presented in alternating polarity and responses to each polarity were summed to limit contamination of the recording by cochlear microphonic and stimulus artifact (Skoe and Kraus, 2010)
-subjects watched videos to maintain a still, wakeful state
-brainstem responses collected using Scan 4.3, with a vertical, ipsilateral montage
-responses filtered offline from 70-2000Hz with a 12 dB roll-off, epoched from -50 to 250ms, and digitally sampled at 20000Hz
-events with amplitude exceeding +/-35 uV were rejected as artifacts
-stimuli were band-pass filtered to match ABR characteristics (70-2000Hz)
-broadband amplitude envelopes obtained with Hilbert transform on the stimulus and response waveforms and low-pass filtering at 200Hz
-each instrument had different envelope, known to differentiate instruments on the basis of perceptual timbre (Iverson and Krumhansl, 1993)
-stimulus and brainstem response envelopes were compared from 0-200ms in 40ms blocks which overlapped by 39ms; each block was cross-correlated using xcorr in Matlab to create a cross-correlogram (Skoe and Kraus, 2010)
-peak r values for each block, defined as max correlation within 6.5-10.5ms lag range (subcortical response delay), were averaged to generate a single correlation coefficient for each subject/stimulus pairing
-prior to analysis, average r values were Fisher transformed and normality was confirmed by Kolmogorov-Smirnov test
                  
Results        
-by cross-correlating the stimulus and the envelope of the brainstem response, could get an indication of how well the musicians' brainstems were encoding the stimuli
-found that the pianists had a higher correlation for piano sounds than did the nonpianists
-pianists and nonpianists did not differ for either of the other musical sounds
                  
Discussion        
-the plasticity with the brainstem is likely driven by cortical-brainstem reciprocity (Suga and Ma, 2003) which is strengthened with musical practice
-the biological mechanisms which drive this specialization are limited to: local reorganization of the auditory brainstem, or top-down modulation via corticofugal neuronal tracts is driven by higher-level control over basic sensory processing (Krishnan and Gandour, 2009)
-although both are likely involved, corticofugal tracts have proven critical for auditory learning (Bajo et al., 2010)
-the results of the study support that the brainstem is malleable to experience, and it is not innate differences between musicians and nonmusicians that drives the more robust encoding of sounds in musicians},
author = {Strait, Dana L and Chan, Karen and Ashley, Richard and Kraus, Nina},
doi = {10.1016/j.cortex.2011.03.015},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/EEG/2012 (StraitChanAshleyKraus) - Timbre Representation cABRs Pianists Non-pianists.pdf:pdf},
issn = {1973-8102},
journal = {Cortex; a journal devoted to the study of the nervous system and behavior},
keywords = {Acoustic Stimulation,Adolescent,Adult,Auditory Perception,Brain Stem,Brain Stem: physiology,Data Interpretation, Statistical,Education,Evoked Potentials, Auditory, Brain Stem,Evoked Potentials, Auditory, Brain Stem: physiolog,Female,Humans,Male,Music,Music: psychology,Neuronal Plasticity,Neuronal Plasticity: physiology,Young Adult},
month = mar,
number = {3},
pages = {360--2},
pmid = {21536264},
title = {{Specialization among the specialized: auditory brainstem function is tuned in to timbre.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21536264},
volume = {48},
year = {2012}
}
@misc{TheMendeleySupportTeam2010c,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2010}
}
@article{Looi2007,
abstract = {This study aimed to compare the quality ratings by cochlear implant (CI) and hearing aid (HA) users in response to musical sounds.},
author = {Looi, Valerie and McDermott, Hugh and McKay, Colette and Hickson, Louise},
doi = {10.1097/AUD.0b013e31803150cb},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Subjective Ratings/2007 (Looi et al.) - Comparisons of Quality Ratings for Music by Cochlear Implant and Hearing Aid Users.pdf:pdf},
issn = {0196-0202},
journal = {Ear and hearing},
keywords = {Adult,Auditory Perception,Female,Hearing Aids,Hearing Disorders,Hearing Disorders: therapy,Humans,Male,Music,Professional Competence},
month = apr,
number = {2 Suppl},
pages = {59S--61S},
pmid = {17496649},
title = {{Comparisons of quality ratings for music by cochlear implant and hearing aid users.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17496649},
volume = {28},
year = {2007}
}
@article{Bailey2005,
author = {Bailey, T and Hahn, U},
doi = {10.1016/j.jml.2004.12.003},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Vowel Consonant Discrimination/2004 (Bailey, Hahn) - Phoneme similarity and confusability.pdf:pdf},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {auditory,magnitude estimation,phoneme confusability,phoneme similarity,phonological features,speech errors},
month = apr,
number = {3},
pages = {339--362},
title = {{Phoneme similarity and confusability}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0749596X0400138X},
volume = {52},
year = {2005}
}
@incollection{Nilsson1994,
abstract = {A large set of sentence materials, chosen for their uniformity in length and representation of natural speech, has been developed for the measurement of sentence speech reception thresholds (sSRTs). The mean-squared level of each digitally recorded sentence was adjusted to equate intelligibility when presented in spectrally matched noise to normal-hearing listeners. These materials were cast into 25 phonemically balanced lists of ten sentences for adaptive measurement of sentence sSRTs. The 95\% confidence interval for these measurements is +/- 2.98 dB for sSRTs in quiet and +/- 2.41 dB for sSRTs in noise, as defined by the variability of repeated measures with different lists. Average sSRTs in quiet were 23.91 dB(A). Average sSRTs in 72 dB(A) noise were 69.08 dB(A), or -2.92 dB signal/noise ratio. Low-pass filtering increased sSRTs slightly in quiet and noise as the 4- and 8-kHz octave bands were eliminated. Much larger increases in SRT occurred when the 2-kHz octave band was eliminated, and bandwidth dropped below 2.5 kHz. Reliability was not degraded substantially until bandwidth dropped below 2.5 kHz. The statistical reliability and efficiency of the test suit it to practical applications in which measures of speech intelligibility are required.},
author = {Nilsson, M and Soli, S D and Sullivan, J A},
booktitle = {The Journal of the Acoustical Society of America},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Speech-In-Noise Tests/1994 (Nilsson, Soli, Sullivan) - Development of the Hearing In Noise Test for the measurement of speech reception thresholds in quiet and noise.pdf:pdf},
issn = {0001-4966},
keywords = {Acoustic Stimulation,Adolescent,Adult,Auditory Threshold,Female,Humans,Male,Middle Aged,Noise,Phonetics,Reproducibility of Results,Speech Acoustics,Speech Intelligibility,Speech Perception,Speech Reception Threshold Test,Speech Reception Threshold Test: standards},
month = feb,
number = {2},
pages = {1085--99},
pmid = {8132902},
title = {{Development of the Hearing in Noise Test for the measurement of speech reception thresholds in quiet and in noise.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8132902},
volume = {95},
year = {1994}
}
@article{Byrne1986,
abstract = {A new procedure is presented for selecting the gain and frequency response of a hearing aid from pure-tone thresholds. This was developed from research which showed that a previous procedure did not meet its aim of amplifying all frequency bands of speech to equal loudness but that frequency responses which did so were considerably more effective. Measurements of 30 sensorineurally hearing-impaired ears (27 subjects), together with data from other studies, were analyzed to determine the best formula for predicting the optimal frequency response, for each individual, from the audiogram. The analysis indicated that a flat audiogram would require a rising frequency response characteristic of about 8 dB/octave up to 1.25 kHz and thereafter a falling characteristic of about 2 dB/octave. Variations in audiogram slope required about one-third as much variation in response slope. Three frequency average (3FA) gain was calculated to equal the 3FA gain of the previous procedure. Forty-four subjects (67 aided ears) fitted by the new procedure were evaluated by paired comparison judgments of the intelligibility and pleasantness of speech. The prescribed frequency response was seldom inferior to, and usually better than, any of several variations having more, or less, low and/or high-frequency amplification. On the average, used gain was approximately equal to prescribed gain. It is concluded that the new formula should prescribe a near optimal frequency response with few exceptions.},
author = {Byrne, D and Dillon, H},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Hearing Aids and Hearing Loss/Fitting Procedures/1986 (Byrne, Dillon) - NAL New Procedure for Selecting the Gain and Frequency Response of a Hearing Aid.pdf:pdf},
issn = {0196-0202},
journal = {Ear and hearing},
keywords = {Audiometry, Pure-Tone,Auditory Threshold,Australia,Hearing Aids,Hearing Aids: standards,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: therapy,Humans,Loudness Perception,Pitch Discrimination,Psychoacoustics},
month = aug,
number = {4},
pages = {257--65},
pmid = {3743918},
title = {{The National Acoustic Laboratories' (NAL) new procedure for selecting the gain and frequency response of a hearing aid.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3743918},
volume = {7},
year = {1986}
}
@article{Ahlstrom2009,
abstract = {To assess the extent to which hearing aids improve spatial benefit by restoring the availability of interaural difference cues, the benefit attributable to spatial separation of speech and babble with and without bilateral hearing aids was measured as a function of low-pass cutoff frequency.},
author = {Ahlstrom, Jayne B and Horwitz, Amy R and Dubno, Judy R},
doi = {10.1097/AUD.0b013e31819769c1},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Research/Sound Localization/2009 - Spatial Benefit of Bilateral Hearing-Aids.pdf:pdf},
issn = {1538-4667},
journal = {Ear and hearing},
keywords = {Acoustic Stimulation,Adaptation, Physiological,Adaptation, Physiological: physiology,Aged,Aged, 80 and over,Audiometry, Pure-Tone,Auditory Threshold,Auditory Threshold: physiology,Hearing Aids,Hearing Loss, Sensorineural,Hearing Loss, Sensorineural: physiopathology,Hearing Loss, Sensorineural: rehabilitation,Humans,Noise,Patient Satisfaction,Phonetics,Predictive Value of Tests,Psychoacoustics,Questionnaires,Sound Localization,Sound Localization: physiology,Speech Perception,Speech Perception: physiology},
month = apr,
number = {2},
pages = {203--18},
pmid = {19194292},
title = {{Spatial benefit of bilateral hearing AIDS.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19194292},
volume = {30},
year = {2009}
}
@article{Chasin2004,
annote = {        2. DIFFERENCES BETWEEN MUSIC AND SPEECH FOR HEARING AIDS        
- compared with music, speech is a well-controlled spectrum with well-established and easily predictable characteristics
- music spectra is highly variable and perceptual characteristics depend highly on the type of music, the listener and the instrument(s) being played
- at least 5 differences between speech and music
        
        2.1. SPEECH VERSUS MUSIC SPECTRA        
- speech is constrained by the vocal tract (17cm from larynx to lips) (Kent and Read, 2002)
- speech can be two tubes or one tube, depending on the letter produced
- hearing aid engineers and health care professionals try to understand the long term speech spectrum, to provide optimal amplification to improve speech communication
- long-term music spectrum resembles low-pass filtered noise, and is a relatively meaningless norm
        
        2.2. PHYSICAL OUTPUT VERSUS PERCEPTUAL REQUIREMENTS OF THE LISTENER        
- languages vary in the proportion of audible speech cues important for speech perception
- the articulation index (AI) shows that most of the important sounds for speech intelligibility are derived from bands over 1000Hz, and most of the loudness perception is from bands below 1000Hz
- often those with hearing impairments for speech have low frequencies reduced and higher frequencies increased
- linguistically speaking, speech is phonetically dominant in the lower frequencies, phonemically dominant in the higher frequencies
- on the contrary, the phonemic spectrum of music is highly variable -- a violinist needs to be able to hear the precise relationship between the level of the harmonics and their spectral location
- a violinist has a broadband phonemic requirement of up to 6000Hz
- a clarinetist must be able to hear the lower frequency (1500Hz) inter-resonant breathiness
        
        2.3. LOUDNESS SUMMATION, LOUDNESS, INTENSITY
        - vocal cords are a half-wavelength resonator, meaning that harmonics are evenly spaced at integer multiples of the fundamental frequency
- with speech, there's a good correlation between perception of loudness and physical vocal intensity, so setting a hearing aid to restore speech loudness is easy to do
- some instruments are speech-like, having evenly spaced harmonics (oboes, saxophones, violins, guitars)
- clarinet is a quarter-wave resonator so has odd numbered harmonics, mainly for the lower frequency notes
- if multiple harmonics fall within the same critical band, there is less loudness summation (this occurs with bass, cellos, even though they are half-wavelength resonators)
- therefore, correlations between the physical intensity and perceptual intensity of bass and cello are low
- this seems sort of counterintuitive, but hard-of-hearing bass and cello players need less overall amplification than violin and guitar players to restore loudness perception, because their harmonics fall within fewer critical bands
                  
2.4. THE 'CREST FACTOR' OF SPEECH AND MUSIC        
- crest factor - difference in dB between the peak amplitude in a spectrum and the average (root mean square) value
- crest factor for speech is 12 dB, results from damping in the vocal tract due to soft tongue, nasal cavity, soft cheeks; one of the reasons for setting threshold knee points on hearing aid compression systems is predicated on the crest factor
- crest factor for musical instruments are more on the order of 18 to 20 dB, because of hard-walled horns, stiff resonators
- clinical experience shows that compression systems using RMS detectors as opposed to peak detectors are better for music
                  
2.5. DIFFERENT INTENSITIES FOR SPEECH AND MUSIC        
- speech's dynamic range is from about 50 dB to 83 dB, shouted speech accentuating the vowels
- music can be on the order of 100 dB SPL, peaks and valleys in the +/- 18 dB range
- music can cause the hearing aid to distort the sounds, because the maximum dynamic range is generally around 115 dB
- peak input-limiting level should be elevated to around 115 dB to prevent distortion of music
                  
3. MUSIC PARAMETERS        
- timbre - spectrum, temporal envelope, and transient components
- timbral distinctions best described along 3 dimensions: spectral energy distribution (bandwidth and intensity), synchronicity of temporal envelope across partials, onset characteristics (speed of attack) (Grey, 1977)
- linear distortions - changes in intensity or phase of individual frequency components without addition of new components
- to not distort timbre, must give balanced amplification to low- and high-frequency channels, and must be consistent
- pitch discrimination thresholds are increased when the spectral distribution of energy is changed from one tone to the next (Warrier and Zatorre, 2002)
- people are good at estimating interval size, but an ascending interval may sound larger than normal if one transitions from a bass-weighted spectrum to a treble-weighted spectrum (Russo and Thompson, 2004)
- classic view in psychoacoustics is that the auditory system is insensitive to phase, but in fact it has been shown that people are acutely sensitive to phase relationships, especially for bass and harmonically rich sounds (Galembo et al., 2001)
- phase distortions resulting from stereo systems playing in a room have little effect on people's perception, but phase distortions from hearing aids directly enter the ear canal; binaural phase distortions may result in perception of a moving auditory image, monaural phase distortion across channels may alter pitch
                  
3.2. NONLINEAR DISTORTIONS        
- nonlinear distortions - involve addition of new harmonics (normally of fundamental) not present in the original signal
- common source is peak clipping in a hearing aid (amplitude of signal is driven beyond what the receiver can handle)
- timbre may be severely affected by nonlinear distortions, especially instruments with finnicky harmonic distributions (like the clarinet), or inharmonic instruments (piano), which may result in beating between harmonic and inharmonic potentials, adds roughness to timbre and reduced pitch clarity
- standard alternative to peak clipping is compression
- there are prominent pitches in music, and compression of the intensity of these pitches impedes perception of relations between prominent pitches
- clinical experience suggest compression systems should be set with low compression ratio, and a high threshold knee setting (65-75 dB)
- if the hearing aid is vented (typical of mild-moderate hearing loss), a more effective compression ratio may be less (1.3:1), because unamplified sound enters the vent, bypassing hearing aid processing
- perception of pitch is degraded for inharmonic tones; distortion also results when two or more partials interact within a non-linear system (intermodulation), introducing inharmonic partials
- sensitivity to tonal relations degraded for pitch sequences composed of harmonic tones (Russo et al., 2000)
- effect of inharmonicity most audible for low-frequency tones below 100 Hz (Jarvelainen et al., 2001)
                  
4. HEARING AID PARAMETERS
4.1. PEAK INPUT-LIMITING LEVEL        
- most hearing-aid engineers have a peak input-limiter after the microphone, preventing inputs in excess of 85 dB from being transduced
- peak input-limiting level is not usually listed on the ANSI hearing aid specification sheets, need to talk to the engineering department of the manufacturer
- modern hearing aids can readily transduce up to 115 dB, so why limit the peaks to be 85 dB?
- to address the above question, an experimental hearing aid was developed where the peak input-limiting level could be set at 115, 105, 96, 92 dB SPL, and measures of distortion (signal-to-distortion ratio) and patient quality judgment scales were used
- distortion measurements are affected by many electroacoustic parameters, especially in nonlinear devices; normally use cross-correlation (and auto-correlation), but only works if the amplification scheme is linear
- for nonlinear hearing aids, a 'notch' paradigm can be used to gauge distortion and fidelity, filling in the spectrum with a well-defined 'notch' (Kates, 2000)
- notches can be created with a comb filter, or Adobe Audition for example
- a 0 db signal-to-distortion ratio means perfect fidelity
- measures of sound quality obtained with five, five-point perceptual scales relevant to music - modification of work of Gabrielsson and colleagues (1974, 1991) used extensively in the hearing aid industry
- signal-to-distortion levels reached -10 for 96 dB peak input-limiting, around -2 for 105 dB peak input-limiting
- they plotted the total perceptual quality score with the signal/distortion ratio, and there was a statistical difference between the upper two levels and the lower two levels
- appeal of loud music could be its ability to stimulate the vestibular as well as the auditory system; the sacculus -- a primitive mechanism in humans and fish -- responds to music played above 90 dB, especially for music with a dominant low-frequency end
- sacculus has connections to the hypothalamus, which is responsible for drives like hunger and sex
- to avoid the peak input-limiting problems, one can attenuate the sounds before they enter the microphone, such as with an Adhear wax guard brushed with Whiteout, providing 10-15 dB attenuation from 750 Hz to 6000 Hz
                  
4.2. THREE OTHER ELECTRO-ACOUSTIC PARAMETERS        
- it was determined in the last section that the peak input-limiting level is a major factor in determining optimal reconstruction of music; 3 more secondary factors are considered          
4.2.1 - Parameter 1        
- for music, one channel (or a multichannel device where the gain for each channel is roughly equivalent) is probably best          
4.2.2 - Parameter 2        
- knee-point on the input compression circuit should be set approximately 5-8 dB higher for music as opposed to speech, because of the greater crest factor for music; the higher knee-point prevents the hearing aid from going into compression prematurely          
4.2.3 - Parameter 3
- good argument can be made for a modified WDRC for musicians
- most musicians have a mild-to-moderate hearing loss with poorer acuity in mid- to high-frequency ranges; predominantly OHC damage
- slightly higher knee-point means that the wide dynamic range compression would be narrower or a higher-level version of this circuit
- too low peak input-limiters are as much a problem for analog hearing aids as for digital
- a popular but dated example of a hearing aid comprising all elements of the above stated parameters is the K-AMP circuit (Etymotic Research)
                  
4.3. FEEDBACK AND NOISE REDUCTION SYSTEMS        
- a lot of noise reduction systems are useful for many situations but may have drawbacks for some types of music
- some noise reduction systems erroneously reduce intensity of flute noises
- other feedback reduction systems minimize "feedback-like" sounds immediately after the hearing aid microphone
                  
5. IN-EAR MONITORS
              },
author = {Chasin, M.},
doi = {10.1177/108471380400800202},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chasin - 2004 - Hearing Aids and Music.pdf:pdf},
issn = {1084-7138},
journal = {Trends in Amplification},
month = jun,
number = {2},
pages = {35--47},
title = {{Hearing Aids and Music}},
url = {http://tia.sagepub.com/cgi/doi/10.1177/108471380400800202},
volume = {8},
year = {2004}
}
@article{Wang1973,
annote = {Introduction
-individual features differ significantly in intelligibility (references)
-relative importance of features varies as a function of phonetic context, \& signal distortion (references)
-on average, as the number of feature differences between two sounds increase, the greater the discriminability (references)
-MDS is another approach, because it chooses the perceptual dimensions for you, not requiring an arbitrary specification of features, but it does require interpretation
-MDS also depends on the distance metric used, so it can be a bit unstable
-the question of whether there exists a natural set of perceptual features is not testable, and hasn't been systematically explored
-the technique in Sec II is a sequential method of analyzing transmitted information (TI) for features, always extracting the highest performance feature on an iteration.  it allows one to determine what proportion of total TI is accounted for by the features specified as perceptually important.  the procedure's information analogue is a stepwise multiple regression analysis
-purpose of the study was to determine what features best account for performance on a consonant discrimination task, for different context and listening conditions
        
Results
A) Intelligibility - a lot of effects and interactions are presented here, with no accompanying analysis tables to back them up.  might be worth looking over when i write up my thesis.
B) Perceptual Confusions
C) Sequential Information Analysis
categorical variables X\&Y
let U denote uncertainty
U(X,Y)=U(X)+Ux(Y)=U(Y)+Uy(X)
Ux(Y) is computed by finding U(Y) for each level of X, using conditional probabilities, then taking a weighted average
-to do the analysis, start with a set of features (A,B,C) and stimuli (S), such that U(A,B,C)=U(S).  all this means is that each stimulus has a unique description in terms of features.
-given a confusion matrix, one can computer U(S:R), where R is the response; this metric is the transmitted information
-the procedure follows the following steps:
1) unconditional transmitted information is estimated for each feature in the proposed feature system; performance is assessed in terms of percentage of information transmitted, given by the quantity U(A:a)/U(A), which normalizes the features in case on stimulus feature naturally carries more information.  the feature with the highest percentage information transmitted is designated as "A"
2) holding A constant, calculate conditional transmitted information for the remaining features, terms which represent transmitted information independent of TI on feature A},
author = {Wang, M D and Bilger, R C},
file = {:C$\backslash$:/Users/Jeff/Documents/McMaster University/Neuro-Compensator Articles/Vowel Consonant Discrimination/1973 (Wang, Bilger) - Consonant confusions in noise - a study of perceptual features.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Acoustic Stimulation,Adolescent,Adult,Auditory Perception,Discrimination (Psychology),Female,Humans,Male,Perceptual Masking,Phonetics},
month = nov,
number = {5},
pages = {1248--66},
pmid = {4765809},
title = {{Consonant confusions in noise: a study of perceptual features.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/4765809},
volume = {54},
year = {1973}
}
@article{Rahne2011,
author = {Rahne, Torsten and B\"{o}hme, Lars and G\"{o}tze, Gerrit},
doi = {10.1016/j.jneumeth.2011.05.022},
file = {:C$\backslash$:/Users/Jeff/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rahne, B\"{o}hme, G\"{o}tze - 2011 - Timbre discrimination in cochlear implant users and normal hearing subjects using cross-faded synthetic tones.pdf:pdf},
issn = {01650270},
journal = {Journal of Neuroscience Methods},
month = aug,
number = {2},
pages = {290--295},
publisher = {Elsevier B.V.},
title = {{Timbre discrimination in cochlear implant users and normal hearing subjects using cross-faded synthetic tones}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016502701100327X},
volume = {199},
year = {2011}
}
@article{GFELLER,
abstract = {The purpose of this study was to compare postlingually deafened cochlear implant recipients and normal-hearing adults on timbre (tone quality) recognition and appraisal of 8 musical instruments representing 3 frequency ranges and 4 instrumental families. The implant recipients were significantly less accurate than the normal-hearing adults on timbre recognition. The implant recipients gave significantly poorer ratings than did the normal-hearing adults to those instruments played in the higher frequency range and to those from the string family. The timbre measures were weakly correlated with speech perception measures, but were significantly correlated with 3 cognitive measures of sequential processing.},
author = {GFELLER, Kate and WITT, Shelley and MEHR, Maureen A. and WOODWORTH, George and KNUTSON, John},
issn = {0003-4894},
journal = {The Annals of otology, rhinology \& laryngology},
keywords = {Auditory disorder,Chirurgie,Cirug\'{\i}a,Cochlea,Cochl\'{e}e,Comparative study,C\'{o}clea,ENT disease,Estudio comparativo,Etude comparative,Frecuencia,Frequency,Fr\'{e}quence,Healthy subject,Hombre,Homme,Human,Implant,Implantaci\'{o}n quir\'{u}rgica,Implantation chirurgicale,Implante,Individu sain,Individuo sano,Instrument musique,Instrumento musical,Internal ear disease,Musical instrument,ORL pathologie,ORL patolog\'{\i}a,Oido interno patolog\'{\i}a,Oreille interne pathologie,Perception hearing loss,Qualit\'{e} tonale,Recognition,Reconnaissance,Reconocimiento,Sensory hearing loss,Sordera coclear,Sordera percepci\'{o}n,Surdit\'{e} cochl\'{e}aire,Surdit\'{e} perception,Surgery,Surgical implantation,Tipo,Traitement,Trastorno auditivo,Tratamiento,Treatment,Trouble audition,Type},
language = {eng},
number = {4},
pages = {349--356},
publisher = {Annals Publishing Compagny},
title = {{Effects of frequency, instrumental family, and cochlear implant type on timbre recognition and appraisal}},
url = {http://cat.inist.fr/?aModele=afficheN\&cpsidt=13628657},
volume = {111}
}
