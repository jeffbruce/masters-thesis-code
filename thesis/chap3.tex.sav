\chapter{Methods for Comparing Hearing Aids}
\paragraph{}The current chapter describes the development and application of the multitude of behavioural and subjective tasks that were utilized to compare the WDRC and NC hearing aids.  These tasks were selected to cover the general auditory domains of speech intelligibility, music perception, sound localization, and sound quality.

\section{Speech Intelligibility}
\paragraph{}At the very outset of this research program, the goal was to compare the NC to WDRC on as many different important auditory domains as possible.  With hearing loss, there is a loss of speech intelligibility, in that speech becomes less audible and less clear.  Restoring one's ability to communicate with others is the most common reason for obtaining hearing aids, so a significant part of this research program sought to quantify how well the WDRC and NC hearing aids restored speech cues.

\subsection{Consonant Vowel Consonant (CVC)}
\paragraph{}Vowels obviously make up a very significant part of speech, and so it is important to probe the question of whether vowel recognition is superior with one hearing aid technology versus another.  A convenient task to answer this question, which has been widely used in the past, is called a CVC task.  In a CVC task, CVC words are presented aloud, and participants must identify which CVC word was presented out of a large set of CVC stimuli (the CVC words differ only on the vowel portion of the words).  CVC tasks are used to study vowel perception, as opposed to using whole sentences, because they allow the experimenter to manipulate only the vowel, ignoring any sentence-specific context effects.

CVC words of the form hVd have been used extensively in the context of CVC experiments.  The reasons for the commonplace use of hVd stimuli is that the /h/ sound does not significantly affect the upcoming vowel formants, and most of the hVd words are real English words, making the experimental setup easier to get accustomed to \cite{Potter1950}.

Before programming the hVd experiment, research was done to estimate the difficulty of an hVd task for aided hearing-impaired participants.  Recognition of vowels embedded in hVd stimuli by normally hearing subjects in quiet is very high (95\% at 77 dB(A) with 12 response alternatives; \citeA{Hillenbrand1995}), and aided hearing-impaired subjects are able to achieve high scores as well.  A study by \citeA{Ferguson2002} had normal hearing and hearing-impaired subjects listen to and discriminate monosyllabic CVC stimuli in multi-talker babble to determine whether vowels were more easily discriminated in clear speech than conversational speech.  In this study, aided hearing-impaired subjects were able to achieve greater than 90\% on vowel discrimination in quiet when the speech materials were presented at 70 dB SPL with 10 response alternatives.  Given the relative ease with which vowels are understood in quiet, even for aided hearing-impaired participants, the hVd task in the current study included a noise condition to make the task more difficult in case ceiling effects were present in the quiet condition.

%hearing aid attributes which affect vowel perception?  compression (fast vs. slow-acting, duration, spectral shape of formants, relative intensities of F1 and F2)

\subsection{Vowel Consonant Vowel (VCV)}
\paragraph{}Consonants differ from vowels, in that they generally have less acoustic energy \cite{Hamill2008}, yet they contain proportionally greater high frequency energy, and they contribute more to speech intelligibility \cite{Hamill2008}.  Since they are lower in level and contain more high frequency information than vowels, consonants are more vulnerable to reduced intelligibility with hearing loss, and the consequences of reduced intelligibility of consonants are more dire for overall speech recognition.  Given the importance of consonants for speech understanding, and their vulnerability with hearing loss, it is not surprising that there have been many hearing aid studies examining how different hearing aid processing strategies affect consonant recognition.

Experiments that investigate consonant recognition often choose to implement a VCV task, which is essentially the same concept as the CVC task described earlier.  Only the consonant in the VCV stimulus is experimentally manipulated (sometimes different vowels are used), and any context effect of sentence is eliminated since the word is presented in isolation.

Like the CVC task, research was done before programming the VCV task to estimate the difficulty of VCV tasks for aided hearing-impaired subjects.  One study conducted by \citeA{Vickers2001} amplified 65 dB SPL VCV stimuli (21 consonants, 3 vowels) according to the Cambridge prescription formula \cite{Moore1998}, and included participants with moderately-severe hearing losses.  Overall recognition performance was typically around 50-80\%.  An experiment by \citeA{Walden2001} looked at the effect of amplification and speechreading on consonant recognition for the hearing-impaired, for generally mild-moderate hearing losses.  Fourteen consonants were used with 1 vowel (/\ae /), and the VCV stimuli were presented in quiet in a sound booth.  When VCV stimuli were presented at 50 dB SPL at the participant's head while they wore hearing aids, overall recognition scores were close to 80\%.  Since the degree of hearing losses to be included in the study was not known in advance, a quiet and a noise condition was programmed for the CVC task used in this thesis in case floor or ceiling effects were present for one of the conditions.

%hearing aid attributes which affect vowel perception?  compression (fast vs. slow-acting, duration, spectral shape of formants, relative intensities of F1 and F2)

\subsection{Hearing In Noise Test (HINT)}
\paragraph{}Although CVC and VCV stimuli are useful for determining what spectrotemporal qualities of speech are restored with one hearing aid technology versus another, these tasks are not without disadvantages.  The main disadvantage of using CVC and VCV stimuli to assess speech recognition is that these tasks have low ecological validity.  The stimuli used in CVC and VCV tasks are rarely encountered in everyday environments, and they ignore any effect of context in understanding a sentence, which can play a large role in speech understanding.  Ultimately, most real-world speech is spoken in phrases and sentences, often in situations with multiple, sometimes non-stationary, noise sources.  Therefore, for a comprehensive comparison of two hearing aid technologies, it is good to have a combination of realistic speech tests and more controlled speech tests.

Many tasks have been created to assess real-world speech intelligibility, and one such task is the HINT \cite{Nilsson1994}.  The HINT is an industry standard speech recognition test that has participants listen to audio clips of sentences embedded in speech-shaped noise (SSN), and repeat back the sentences that they heard.  By adaptively adjusting the presentation level of the sentence while keeping the noise level constant, the procedure effectively zeros in on a participant's speech reception threshold (SRT), defined as the speech-to-noise ratio (SNR) at which the participant correctly repeats back 50\% of the sentences.  The sentences are organized into lists of 10, and the different lists are balanced across phonemic content, naturalness, difficulty, and reliability.  The HINT sentences were adapted from the Bamford-Kowal-Bench (BKB) sentence set \cite{Bench1979}, excluding sentences with British idioms that could be unfamiliar to American English speakers, and using only sentences up to 8 syllables long in order to reduce any influence of memory on SRT measurements.

\section{Music Perception}
Chapter 1 already discussed many benefits of music, and Chapter 2 described how hearing aid amplification algorithms have focused primarily on restoring normal loudness and intelligibility of speech.  Not very many hearing aid studies consider how music perception may be affected by wearing hearing aids, in addition to the primary goal of restoring speech intelligibility.

\subsection{Mistuned Harmonic}
Detection of a mistuned harmonic is a widely-used method in the field of music perception.  With this method, one can obtain a threshold for the minimum amount of mistuning of a harmonic that an individual can reliably detect, which results in an end measure of frequency resolution.  It is perhaps obvious why the mistuned harmonic is important in the study of music perception, as accurate pitch perception depends on fine frequency resolution and timbre depends in part on the relation between harmonics \cite{Grey1977}.  A less obvious application of the method is in the domain of auditory scene analysis \cite{Bregman1994}, as partials which are related by integer multiples of the fundamental frequency tend to be grouped together into a single auditory object \cite{Hartmann1996}.

Hearing aids may distort the harmonic relations by applying amplification and compression disproportionately to different frequency channels.  Degradation of the signal may impair auditory abilities, such as frequency resolution or the detection of inharmonicity.  There are no experiments to the author's knowledge which apply the mistuned harmonic method to the study of hearing aid subjects, and very little, if any, with hearing-impaired subjects.  Perhaps there is sparse research on the topic because of the difficulty of testing hearing aids using tonal stimuli (due to feedback and entrainment).  Based on the mistuned harmonic's importance in music perception research, it certainly should be applied to hearing aid research if possible, and this thesis aimed to apply this method to the study of hearing aids.

\subsection{Timbre Perception}
Timbre is the multidimensional musical quality that allows one to differentiate two dissimilar instruments playing the same note, with the same intensity, and subjective duration.  It is multidimensional in the sense that there are many contributing factors to the perception of timbre \cite{Grey1977, McAdams1995}, although the three main factors which characterize timbre include the spectral shape of the sound, the spectral variation, and the rise time.  Timbre perception research has mostly focused on altering different attributes of complex tones \cite{Plomp1969, Samson1994}, but there have been more recent studies using real \cite{Emiroglu2008} and synthesized \cite{Rahne2011} instruments.  Attention has been given to different special populations in timbre perception research, such as infants \cite{Clarkson1988, Trehub1990}, patients with unilateral temporal lobe excisions \cite{Samson1994, Samson2002}, and hearing-impaired subjects \cite{Emiroglu2008}; much attention has been given to patients with cochlear implants \cite{Gfeller1991, Gfeller2002, McDermott2004}; yet surprisingly little research has examined patients with hearing aids \cite{Looi2008}.  Considering the absence of research in this area, and the importance of timbre for music perception and appreciation, we decided to compare the NC to WDRC on a novel timbre discrimination task, described in the next chapter.

\subsection{Gap Detection}
Thus far, the discussion has focused on the ability of hearing aids to restore normal speech intelligibility, frequency resolution and music perception, but one important element of sound remains; time.  Sound is spectrotemporal by nature, so the temporal processing of sound should figure prominently in the discussion, and is a field in and of itself.  Several procedures have been developed to investigate temporal aspects of auditory perception and the methods have been applied in the study of different special populations, such as the hearing-impaired \cite{Glasberg1987}, populations of different ages \cite{Schneider1999, Smith2006}, and other species \cite{Church1976, Giraudi-Perry1982}.  Temporal resolution has been studied using duration discrimination \cite{Abel1972}, masking approaches \cite{Glasberg1987}, and gap detection \cite{Shailer1983} paradigms, with varying stimulus characteristics.  In the present study, a gap detection paradigm was selected as it has been used in the past with hearing-impaired subjects \cite{Fitzgibbons1982, Glasberg1987} and subjects with hearing aids \cite{Moore2001}, which will allow us to compare our data on the NC study.  Participants with hearing impairments generally perform just as well as those with normal hearing on gap detection tasks which use pure tones \cite{Moore1988}, but for narrow-band noises the hearing-impaired perform much worse \cite{Fitzgibbons1982}.  Loudness recruitment is one explanation for why hearing-impaired subjects have larger gap thresholds than normals with narrow-band noises but not pure tones \cite{Glasberg1992}.  Likewise, hearing aids may not restore normal temporal resolution due to an inadequate amount of amplification \cite{Nelson1997}, and the type of compression used \cite{Moore2001}, as well as other factors.  Thus, with the well-established methodology of gap detection, we aim to compare the NC with WDRC on their capacity to restore normal temporal processing abilities.

\section{Sound Localization}
\subsection{Horizontal Localization}
Sound localization is an important auditory ability which contributes to communication \cite{Bronkhorst1988} and survival, and is dependent on binaural processing of intensity, timing, and spectral information.  The processes involved for horizontal and vertical localization are not the same \cite{Middlebrooks1991}, and the focus of this experiment was on frontal horizontal localization.  Interaural time and level difference (ITD, ILD) cues are the main contributors to localization in the horizontal plane.  In particular, ITD cues are used in the localization of low frequency sounds, whereas for high frequency localization, ILD cues are used due to the presence of a head shadow and the unreliability of ITD cues because of the short wavelength of the signal.

There is some indication in the literature that hearing aids impair sound localization \cite{Noble1990, VandenBogaert2006, Keidser2006}.  Hearing aid delay, compression, and directional microphones may all contribute to impaired sound localization with hearing aids, though \citeA{Keidser2006} claim that directional microphones impair horizontal localization the most out of the features listed.  Thus, there is room for improvement in sound localization for hearing aids, and it is the aim of this experiment to assess how well the NC technology restores horizontal localization relative to WDRC, controlling for features such as directional microphones that may significantly affect localization performance.

\section{Subjective Measures}
While objective measures, such as those described above, can be used to assess objective hearing aid performance in controlled settings, ultimately a hearing aid user's preference matters a great deal, as well.  Subjective measures were included in this thesis in order to fill this void.

\subsection{Abbreviated Profile of Hearing Aid Benefit (APHAB)}
The APHAB \cite{Cox1995} is a condensed version of the Profile of Hearing Aid Performance (PHAP; \citeA{Cox1990}), and is widely used in hearing aid research.  It can be self-administered, but may also be employed in clinical research settings to compare different fittings and technologies, or the same fitting, over time.  Thus, it lends itself well to the structure of the present study.  The inventory comprises a few subscales spanning the 24-item inventory, including scales for ease of communication, reverberation, background noise, and aversiveness of sounds.

\subsection{Speech and Music Quality}
There exist other hearing aid studies comparing subjective quality measures for speech and music across different hearing aid technologies \cite{Boike2000, Larson2000, Davies-Venn2007}, but often in these studies the different technologies are programmed onto the same hearing aid.  Since a version of the NC and WDRC could not be programmed onto the same hearing aid for the purpose of this study, it was impossible to make a side by side comparison of sound quality.  Instead, a general sound quality questionnaire was drafted and used, which asked the participant to report perceived music quality and overall sound quality under different listening conditions.  The aforementioned questionnaire is attached in the Appendix. 